<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2956:找到两个数组中的公共元素</title>
      <link href="/2024/07/16/2956-%E6%89%BE%E5%88%B0%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E5%85%83%E7%B4%A0/"/>
      <url>/2024/07/16/2956-%E6%89%BE%E5%88%B0%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E5%85%83%E7%B4%A0/</url>
      
        <content type="html"><![CDATA[<p>把数组转成哈希集合，就可以 O(1) 判断元素是否在数组中了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] findIntersectionValues(<span class="hljs-type">int</span>[] nums1, <span class="hljs-type">int</span>[] nums2) &#123;<br>            HashSet&lt;Integer&gt;set1=<span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x:nums1)&#123;<br>                set1.add(x);<br>            &#125;<br>            HashSet&lt;Integer&gt;set2=<span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x:nums2)&#123;<br>                set2.add(x);<br>            &#125;<br>            <span class="hljs-type">int</span> n1=<span class="hljs-number">0</span>,n2=<span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x:nums1)&#123;<br>                <span class="hljs-keyword">if</span>(set2.contains(x))&#123;<br>                    n1++;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> x:nums2)&#123;<br>                <span class="hljs-keyword">if</span>(set1.contains(x))&#123;<br>                    n2++;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;n1,n2&#125;;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>206.反转链表</title>
      <link href="/2024/07/16/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"/>
      <url>/2024/07/16/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p>思路：</p><p>申请两个指针，第一个指针叫 pre，最初是指向 null 的。</p><p>第二个指针 cur 指向 head，然后不断遍历 cur。</p><p>每次迭代到 cur，都将 cur 的 next 指向 pre，然后 pre 和 cur 前进一位。</p><p>都迭代完了(cur 变成 null 了)，pre 就是最后一个节点了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">reverseList</span><span class="hljs-params">(ListNode head)</span> &#123;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">pre</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-type">ListNode</span> <span class="hljs-variable">cur</span> <span class="hljs-operator">=</span> head;<br>        <span class="hljs-keyword">while</span>(cur!=<span class="hljs-literal">null</span>)&#123;<br>            ListNode nxt=cur.next;<br>            cur.next=pre;<br>            pre=cur;<br>            cur=nxt;<br>        &#125;<br>        <span class="hljs-keyword">return</span> pre;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2024/gif/33777925/1721112854377-19aecd3d-48b9-47b6-9af4-b4f7ff38cd32.gif" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.两数相加</title>
      <link href="/2024/07/16/%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/"/>
      <url>/2024/07/16/%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/</url>
      
        <content type="html"><![CDATA[<p>创建哨兵节点在返回的链表节点之前，之后采用节点指针遍历，注意判断终止条件，如果有进位也要继续。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Definition for singly-linked list.</span><br><span class="hljs-comment"> * public class ListNode &#123;</span><br><span class="hljs-comment"> *     int val;</span><br><span class="hljs-comment"> *     ListNode next;</span><br><span class="hljs-comment"> *     ListNode() &#123;&#125;</span><br><span class="hljs-comment"> *     ListNode(int val) &#123; this.val = val; &#125;</span><br><span class="hljs-comment"> *     ListNode(int val, ListNode next) &#123; this.val = val; this.next = next; &#125;</span><br><span class="hljs-comment"> * &#125;</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> ListNode <span class="hljs-title function_">addTwoNumbers</span><span class="hljs-params">(ListNode l1, ListNode l2)</span> &#123;<br>        ListNode head=<span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>();<span class="hljs-comment">//哨兵节点</span><br>        ListNode current=head;<br>        <span class="hljs-type">int</span> rem=<span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(l1!=<span class="hljs-literal">null</span>||l2!=<span class="hljs-literal">null</span>||rem!=<span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">if</span> (l1!=<span class="hljs-literal">null</span>)rem+=l1.val;<br>            <span class="hljs-keyword">if</span> (l2!=<span class="hljs-literal">null</span>)rem+=l2.val;<br>            current.next=<span class="hljs-keyword">new</span> <span class="hljs-title class_">ListNode</span>(rem%<span class="hljs-number">10</span>);<br>            current=current.next;<br>            rem/=<span class="hljs-number">10</span>;<br>            <span class="hljs-keyword">if</span>(l1!=<span class="hljs-literal">null</span>)l1=l1.next;<br>            <span class="hljs-keyword">if</span>(l2!=<span class="hljs-literal">null</span>)l2=l2.next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> head.next;<br>    &#125;<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.两数之和</title>
      <link href="/2024/07/16/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
      <url>/2024/07/16/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
      
        <content type="html"><![CDATA[<p>暴力：双循环</p><p>正解：</p><p>哈希表&lt;值，下标&gt;</p><p>先find找不到再insert，保证不会和自己匹配。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span>[] twoSum(<span class="hljs-type">int</span>[] nums, <span class="hljs-type">int</span> target) &#123;<br>        Map&lt;Integer, Integer&gt; hashtable = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;Integer, Integer&gt;();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; nums.length; ++i) &#123;<br>            <span class="hljs-keyword">if</span> (hashtable.containsKey(target - nums[i])) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;hashtable.get(target - nums[i]), i&#125;;<br>            &#125;<br>            hashtable.put(nums[i], i);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>链接：<a href="https://leetcode.cn/problems/two-sum/solutions/434597/liang-shu-zhi-he-by-leetcode-solution/">https://leetcode.cn/problems/two-sum/solutions/434597/liang-shu-zhi-he-by-leetcode-solution/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode刷题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据投毒攻击</title>
      <link href="/2024/07/15/%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92%E6%94%BB%E5%87%BB/"/>
      <url>/2024/07/15/%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92%E6%94%BB%E5%87%BB/</url>
      
        <content type="html"><![CDATA[<p>数据投毒攻击（Data Poisoning Attack）定义为攻击者在机器学习模型的训练阶段，通过向训练数据集中注入少量精心设计的恶意样本（也称为“毒化样本”），从而影响模型的学习过程。这些恶意样本利用模型的训练或微调（fine-tuning）过程，使得模型在测试阶段或部署后的预测阶段表现异常。数据投毒攻击的目的是破坏模型的可用性或完整性，导致模型对于特定的输入产生错误的输出，或者在更广泛的范围内降低模型的准确性和可靠性。</p><h2 id="理论模型"><a href="#理论模型" class="headerlink" title="理论模型"></a>理论模型</h2><p>数据投毒的威胁模型可以根据攻击者的目标、知识水平和攻击方式来描述。攻击者的目标可以分为有目标和无目标两种。在无目标攻击中，攻击者旨在尽可能地产生模型错误预测，而有目标攻击则专注于特定的测试样本，试图改变模型对其分类结果。攻击者的知识水平对攻击的能力和战略至关重要。白盒攻击者了解目标机器学习系统的任务、算法、数据集和内部工作原理，可以直接访问训练数据和模型权重。黑盒攻击者无法直接访问受害模型和数据集，但可以利用替代数据集和模型来模拟原始系统。灰盒攻击者则对目标模型部分了解。攻击者可以通过修改数据的标签或内容来进行数据投毒。标签修改是指操纵数据的标签，例如将数字1标记为7；数据修改则是修改训练数据的内容，例如向图像中添加噪声。此外，还有数据注入的方式，即向训练集中注入中毒数据，如虚构用户向推荐系统上传信息。数据投毒的建模可看作是一个双层优化模型。外层优化旨在调整中毒样本，使模型在验证集上产生最大损失。内层优化则调整模型参数，使加入中毒样本后的训练损失最小化。通过这种方式，攻击者可以针对模型进行有针对性的攻击，使其在训练或预测时产生错误结果。</p><h2 id="攻击方法"><a href="#攻击方法" class="headerlink" title="攻击方法"></a>攻击方法</h2><h3 id="基于标签翻转的数据投毒攻击"><a href="#基于标签翻转的数据投毒攻击" class="headerlink" title="基于标签翻转的数据投毒攻击"></a>基于标签翻转的数据投毒攻击</h3><p>基于标签翻转的数据投毒攻击是针对有监督机器学习模型的一种常见攻击方式。其核心思想是通过改变训练数据的标签来扰乱模型学习的映射关系，从而损害模型的性能。在这种攻击中，攻击者通常希望以最少的标签翻转达到最大的攻击效果。最早的攻击方法通常是不加章法地随机翻转训练数据的标签，导致模型学习错误的映射关系。例如，在数字识别任务中，将数字1的标签随机更改为7。然而，随机翻转标签的方法并不一定是最有效的，因为它可能需要翻转大量的数据才能对模型产生显著的影响，并且攻击效果也不可控。为了提高攻击的效果和效率，研究者开始探索基于模型梯度信息或生成对抗网络的方法，以选择最具攻击性的样本进行标签翻转，从而在翻转更少的标签的情况下对模型造成更大的影响。</p><h3 id="基于优化的数据投毒攻击"><a href="#基于优化的数据投毒攻击" class="headerlink" title="基于优化的数据投毒攻击"></a>基于优化的数据投毒攻击</h3><p>基于优化的数据投毒攻击核心在于将攻击目标转化为优化问题，并在特定的约束条件下解决这些问题，以影响机器学习模型的性能。这种攻击方法的关键在于攻击者通过调整中毒样本的特征，使得模型在训练过程中产生最大的误差。通常，攻击者面临两种优化策略：修改标签和修改数据。在修改标签的策略中，攻击者试图找到一组最具有影响力的样本，从而使模型学习产生最大的误差。而在修改数据的策略中，攻击者则尝试在不改变标签的情况下，通过引入噪音或扰动来影响模型的学习过程。为了更好地控制攻击效果，研究者通常引入各种约束条件，例如限制噪音水平、染毒率以及修改数量等。</p><h3 id="基于特征碰撞的数据投毒攻击"><a href="#基于特征碰撞的数据投毒攻击" class="headerlink" title="基于特征碰撞的数据投毒攻击"></a>基于特征碰撞的数据投毒攻击</h3><p>数据投毒的特征碰撞法是一种用于攻击机器学习模型的方法，其基本原理是通过有意选择或生成具有误导性的样本，使其在关键特征上与正常样本相似但在其他方面有所不同，从而导致模型做出错误的分类决策。攻击者首先需要深入了解目标模型的工作原理，尤其是其特征提取过程。攻击者可能会利用对抗样本生成技术来生成具有误导性的样本，或者有针对性地修改已有样本的特征。这种方法的优势在于攻击者可以有选择地攻击模型的关键特征，从而更有效地干扰模型的预测结果。然而，特征碰撞法也存在挑战和限制，攻击者需要具备深入的专业知识和对模型的理解，并且攻击效果可能受到模型鲁棒性和特征多样性等因素的影响。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>知识蒸馏</title>
      <link href="/2024/07/15/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/"/>
      <url>/2024/07/15/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/</url>
      
        <content type="html"><![CDATA[<p>知识蒸馏（Knowledge Distillation）是一种模型压缩技术，它允许一个大型、复杂的模型（称为“教师模型”）的知识被转移到一个更小、更简单的模型（称为“学生模型”）。这种方法的核心目的是在保持性能的同时减少模型的复杂性和计算资源需求，从而使得模型更适合在资源受限的环境下部署。[1]<br>知识蒸馏的基本流程包括两个阶段：首先是训练一个复杂的教师模型，然后使用这个模型的输出或中间结果作为学生模型训练的监督信号来训练一个结构更简单、参数更少的学生模型。<br>在知识蒸馏中，根据所使用的知识类型，可以将其分为几种不同的策略，每种策略利用教师模型的不同方面来指导学生模型的学习。以下是三种主要的知识蒸馏策略：<br><strong>基于响应的知识蒸馏，</strong>这种策略主要关注于教师模型的最后一层输出，即类别的logits（未经softmax层处理的原始输出）。学生模型的目标是模仿这些logits，而不是直接模仿softmax层后的概率分布。这种方法假设对数向量Z为全连接层的最后输出，学生模型的训练可以通过最小化学生模型的logits和教师模型的logits之间的差异来完成。这种差异通常通过KL散度（Kullback-Leibler divergence）来衡量，优化该损失函数可以使学生模型的logits与教师模型的logits相匹配。此外，通过引入温度参数T，可以调整softmax函数的输出，使得学生模型学习到的类别概率分布更加平滑，从而更好地捕捉教师模型的知识。这种方法特别适用于图像分类任务中，其中软目标（soft targets）是输入类别的概率，可以通过softmax函数结合温度参数来估计。<br><strong>基于特征的知识蒸馏，</strong>与基于响应的知识蒸馏不同，基于特征的知识蒸馏关注的是教师模型中间层的激活或特征图。这种方法的核心思想是将教师模型和学生模型的中间层特征直接匹配起来。通过最小化两个模型在中间层特征表示上的差异，学生模型可以学习到更丰富的信息，这不仅包括了最终的预测结果，还包括了数据的中间层次表示。特征匹配通常通过一些相似性度量来实现，如L1范数、L2范数或交叉熵等。这种方法特别适用于深度神经网络，因为它们在不同层学习到的特征具有不同层次的语义信息。基于特征的知识蒸馏可以为学生模型提供更丰富的信息，帮助其更好地泛化。<br><strong>基于关系的知识蒸馏，</strong>进一步探索了不同层或数据样本之间的关系。这种策略不仅考虑单个样本的知识，还考虑样本之间的关系，如成对样本的相似性或类别之间的关系。这种关系可以是显式的，如成对样本的相似性，或者是隐式的，如通过图结构来表示的数据点之间的关系。<br>在关系蒸馏中，学生模型不仅学习教师模型的特征表示，还学习这些特征之间的关系。例如，可以使用成对的教师模型特征图和学生模型特征图之间的相似性度量作为损失函数的一部分。这种方法可以帮助学生模型学习到更复杂的数据结构和模式，从而提高其性能。<br>另外，知识蒸馏的实施方式可以根据教师模型和学生模型的更新策略来分类，主要分为离线蒸馏、在线蒸馏和自蒸馏三种模式：<br><strong>离线蒸馏</strong><br>离线蒸馏（Offline Distillation） 是最常见的知识蒸馏方法，它涉及两个阶段的训练过程：首先独立训练一个大型的教师模型，直到其性能达到最优。接着，使用教师模型在训练集上生成的软目标（如softmax层的概率分布）作为训练信号来训练学生模型。学生模型学习模仿这些软目标，而不是直接学习原始数据的硬标签。 离线蒸馏的优点在于简单和易于实现，但它的缺点是训练时间长，且学生模型对教师模型有较大依赖性。此外，由于教师模型在学生训练阶段是固定的，它不能适应学生模型的学习进度。<br><strong>在线蒸馏</strong><br>在线蒸馏（Online Distillation） 是一种端到端的训练方案，其中教师模型和学生模型同时更新。在线蒸馏的关键在于，它允许学生模型从教师模型中学习，同时教师模型也可以从学生模型中获得反馈，从而实现两者的协同优化。  在线蒸馏的优点是可以更灵活地调整教师和学生模型之间的关系，但实现起来相对复杂，需要更精细的调参和训练策略。<br><strong>自蒸馏</strong><br>自蒸馏（Self-Distillation） 是一种特殊的在线蒸馏，其中教师模型和学生模型实际上是同一个网络，或者学生模型是教师模型的一个副本。  自蒸馏的优点在于可以更有效地利用网络自身的能力，并且有助于提高模型的泛化能力。此外，自蒸馏不需要额外的教师模型，从而节省了计算资源。 </p><ol><li>Hinton, G., Vinyals, O., &amp; Dean, J. (2015). Distilling the Knowledge in a Neural Network. In NIPS Deep Learning and Representation Learning Workshop.</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>低秩矩阵分解</title>
      <link href="/2024/07/14/%E4%BD%8E%E7%A7%A9%E7%A8%80%E7%96%8F%E5%88%86%E8%A7%A3/"/>
      <url>/2024/07/14/%E4%BD%8E%E7%A7%A9%E7%A8%80%E7%96%8F%E5%88%86%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>矩阵的秩是其线性独立行或列的最大数目，而低秩矩阵是指其秩远小于其行数或列数的矩阵。一个低秩矩阵通常意味着它包含的线性独立信息较少，这种矩阵的特性使得它们在数据压缩、降维、信号处理和计算机视觉等领域非常有用。例如，在机器学习中，低秩矩阵分解可以用于特征提取和推荐系统；在信号处理中，它们可以用于噪声过滤和信号分离；在计算机视觉中，低秩矩阵分解有助于图像去噪和三维重建。低秩矩阵通常具有稀疏性，即它们包含大量的零或近似零元素，这使得它们在存储和计算上更为高效。此外，低秩矩阵分解在数值稳定性方面也具有优势，因为它们对噪声和异常值的敏感性较低。<br>矩阵的低秩分解问题形式化定义为：给定一个𝑚×𝑛的矩阵 𝑀，目标是找到两个低秩矩阵 𝐴和 𝐵，A 是 m × k 的矩阵，B 是 k × n 的矩阵，使得 𝑀可以近似表示为 𝐴 和 𝐵 的乘积。我们希望最小化 𝑀 和 𝐴×𝐵 之间的差异，这通常通过最小化它们的范数来实现。在实际操作中，𝐴 和 𝐵的选择旨在使 𝐴×𝐵 尽可能接近 𝑀，同时保持 𝐴和 𝐵的秩尽可能低。这通常意味着在保留数据主要特征的同时，忽略了一些较小的细节或噪声。目前实现矩阵低秩分解方法有梯度下降（Gradient Descent, GD）和交替最小二乘法（Alternating Least Squares, ALS）等。</p><h3 id="梯度下降（GD）"><a href="#梯度下降（GD）" class="headerlink" title="梯度下降（GD）"></a>梯度下降（GD）</h3><p>梯度下降法是一种一阶迭代优化算法，通过沿着目标函数梯度的反方向调整参数来寻找最小值。在低秩分解的上下文中，目标通常是最小化原始矩阵与分解后重构矩阵之间的差异。<br>在低秩矩阵分解中，我们的目标是最小化重构误差，这通常表示为Frobenius范数的平方:<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240715215711879.png" alt="image-20240715215711879"><br>为了找到最小化目标函数的矩阵 𝐴 和 𝐵，我们需要计算 𝑓关于 𝐴和 𝐵 的梯度, 利用梯度信息，我们更新 𝐴和 𝐵以减少 𝑓_f_的值。更新规则为：<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240715215737204.png" alt="image-20240715215737204"><br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240715215843119.png" alt="image-20240715215843119"><br>其中，𝛼是学习率，一个正的小数值，控制着更新的步长，重复上述更新步骤直到满足某个停止条件，如梯度的范数下降到一个很小的值，或者迭代次数达到预设的上限</p><h3 id="交替最小二乘法（ALS）"><a href="#交替最小二乘法（ALS）" class="headerlink" title="交替最小二乘法（ALS）"></a>交替最小二乘法（ALS）</h3><p>交替最小二乘法是一种解决低秩矩阵分解问题的有效算法，特别适合于分解大型稀疏矩阵。它通过交替优化一个因子矩阵，同时固定另一个因子矩阵来逐步改善分解。<br>ALS通过将原始问题分解为一系列更小的问题来求解。在每一步中，固定一个矩阵，然后优化另一个矩阵。首先当 𝐴固定时，我们只优化 𝐵。这可以通过最小二乘法解析求解：<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1425713adaf1877a4920b6a237f16466.svg"><br>这里假设 𝐴^𝑇𝐴 是可逆的。如果 𝐴^𝑇𝐴 不可逆或接近奇异，可能需要正则化。<br>同理，当 𝐵 固定时，我们优化 𝐴：<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/23e5c5ddb5faddb72f5ec0dd16543703.svg"><br>交替进行上述两个步骤，直到收敛。收敛条件可以是残差平方和的减少量低于某个阈值，或者迭代次数达到一定数目。<br><strong>深度学习框架中的矩阵分解</strong><br>矩阵分解技术（包括奇异值分解SVD、主成分分析PCA、低秩矩阵分解等）在深度学习框架中如PyTorch和TensorFlow被广泛应用于模型压缩和加速计算。在PyTorch中，可以使用torch.linalg.svd进行奇异值分解，这是实现矩阵分解的一种基础方法。此外，pytorch中的Tensorly库为PyTorch提供了多种张量分解技术，如CP分解和Tucker分解，特别适用于加速卷积层的计算。而在TensorFlow中，tf.linalg.svd同样可以用于执行低秩分解，并且TensorFlow的模型优化工具箱（TensorFlow Model Optimization Toolkit）提供了系统化的模型压缩技术，包括低秩近似方法。另外，TensorFlow中可以使用tf.matrix_solve_ls等函数来进行低秩近似，这在某些情况下可以加速模型的推理过程。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>深度学习编译器</title>
      <link href="/2024/07/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/"/>
      <url>/2024/07/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>深度学习编译器是一种专门针对深度学习应用的编译器，它的作用是将深度学习模型（通常由高级框架如TensorFlow、PyTorch等构建和训练）转换成在特定硬件平台上高效运行的低级代码。<br>深度学习编译器通常在前端接收不同深度学习框架（如TensorFlow, PyTorch等）生成的模型，并将其转换成统一的中间表示（Intermediate Representation, IR）。IR是一种抽象的模型表示，它提供了一种平台无关的方式来描述计算图和操作。IR可以是图级别的，也可以是更低层次的。然后，在IR层面上，编译器会应用一系列的图优化技术，如节点融合、常量折叠等，以简化模型并减少计算量。根据目标硬件的特性（如CPU的SIMD指令集、GPU的线程并行性等），编译器会进行特定的优化，如算子融合、内存访问模式优化等。在调度阶段，编译器为模型中的每个操作生成具体的执行计划，包括决定循环的顺序、数据的布局、并行化策略等。最后，编译器将优化后的IR和调度信息转换成目标硬件的机器码，并在目标设备上执行编译后的模型。</p><h1 id="TVM"><a href="#TVM" class="headerlink" title="TVM"></a>TVM</h1><p>Apache TVM是端到端的开源机器学习编译框架，使基于不同机器学习框架（如TensorFlow, PyTorch,MXNet, ONNX等）的机器学习模型在不同硬件上（CPU、GPU、ASIC等）经过优化高效运行。<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image.png" alt="image"><br>TVM进行模型优化过程如图所示，TVM首先将其他框架导出的模型导入编译器前端，之后将其转换成TVM的高级中间表示（High-level IR）Relay，之后使用Relay进行图级别的优化。在高级优化完毕后，编译器将模型分解为多个子图，并将中间表示转换为张量表达式（TE），TE支持循环切分、并行化、循环展开和融合等基本优化操作，TVM通过Auto-tuning module模块搜索最佳的底层循环优化调度，为每个子图提供最佳调度方案。最后，编译器将所有子图的中间表示（TE）转换为底层中间表示（TIR），在经过优化后TIR传递给需要部署的编译器后端（如LLVM，NVCC，BYOC等），编译器后端生成对应的机器码，并将模型编译为可链接对象模块通过TVM runtime动态加载模型。</p><h2 id="TVM加速Pytorch模型示例："><a href="#TVM加速Pytorch模型示例：" class="headerlink" title="TVM加速Pytorch模型示例："></a>TVM加速Pytorch模型示例：</h2><ol><li><p>安装 TVM：TVM 可以通过 pip 或源代码安装。使用 pip 安装是最简单的方式，如果需要支持特定的硬件后端(如 CUDA),可以使用 pip install tvm[cuda] 等命令。也可以从源代码构建 TVM。</p></li><li><p>准备机器学习模型：以Pytorch为例，确保你有一个已经训练完成的PyTorch模型。如对于ResNet18，可以通过torchvision.models模块轻松获得。使用pretrained&#x3D;True参数来下载和加载一个已经预训练好的模型。</p></li><li><p>转换为TorchScript：利用torch.jit.trace方法对模型执行跟踪，将其转换为TorchScript格式。这一步是必要的，因为TVM前端需要TorchScript格式的模型来进行后续处理。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs makefile">import torch<br><span class="hljs-comment"># 假设你已经定义了 PyTorch 模型</span><br>model = ...<br>input_shape = [1, 3, 224, 224]  <span class="hljs-comment"># 定义模型的输入尺寸</span><br>input_data = torch.randn(input_shape)<br>scripted_model = torch.jit.trace(model, input_data).eval()<br></code></pre></td></tr></table></figure></li><li><p>转换为TVM Relay：使用TVM的Relay前端，将TorchScript模型转换成Relay中间表示(IR)。这一步涉及将PyTorch的算子映射并替换为TVM的算子。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> tvm<br><span class="hljs-title">from</span> tvm <span class="hljs-keyword">import</span> relay<br><span class="hljs-meta"># 将 PyTorch 模型转换为 Relay IR</span><br><span class="hljs-title">mod</span>, params = relay.frontend.from_pytorch(model, input_shape)<br></code></pre></td></tr></table></figure></li><li><p>构建Relay模型：通过relay.build函数，将Relay模型转换成目标硬件平台的可执行代码。选择”llvm”作为目标，这通常适用于CPU架构。其中opt_level 控制优化级别,范围从 0 到 3,级别越高,优化程度越高,但编译时间也会更长。</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># 为 CPU 优化</span><br><span class="hljs-keyword">target</span> = tvm.<span class="hljs-keyword">target</span>.<span class="hljs-keyword">Target</span>(<span class="hljs-string">&quot;llvm&quot;</span>)<br><span class="hljs-comment"># 为 NVIDIA GPU 优化  </span><br><span class="hljs-keyword">target</span> = tvm.<span class="hljs-keyword">target</span>.<span class="hljs-keyword">Target</span>(<span class="hljs-string">&quot;cuda&quot;</span>)<br><span class="hljs-comment"># 为 ARM CPU 优化</span><br><span class="hljs-keyword">target</span> = tvm.<span class="hljs-keyword">target</span>.<span class="hljs-keyword">Target</span>(<span class="hljs-string">&quot;llvm -mtriple=aarch64-linux-gnu&quot;</span>)<br>with tvm.transform.PassContext(opt_level=<span class="hljs-number">3</span>):  <span class="hljs-comment"># 指定优化级别</span><br>    lib = relay.build(mod, <span class="hljs-keyword">target</span>=<span class="hljs-keyword">target</span>, params=params)<br></code></pre></td></tr></table></figure></li><li><p>另外，TVM 提供了自动调优功能,可以进一步优化模型在特定硬件上的性能。它会自动探索不同的调度策略和参数组合,以找到最优的执行方式。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 创建任务</span><br>task = autotvm.task.create(<span class="hljs-built_in">..</span>.)<br><br><span class="hljs-comment"># 运行自动调优</span><br>tuner = autotvm.tuner.RandomTuner(task)<br>n_trial = 1000  # 设置最大调优次数<br>tuner.tune(<span class="hljs-attribute">n_trial</span>=n_trial)<br><br><span class="hljs-comment"># 应用调优结果</span><br>with tvm.transform.PassContext(<span class="hljs-attribute">opt_level</span>=3, config=&#123;<span class="hljs-string">&quot;relay.backend.use_auto_scheduler&quot;</span>: <span class="hljs-literal">True</span>&#125;):<br>    lib = relay.build(mod, <span class="hljs-attribute">target</span>=target, <span class="hljs-attribute">params</span>=params)<br></code></pre></td></tr></table></figure></li><li><p>运行编译后的模型：使用TVM runtime来加载和运行编译后的模型。首先，确保LLVM运行时被启用，然后选择目标CPU核心，并加载模型。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs makefile">tvm.runtime.enabled(<span class="hljs-string">&quot;llvm&quot;</span>)<br>ctx = tvm.cpu(0)  <span class="hljs-comment"># 指定CPU核心为例</span><br><span class="hljs-comment"># 创建运行时模块</span><br>module = tvm.contrib.graph_executor.GraphModule(lib[<span class="hljs-string">&quot;default&quot;</span>](device))<br><span class="hljs-comment"># 设置输入数据</span><br>input_data = ...<br>module.run(data=input_data)<br></code></pre></td></tr></table></figure></li></ol><h1 id="Tensorflow-XLA"><a href="#Tensorflow-XLA" class="headerlink" title="Tensorflow XLA"></a>Tensorflow XLA</h1><p>XLA（Accelerated Linear Algebra）是Tensorflow内置的一种深度学习编译器，用于加速TensorFlow模型的运行速度并改进内存使用效率。TensorFlow XLA，作为TensorFlow生态系统内的关键组件，XLA能够针对不同硬件后端生成定制化代码，如利用CUDA为NVIDIA GPU生成优化并行代码，或使用ROCm为AMD GPU生成代码，实现设备特定的优化。此外，XLA在优化过程中考虑多线程和并行执行，通过重构计算图来提升执行效率，充分利用多核CPU或多GPU的计算资源。在内存优化方面，XLA通过改进内存访问模式，减少全局内存访问，转而使用局部缓存或寄存器，有效提升了模型的运行速度。<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1714395363723-7402366c-13da-47e5-990f-d560fbbe83d1.png" alt="image.png"><br>在TensorFlow会话配置被设置以启用XLA时，如将global_jit_level设置为tf.OptimizerOptions.ON_1，用户定义的模型被构建成TensorFlow的计算图，该图经过分析识别出使用XLA优化的部分。这些部分被转换成XLA的中间表示——高级优化语言（HLO IR）。XLA接着对HLO图执行目标无关的优化，如常量传播、死码消除和表达式简化等。之后将HLO图传递给XLA后端，XLA根据目标硬件的特性，如CPU或GPU，进行特定的优化，包括内存访问模式优化和操作融合。最后优化后的HLO图最终被转换成目标硬件的机器代码，如利用LLVM等工具为CPU生成机器码，或为GPU生成CUDA或PTX代码。<br>在TensorFlow中启用XLA（加速线性代数）可以通过以下几种方式进行：</p><ol><li><p>使用tf.function装饰器： 通过为TensorFlow函数添加tf.function装饰器并设置参数jit_compile&#x3D;True，可以明确指示TensorFlow使用XLA进行编译。这要求函数的输入形状是静态的或者可以被推断出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><br><span class="hljs-meta">@tf.function(<span class="hljs-params">jit_compile=<span class="hljs-literal">True</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_step</span>(<span class="hljs-params">x, y</span>):<br>    <span class="hljs-comment"># 定义训练步骤的计算图</span><br>    <span class="hljs-keyword">return</span> compute_loss(x, y)  <span class="hljs-comment"># 假设compute_loss是一个已定义的函数</span><br></code></pre></td></tr></table></figure></li><li><p>自动聚类： 使用环境变量TF_XLA_FLAGS来启用XLA的自动聚类功能。这种方法不需要修改现有的TensorFlow代码，XLA会自动处理可以被编译的TensorFlow图的部分。在命令行中启动程序之前，设置环境变量：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">TF_XLA_FLAGS</span>=--tf_xla_auto_jit=2<br>python my_tensorflow_program.py<br></code></pre></td></tr></table></figure><p>对于CPU上的自动聚类，可以使用：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">export</span> <span class="hljs-attribute">TF_XLA_FLAGS</span>=<span class="hljs-string">&quot;--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit&quot;</span><br></code></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>模型量化</title>
      <link href="/2024/07/12/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/"/>
      <url>/2024/07/12/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>在深度学习中，模型的参数和激活值通常以浮点数的形式存储在内存中，而嵌入式设备、移动设备等端侧存储空间和计算速度有限。模型量化（ Quantization）是一种将深度学习模型中的参数或激活值从浮点数转换为低比特定点数的技术，通过数据存储方式的转换以减少模型的内存占用和计算成本，以较小的精度损失可以显著减少模型的内存和存储占用、降低计算成本。</p><h2 id="3-1-整数、定点数与浮点数"><a href="#3-1-整数、定点数与浮点数" class="headerlink" title="3.1 整数、定点数与浮点数"></a>3.1 整数、定点数与浮点数</h2><p>在计算机中，整数、定点数、浮点数数据都是以二进制形式存储的。其中整数数据是不包含小数部分的数值类型，在计算机中以二进制补码形式存储。整数数据可以是有符号的（可以表示正数、负数和零）或无符号的（只能表示非负数）。无符号整数中所有位都用来表示数值部分，不包含符号位。例如，一个8位的无符号整数可以表示范围为0到255的整数。而有符号整数中最高位通常用作符号位，0表示正数，1表示负数。其余位表示整数的数值部分。例如，一个8位的有符号整数可以表示范围为-128到+127的整数。<br>定点数是一种用于表示实数的数值系统，其中小数点的位置是固定的，它们在计算机中以固定的位数表示整数和小数部分。例如有一个8位的定点小数，其中小数点在第4位上。这意味着第1位用来表示符号，第2~4位用于表示整数部分，后面的4位用于表示小数部分（见图）。<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1714396700042-6cb78d75-23bb-45c1-9ae8-eeaa69a94161.png" alt="未命名文件(19).png" style="zoom:33%;" /><br>在计算机中，浮点数以二进制形式存储，通常使用IEEE 754标准来定义浮点数的存储方式。该标准定义了单精度浮点数（32位）和双精度浮点数（64位）两种格式。其中，单精度浮点数使用32位（4字节）存储，其中不同部分的位数分配如下：符号位（1位）：用于表示数的正负，0表示正数，1表示负数。指数部分（8位）：用于表示数的指数部分，以偏置值的形式表示，通常加上127来表示实际指数值。尾数部分（23位）：用于表示数的尾数部分，也称为有效位数或尾数，其中包含小数点后面的数字。<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1714397159813-92d8c6dc-50d7-452c-b810-37029ab3e61d.png" alt="未命名文件(20).png" style="zoom:33%;" /></p><h2 id="3-2-量化方式"><a href="#3-2-量化方式" class="headerlink" title="3.2 量化方式"></a>3.2 量化方式</h2><p>模型量化将浮点数参数或激活值映射到整数或定点数表示，从而实现模型参数和激活值的量化。根据映射函数的性质，可以分为线性量化和非线性量化。<br>线性量化是一种均匀量化方法，它将连续的浮点数范围线性映射到有限的离散整数值。在这种方法中，每个量化级别之间的间隔是相同的。例如，如果我们使用8位整数（INT8）进行量化，那么量化的范围通常是-128到+127，中间间隔为1。线性量化的公式可以表示为：<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240715215047466.png" alt="image-20240715215047466"><br>其中，𝑅 是原始的浮点值，𝑄是量化后的整数值，𝑆是量化的尺度因子，𝑍是量化的零点（通常是0）。<br>非线性量化，也称为非均匀量化，是一种量化策略，它允许不同数值区间有不同的量化粒度。这种量化方法对于处理具有非均匀分布数据的模型特别有用，它可以根据数据的统计特性来调整量化的精度。<br>模型量化根据量化时机可以分为训练后量化（Post-Training Quantization）和量化感知训练（Quantization-Aware Training, QAT）。<br>训练后量化是一种在模型完成训练后应用的技术，它通过收集模型在推理过程中的统计信息来确定量化参数，然后应用这些参数将模型的权重和激活函数量化为整数格式。这种方法的优点是操作简单，不需要改变原有的训练流程，但它不涉及对模型训练过程的调整，因此可能无法完全补偿量化带来的性能损失。训练后量化通常分为两个步骤：准备（Prepare）和转换（Convert）。首先，通过插入观察者（Observer）来收集量化所需的统计信息。然后，将模型的权重和激活量化到较低的位宽。<br>量化感知训练是一种在模型训练阶段就引入量化噪声的方法。量化感知训练在模型训练过程中模拟量化操作，允许模型权重在前向传播时被量化，而在反向传播时使用全精度进行更新。在QAT过程中，模型的权重和激活函数在前向传播时会被模拟量化，而在反向传播时则使用全精度的浮点数进行梯度计算。这样可以使模型在训练过程中逐渐适应量化带来的误差，从而在量化后保持更高的精度。QAT的优点在于能够提高量化模型的精度，但缺点是增加了训练的复杂性，并且需要额外的训练时间来完成量化适应。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>模型剪枝</title>
      <link href="/2024/07/10/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/"/>
      <url>/2024/07/10/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/</url>
      
        <content type="html"><![CDATA[<p>模型剪枝是深度学习模型优化技术之一，其核心目的是减少模型的参数数量和计算复杂度，以提高模型在资源受限环境中的部署效率和运行速度，剪枝问题可以形式化定义为：<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240715215130751.png" alt="image-20240715215130751"><br>其中L为损失函数，x为输入，W为原始权重，Wp为剪枝后的权重,而Wp的范数为剪枝后的权重中的非零值，N剪枝目标设置的非零值的个数。<br>剪枝可以在模型生命周期的不同阶段进行，包括训练前、训练中、训练后，以及通过增量或动态的方式进行。训练前剪枝通过减少初始参数数量来降低模型的复杂度，但可能需要特别的初始化和训练策略来维持性能。训练中剪枝允许模型逐步适应剪枝操作，但需要精心设计的剪枝策略以避免性能损失。训练后剪枝则基于训练完成的模型来识别不重要的参数，通常需要重训练或微调来补偿可能的性能下降。增量剪枝结合了训练中和训练后剪枝的优点，通过分阶段剪枝为模型提供了更多适应机会。动态剪枝则在模型推理时根据输入数据动态调整剪枝程度，以提高特定任务的效率，但实现更为复杂。<br>模型剪枝的策略尽可能保持或恢复模型性能且尽可能减少参数数目。常见的剪枝策略包括基于权重幅度的剪枝，它进行权重排序，移除那些权重较小的连接，通过阈值选择进行剪枝；正则化策略通过鼓励权重稀疏性，使得模型在训练过程中自然形成稀疏权重矩阵，从而为剪枝提供依据。另外，结构化剪枝如过滤器剪枝易于在硬件上实现，但可能不如非结构化剪枝灵活。非结构化剪枝可以提供更大的压缩空间，但可能需要特定硬件或软件支持来实现加速。<br><strong>结构化剪枝</strong><br>结构化剪枝通过移除模型中的整个结构单元来实现稀疏化，而不破坏数据的存储结构。结构化剪枝有多种粒度，每种粒度针对模型的不同层次进行操作：<br>过滤器剪枝（Filter Pruning），这种剪枝方法通过移除整个过滤器（或称为通道）来减少模型的参数数量和计算量。由于每个过滤器与后续层的每个神经元都相连，移除一个过滤器可以显著减少网络的宽度，从而降低计算复杂度。过滤器剪枝是一种粗粒度剪枝，因为它以过滤器为单位进行操作，而过滤器通常包含多个权重。这种方法对于硬件友好，因为它保持了数据的存储结构，不会破坏卷积层的数据对齐性。<br>核剪枝（Kernel Pruning）：核剪枝涉及到移除卷积核中的某些部分，这可能是一行、一列或者是核中的某些区域。与过滤器剪枝相比，核剪枝的粒度更细，因为它不移除整个过滤器，而是过滤器内部的部分权重。核剪枝可能需要特定的硬件支持来实现有效加速，因为它打破了卷积运算的标准流程。<br>向量级剪枝（Vector-Level Pruning）：向量级剪枝是指移除卷积核中的整行或整列权重，这种剪枝方法的粒度介于过滤器剪枝和核剪枝之间。它通常用于减少卷积核的尺寸，但保持了卷积层的大部分结构。<br>细粒度剪枝（Fine-Grained Pruning）：细粒度剪枝，或称为非结构化剪枝，涉及单个权重的移除。这种剪枝方法可以提供最大的压缩比，因为它允许模型在非常细的粒度上减少参数。然而，由于剪枝后权重的分布变得不规则，这可能会导致计算过程中的缓存命中率下降，从而影响运行效率。因此，细粒度剪枝通常需要特定硬件支持，以便有效利用稀疏性。<br><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1714396271434-8414e39e-2418-43db-b6dc-452b234181a0.png" alt="未命名文件(17).png"><br> Exploring the granularity of sparsity in convolutional neural networks [Mao et al., CVPR-W]<br>剪枝工具<br>在深度学习框架如Pytorch和TensorFlow中也提供了剪枝的工具，如Torch-Pruning是开源的PyTorch工具箱，专门用于结构化剪枝，以优化和压缩深度学习模型。Torch-Pruning通过构建依赖图（Dep Graph）自动处理层之间的依赖关系，确保剪枝操作不会破坏模型的结构，示例代码如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">import torch_pruning <span class="hljs-keyword">as</span> tp<br>model=<span class="hljs-operator"> ...</span><br><span class="hljs-operator"></span>DG = tp.<span class="hljs-constructor">DependencyGraph()</span><br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">DG</span>.</span></span>build<span class="hljs-constructor">_dependency(<span class="hljs-params">model</span>, <span class="hljs-params">example_inputs</span>=<span class="hljs-params">torch</span>.<span class="hljs-params">randn</span>(1, 3, 224, 224)</span>)<br>strategy = tp.strategy.<span class="hljs-constructor">L1Strategy()</span><br>pruning_idxs = strategy(model.conv1.weight, amount=<span class="hljs-number">0.4</span>)  # 假设剪枝<span class="hljs-number">40</span>%<br>pruning_plan = <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">DG</span>.</span></span>get<span class="hljs-constructor">_pruning_plan(<span class="hljs-params">model</span>.<span class="hljs-params">conv1</span>, <span class="hljs-params">tp</span>.<span class="hljs-params">prune_conv</span>, <span class="hljs-params">idxs</span>=<span class="hljs-params">pruning_idxs</span>)</span><br>pruning_plan.exec<span class="hljs-literal">()</span><br></code></pre></td></tr></table></figure><p>TensorFlow的剪枝API是TensorFlow Model Optimization Toolkit的一部分，它提供了一种在训练过程中减少模型权重的方法，从而创建一个稀疏的模型。具体如tensorflow_model_optimization.sparsity.keras.prune_low_magnitude是用于实现剪枝操作的函数，它会移除模型中幅度较低的权重。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import tensorflow_model_optimization as tfmot<br>model = <span class="hljs-built_in">..</span>.<br><span class="hljs-comment"># 定义剪枝计划</span><br>pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(<br>    <span class="hljs-attribute">initial_sparsity</span>=0.0, <br>    <span class="hljs-attribute">final_sparsity</span>=0.5,<br>    <span class="hljs-attribute">begin_step</span>=2000, <br>    <span class="hljs-attribute">end_step</span>=4000<br>)<br><span class="hljs-comment"># 应用剪枝</span><br>model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, <span class="hljs-attribute">pruning_schedule</span>=pruning_schedule)<br><span class="hljs-comment"># 继续训练剪枝后的模型</span><br>model_for_pruning.fit(<span class="hljs-built_in">..</span>.)<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>函数式编程与响应式编程</title>
      <link href="/2024/01/15/%E5%87%BD%E6%95%B0%E5%BC%8F%E3%80%81%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
      <url>/2024/01/15/%E5%87%BD%E6%95%B0%E5%BC%8F%E3%80%81%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="编程范式"><a href="#编程范式" class="headerlink" title="编程范式"></a>编程范式</h2><p>编程范式，又称为编程模型，泛指软件编程过程中使用的编程风格，常见的编程范式包括命令式编程（面向对象、面向过程等），声明式编程（响应式、函数式），</p><p><strong>命令式编程</strong> 是面向<strong>计算机硬件</strong>的抽象，有变量、赋值语句、表达式、控制语句等，可以理解为 命令式编程就是<strong>冯诺伊曼的指令序列。</strong> 它的主要思想是关注计算机执行的步骤，即一步一步告诉计算机先做什么再做什么。</p><p><strong>声明式编程</strong> 是以<strong>数据结构</strong>的形式来表达程序执行的逻辑。声明式编程范式关注的焦点不是采用什么算法或者逻辑来解决问题，而是描述、声明解决的问题是什么。当你的代码匹配预先设定好规则，业务逻辑就会被自动触发执行。SQL、HTML 、XML、 CSS 都属于声明式编程。它的特点：1.它不需要创建变量用来存储数据 2.另一个特点是它不包含循环控制的代码。</p><p>如图：</p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240115100548819.png" alt="program" style="zoom:25%;" /><h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><p>函数式编程是面向数学的抽象，将计算描述为一种<strong>表达式求值</strong>，其实，函数式程序就是一个<strong>表达式。</strong>函数式编程中<strong>的</strong>函数并部署指计算机中的函数，而是指数学中的函数，即自变量的映射。函数的值取决于函数的参数的值，不依赖于其他状态，比如abs(x)函数计算x的绝对值，只要x不变，无论何时调用、调用次数，最终的值都是一样。</p><h3 id="核心理念"><a href="#核心理念" class="headerlink" title="核心理念"></a>核心理念</h3><ul><li><p>函数是第一等公民：<strong>函数是第一等公民</strong>：是指函数跟其它的数据类型一样处于平等地位，可以赋值给其他变量，可以作为参数传入另一个函数，也可以作为别的函数的返回值。</p></li><li><p>函数是纯函数：<strong>纯函数</strong>是指相同的输入总会得到相同的输出，并且不会产生副作用的函数。<strong>无副作用</strong> 指的是函数内部的操作不会对外部产生影响（如修改全局变量的值、修改 dom 节点等）。</p></li><li><p>不可变性：没有可变变量、类似代数变量</p></li><li><p>迭代是通过<strong>递归</strong>实现的：没有循环结构</p></li></ul><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul><li><p><strong>确定性</strong>：消除了多线程中的数据竞争问题</p></li><li><p>同一个输入始终产生同一个输出，<strong>结果可缓存、结果可测试</strong></p></li><li><p>只要编译成功，就能成功运行，不受可变性影响</p></li></ul><h3 id="函数合成（compose）"><a href="#函数合成（compose）" class="headerlink" title="函数合成（compose）"></a>函数合成（compose）</h3><p>指的是将代表各个动作的多个函数合并成一个函数。</p><h4 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h4><p><em>在函数式编程中，函数被称为first class，意思是函数与值一样，可以作为<strong>函数参数</strong>传入函数，也可以作为<strong>函数返回值</strong>返回。</em></p><p>高阶函数：将函数作为参数或返回值的函数。</p><h4 id="函数复合"><a href="#函数复合" class="headerlink" title="函数复合"></a>函数复合</h4><p><em>在函数式编程中，函数的复合和数学函数复合概念一致，想法是通过<strong>组合</strong>更小的、更简单的函数构建更大的、更复杂的函数。</em></p><h4 id="嵌套调用与复合运算符"><a href="#嵌套调用与复合运算符" class="headerlink" title="嵌套调用与复合运算符"></a>嵌套调用与复合运算符</h4><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">toString</span> :: <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">String</span><br><span class="hljs-title">toString</span> n = show n<br><span class="hljs-title">toArray</span> :: <span class="hljs-type">String</span> -&gt; <span class="hljs-type">Array</span> <span class="hljs-type">String</span><br><span class="hljs-title">toArray</span> s = &#123;s&#125;<br><span class="hljs-comment">-- 嵌套调用</span><br><span class="hljs-title">intToStringArray</span> :: <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Array</span> <span class="hljs-type">String</span><br><span class="hljs-title">intToStringArray</span> n = toArray(toString n)<br><span class="hljs-comment">-- 等价于左复合</span><br><span class="hljs-title">intToStringArray</span> :: <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Array</span> <span class="hljs-type">String</span><br><span class="hljs-title">intToStringArray</span> n = toArray &lt;&lt;&lt; toString<br><span class="hljs-comment">-- 等价于右复合</span><br><span class="hljs-title">intToStringArray</span> :: <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Array</span> <span class="hljs-type">String</span><br><span class="hljs-title">intToStringArray</span> n = toString &gt;&gt;&gt; toArray<br></code></pre></td></tr></table></figure><h3 id="函数柯里化currying"><a href="#函数柯里化currying" class="headerlink" title="函数柯里化currying"></a>函数柯里化currying</h3><p><strong>函数柯里化又称部分求值</strong>，指的是将多参数函数转换为单参数函数的特性。一个柯里化的函数首先会接受一些参数，接受了这些参数之后，该函数并不会立即求值，而是继续返回另外一个函数，刚才传入的参数在函数形成的闭包中被保存起来。待到函数被真正需要求值的时候，之前传入的所有参数都会被一次性用于求值</p><p><strong>解析</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs haskell">&#x27;&#x27;&#x27; haskell<br><span class="hljs-comment">-- 接受三个INT参数，返回一个INT</span><br><span class="hljs-title">f</span> :: <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span><br><span class="hljs-comment">-- 等价于, 接受一个INT参数，返回一个函数</span><br><span class="hljs-title">f</span> :: <span class="hljs-type">Int</span> -&gt; (<span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span>)<br><span class="hljs-comment">-- 等价于</span><br><span class="hljs-title">f</span> :: <span class="hljs-type">Int</span> -&gt; (<span class="hljs-type">Int</span> -&gt; (<span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span>))<br>&#x27;&#x27;&#x27;<br></code></pre></td></tr></table></figure><p><strong>例子</strong></p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-comment">-- add :: Int -&gt; Int -&gt; Int </span><br><span class="hljs-comment">-- add x y = x + y</span><br><span class="hljs-comment">-- 等价于</span><br><span class="hljs-title">add</span> :: <span class="hljs-type">Int</span> -&gt; (<span class="hljs-type">Int</span> -&gt; <span class="hljs-type">Int</span>)<br><span class="hljs-title">add</span> x y = x + y<br><span class="hljs-comment">-- 调用 </span><br><span class="hljs-title">add</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span><br><span class="hljs-comment">-- 等价于</span><br>(add <span class="hljs-number">1</span>) <span class="hljs-number">2</span><br><span class="hljs-comment">-- add 1 先返回 函数 Int -&gt; Int ,之后使用参数2调用这个函数</span><br><span class="hljs-comment">-- 而不是直接传入两个参数</span><br></code></pre></td></tr></table></figure><h3 id="闭包closure"><a href="#闭包closure" class="headerlink" title="闭包closure"></a>闭包closure</h3><p>函数与其<strong>词法环境</strong>的组合就是闭包。</p><h3 id="lambda函数"><a href="#lambda函数" class="headerlink" title="lambda函数"></a>lambda函数</h3><h4 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h4><ul><li>lambda 函数的语法只包含一个语句，表现形式如下：<br><code>lambda [arg1 [,arg2,.....argn]]:expression</code></li><li>其中，lambda 是 Python 预留的关键字，[arg…] 和 expression 由用户自定义。</li><li>具体介绍如下:<br><strong>[arg…] 是参数列表</strong>，它的结构与 Python 中函数(function)的参数列表是一样的，如下。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a, b<br>a=<span class="hljs-number">1</span>, b=<span class="hljs-number">2</span><br>*args<br>**kwargs<br>a, b=<span class="hljs-number">1</span>, *args<br>空<br>......<br></code></pre></td></tr></table></figure><ul><li><strong>expression 是一个参数表达式</strong>，表达式中出现的参数需要在<code>[arg......]</code>中有定义，并且表达式只能是单行的，只能有一个表达式。</li></ul><h4 id="lambda-特性"><a href="#lambda-特性" class="headerlink" title="lambda 特性"></a>lambda 特性</h4><ul><li><p>lambda 函数是匿名的：所谓匿名函数，通俗地说就是没有名字的函数。lambda函数没有名字。</p></li><li><p>lambda 函数有输入和输出：输入是传入到参数列表argument_list的值，输出是根据表达式expression计算得到的值。</p></li><li><p>lambda 函数拥有自己的命名空间：不能访问自己参数列表之外或全局命名空间里的参数，只能完成非常简单的功能。</p></li></ul><p>常见的lambda函数示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">lambda</span> x, y: x*y<span class="hljs-comment"># 函数输入是x和y，输出是它们的积x*y</span><br><span class="hljs-keyword">lambda</span>:<span class="hljs-literal">None</span><span class="hljs-comment"># 函数没有输入参数，输出是None</span><br><span class="hljs-keyword">lambda</span> *args: <span class="hljs-built_in">sum</span>(args)<span class="hljs-comment"># 输入是任意个数参数，输出是它们的和(隐性要求输入参数必须能进行算术运算)</span><br><span class="hljs-keyword">lambda</span> **kwargs: <span class="hljs-number">1</span><span class="hljs-comment"># 输入是任意键值对参数，输出是1</span><br></code></pre></td></tr></table></figure><h4 id="lambda-常见用法"><a href="#lambda-常见用法" class="headerlink" title="lambda 常见用法"></a>lambda 常见用法</h4><ol><li><p>将lambda函数赋值给一个变量，通过这个变量间接调用该lambda函数。</p><p><code>add = lambda x, y: x+y</code></p></li><li><p>将lambda函数赋值给其他函数，从而将其他函数用该lambda函数替换。</p></li><li><p>将lambda函数作为参数传递给其他函数。</p></li></ol><h2 id="响应式编程"><a href="#响应式编程" class="headerlink" title="响应式编程"></a>响应式编程</h2><p><em>Wikipedia: 在计算中，<strong>响应式编程</strong>或<strong>反应式编程</strong>（英语：Reactive programming）是一种面向数据流和变化传播的声明式编程范式。这意味着可以在编程语言中很方便地表达静态或动态的数据流，而相关的计算模型会自动将变化的值通过数据流进行传播。</em></p><center><b>响应式编程是基于异步数据流构建构建事务关系编程范式</b></center><p>目的：<strong>提高应用程序的性能和可伸缩性，以应对高并发和高负载的场景</strong>。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><strong>观察者模式</strong>（又被称为发布-订阅（Publish&#x2F;Subscribe）模式，属于行为型模式的一种，它定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态变化时，会通知所有的观察者对象，使他们能够自动更新自己。</p><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/v2-8156c5d36b3370bef70fb6fad53cdbfa_r.jpg" alt="img"></p><p>Reactor 中大部分实现都是按照上图的逻辑来执行的：</p><ol><li>首先是Subscriber（订阅者）主动订阅 Publisher（发布者），通过调用 Publisher 的 subscribe 方法</li><li>Publisher 在向下游发送数据之前，会先调用 Subscriber 的 onSubscribe 方法，传递的参数为 Subscription（订阅媒介）</li><li>Subscriber 通过 Subscription#request 来请求数据，或者 Subscription#cancel 来取消数据发布（这就是响应式编程中的背压，订阅者可以控制数据发布）</li><li>Subscription 在接收到订阅者的调用后，通过 Subscriber#onNext 向下游订阅者传递数据。</li><li>在数据发布完成后，调用 Subscriber#onComplete 结束本次流，如果数据发布或者处理遇到错误会调用 Subscriber#onError</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/363757919">什么是「函数式编程」？ - 知乎 (zhihu.com)</a></li><li><a href="https://blog.csdn.net/PY0312/article/details/88956795">Python 之 lambda 函数完整详解 &amp; 巧妙运用_lambda函数python-CSDN博客</a></li><li><a href="https://cloud.tencent.com/developer/article/2099612">从架构师的角度带你把“响应式编程”给一次性搞明白，果然绝绝子-腾讯云开发者社区-腾讯云 (tencent.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/439265017">响应式编程入门之 Project Reactor - 知乎 (zhihu.com)</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 基础概念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP论文复现-paddle指南</title>
      <link href="/2024/01/10/NLP%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0-paddle%E6%8C%87%E5%8D%97/"/>
      <url>/2024/01/10/NLP%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0-paddle%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="论文复现赛指南-NLP方向"><a href="#论文复现赛指南-NLP方向" class="headerlink" title="论文复现赛指南-NLP方向"></a>论文复现赛指南-NLP方向</h1><p>本文为针对 <code>NLP</code> 方向的复现赛指南</p><h2 id="1-总览"><a href="#1-总览" class="headerlink" title="1. 总览"></a>1. 总览</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><ul><li><p>以深度学习为核心的人工智能技术仍在高速发展，通过论文复现，开发者可以获得 </p></li><li><ul><li>学习成长：自我能力提升</li><li>技术积累：对科研或工作有所帮助和启发</li><li>社区荣誉：成果被开发者广泛使用</li></ul></li></ul><h3 id="1-2-前序工作"><a href="#1-2-前序工作" class="headerlink" title="1.2 前序工作"></a>1.2 前序工作</h3><p>基于本指南复现论文过程中，建议开发者准备以下内容。</p><ul><li><p>了解该模型输入输出格式。以BERT的情感分类任务为例，通过阅读论文与参考代码，了解到模型输入为<code>[batch_size, sequence_length]</code>的tensor，类型为<code>int64</code>，label为<code>[batch, ]</code>的label，类型为<code>int64</code>。</p></li><li><p>准备好训练&#x2F;验证数据集，用于模型训练与评估</p></li><li><p>准备好fake input data以及label，与模型输入shape、type等保持一致，用于后续模型前向对齐。 </p></li><li><ul><li>在对齐模型前向过程中，我们不需要考虑数据集模块等其他模块，此时使用fake data是将模型结构和数据部分解耦非常合适的一种方式。</li><li>将fake data以文件的形式存储下来，也可以保证PaddlePaddle与参考代码的模型结构输入是完全一致的，更便于排查问题。</li><li>在该步骤中，以BERT为例，生成fake data的脚本可以参考：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/fake_data/gen_fake_data.py">gen_fake_data.py</a>。</li></ul></li><li><p>在特定设备(CPU&#x2F;GPU)上，跑通参考代码的预测过程(前向)以及至少2轮(iteration)迭代过程，保证后续基于PaddlePaddle复现论文过程中可对比。</p></li><li><p>本文档基于 <code>BERT-SST2-Prod</code> 代码以及<code>reprod_log</code> whl包进行说明与测试。如果希望体验，建议参考<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/README.md">BERT-SST2-Prod文档</a>进行安装与测试。</p></li><li><p>在复现的过程中，只需要将PaddlePaddle的复现代码以及打卡日志上传至github，不能在其中添加<code>参考代码的实现</code>，在验收通过之后，需要删除打卡日志。建议在初期复现的时候，就将<strong>复现代码与参考代码分成2个文件夹进行管理</strong>。</p></li><li><p>飞桨训推一体认证 (Training and Inference Pipeline Certification, TIPC) 是一个针对飞桨模型的测试工具，方便用户查阅每种模型的训练推理部署打通情况，并可以进行一键测试。论文训练对齐之后，需要为代码接入TIPC基础链条测试文档与代码，关于TIPC基础链条测试接入规范的文档可以参考：<a href="https://github.com/PaddlePaddle/models/blob/tipc/docs/tipc_test/development_specification_docs/train_infer_python.md">链接</a>。更多内容在<code>3.13</code>章节部分也会详细说明。</p></li></ul><h2 id="2-整体框图"><a href="#2-整体框图" class="headerlink" title="2. 整体框图"></a>2. 整体框图</h2><h3 id="2-1-流程概览"><a href="#2-1-流程概览" class="headerlink" title="2.1 流程概览"></a>2.1 流程概览</h3><p>面对一篇自然语言处理的论文，复现该论文的整体流程如下图所示。</p><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1704852475151-da141b98-07da-437c-93fc-ca4c416e33ec.png" alt="img"></p><p>总共包含12个步骤。为了高效复现论文，设置了6个验收节点。如上图中黄色框所示。后续章节会详细介绍上述步骤和验收节点，具体内容安排如下：</p><ul><li>第3章：介绍12个复现步骤的理论知识、实战以及验收流程。</li><li>第4章：针对复现流程过程中每个步骤可能出现的问题，本章会进行详细介绍。</li></ul><h3 id="2-2-reprod-log-whl包"><a href="#2-2-reprod-log-whl包" class="headerlink" title="2.2 reprod_log whl包"></a>2.2 reprod_log whl包</h3><h4 id="2-2-1-reprod-log工具简介"><a href="#2-2-1-reprod-log工具简介" class="headerlink" title="2.2.1 reprod_log工具简介"></a>2.2.1 reprod_log工具简介</h4><p><code>reprod_log</code>是用于论文复现赛中辅助自查和验收工具。该工具源代码地址在：<a href="https://github.com/WenmuZhou/reprod_log%E3%80%82%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD%E5%A6%82%E4%B8%8B%EF%BC%9A">https://github.com/WenmuZhou/reprod_log。主要功能如下：</a></p><ul><li>存取指定节点的输入输出tensor</li><li>基于文件的tensor读写</li><li>2个字典的对比验证</li><li>对比结果的输出与记录</li></ul><p>更多API与使用方法可以参考：<a href="https://github.com/WenmuZhou/reprod_log/blob/master/README.md">reprod_log API使用说明</a>。</p><h4 id="2-2-2-reprod-log使用demo"><a href="#2-2-2-reprod-log使用demo" class="headerlink" title="2.2.2 reprod_log使用demo"></a>2.2.2 reprod_log使用demo</h4><p>下面基于代码：<a href="https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline/reprod_log_demo%EF%BC%8C%E7%BB%99%E5%87%BA%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%A5%E5%B7%A5%E5%85%B7%E3%80%82">https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline/reprod_log_demo，给出如何使用该工具。</a></p><p>文件夹中包含<code>write_log.py</code>和<code>check_log_diff.py</code>文件，其中<code>write_log.py</code>中给出了<code>ReprodLogger</code>类的使用方法，<code>check_log_diff.py</code>给出了<code>ReprodDiffHelper</code>类的使用方法，依次运行两个python文件，使用下面的方式运行代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">进入文件夹</span><br>cd pipeline/reprod_log_demo<br><span class="hljs-meta prompt_"># </span><span class="language-bash">随机生成矩阵，写入文件中</span><br>python write_log.py<br><span class="hljs-meta prompt_"># </span><span class="language-bash">进行文件对比，输出日志</span><br>python check_log_diff.py<br></code></pre></td></tr></table></figure><p>最终会输出以下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">[2021/11/18 09:29:31] root INFO: demo_test_1:<br>[2021/11/18 09:29:31] root INFO:     mean diff: check passed: True, value: 0.0<br>[2021/11/18 09:29:31] root INFO: demo_test_2:<br>[2021/11/18 09:29:31] root INFO:     mean diff: check passed: False, value: 0.33387675881385803<br>[2021/11/18 09:29:31] root INFO: diff check failed<br></code></pre></td></tr></table></figure><p>可以看出：对于key为<code>demo_test_1</code>的矩阵，由于diff为0，小于设置的阈值<code>1e-6</code>，核验成功；对于key为<code>demo_test_2</code>的矩阵，由于diff为0.33，大于设置的阈值<code>1e-6</code>，核验失败。</p><h4 id="2-2-3-reprod-log在论文复现中应用"><a href="#2-2-3-reprod-log在论文复现中应用" class="headerlink" title="2.2.3 reprod_log在论文复现中应用"></a>2.2.3 reprod_log在论文复现中应用</h4><p>在论文复现中，基于reprod_log的结果记录模块，产出下面若干文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plain">log_reprod<br>├── forward_paddle.npy<br>├── forward_torch.npy    # 与forward_paddle.npy作为一并核查的文件对<br>├── metric_paddle.npy<br>├── metric_torch.npy     # 与metric_paddle.npy作为一并核查的文件对<br>├── loss_paddle.npy<br>├── loss_torch.npy       # 与loss_paddle.npy作为一并核查的文件对<br>├── bp_align_paddle.npy<br>├── bp_align_torch.npy   # 与bp_align_paddle.npy作为一并核查的文件对<br>├── train_align_paddle.npy<br>├── train_align_torch.npy # pytorch运行得到的参考评估指标<br></code></pre></td></tr></table></figure><p>基于reprod_log的<code>ReprodDiffHelper</code>模块，产出下面5个日志文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">├── forward_diff.log     # forward_paddle.npy与forward_torch.npy生成的diff结果文件<br>├── metric_diff.log      # metric_paddle.npy与metric_torch.npy生成的diff结果文件<br>├── loss_diff.log          # loss_paddle.npy与loss_torch.npy生成的diff结果文件<br>├── bp_align_diff.log    # bp_align_paddle.npy与bp_align_torch.npy生成的diff结果文件<br>├── train_align_diff.log # train_align_paddle.train_align_torch.npy生成的diff结果文件<br></code></pre></td></tr></table></figure><p>上述文件的生成代码都需要开发者进行开发，验收时需要提供上面罗列的所有文件（不需要提供产生这些文件的可运行程序）以及完整的模型训练评估程序和日志。</p><p>BERT-SST2-Prod项目提供了基于reprod_log的5个验收点对齐验收示例，具体代码地址为：<a href="https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E7%9A%84README.md%E6%96%87%E6%A1%A3%E6%8F%90%E4%BE%9B%E4%BA%86%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E3%80%82">https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline，每个文件夹中的README.md文档提供了使用说明。</a></p><p>InsightFace项目中提供了<code>TIPC基础链条验收点</code>的验收示例，参考代码地址为：<a href="https://github.com/deepinsight/insightface/blob/master/recognition/arcface_paddle/test_tipc/readme.md%EF%BC%8C%E6%9B%B4%E5%A4%9A%E5%85%B3%E4%BA%8ETIPC%E5%9F%BA%E7%A1%80%E9%93%BE%E6%9D%A1%E6%B5%8B%E8%AF%95%E6%8E%A5%E5%85%A5%E8%A7%84%E8%8C%83%E7%9A%84%E4%BB%A3%E7%A0%81%E5%8F%AF%E4%BB%A5%E5%8F%82%E8%80%83%EF%BC%9Ahttps://github.com/PaddlePaddle/models/blob/tipc/docs/tipc_test/development_specification_docs/train_infer_python.md">https://github.com/deepinsight/insightface/blob/master/recognition/arcface_paddle/test_tipc/readme.md，更多关于TIPC基础链条测试接入规范的代码可以参考：https://github.com/PaddlePaddle/models/blob/tipc/docs/tipc_test/development_specification_docs/train_infer_python.md</a></p><h2 id="3-论文复现理论知识及实战"><a href="#3-论文复现理论知识及实战" class="headerlink" title="3. 论文复现理论知识及实战"></a>3. 论文复现理论知识及实战</h2><h3 id="3-1-模型结构对齐"><a href="#3-1-模型结构对齐" class="headerlink" title="3.1 模型结构对齐"></a>3.1 模型结构对齐</h3><p>对齐模型结构时，一般有3个主要步骤：</p><ul><li>网络结构代码转换</li><li>权重转换</li><li>模型组网正确性验证</li></ul><p>下面详细介绍这3个部分。</p><h4 id="3-1-1-网络结构代码转换"><a href="#3-1-1-网络结构代码转换" class="headerlink" title="3.1.1 网络结构代码转换"></a>3.1.1 网络结构代码转换</h4><p><strong>【基本流程】</strong></p><p>由于PyTorch的API和PaddlePaddle的API非常相似，可以参考<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">PyTorch-PaddlePaddle API映射表</a><br>，组网部分代码直接进行手动转换即可。</p><p><strong>【实战】</strong></p><p>BERT网络结构的PyTorch实现: <a href="https://github.com/huggingface/transformers/blob/master/src/transformers/models/bert/modeling_bert.py">transformers-bert</a></p><p>对应转换后的PaddlePaddle实现: <a href="https://github.com/PaddlePaddle/PaddleNLP/blob/develop/paddlenlp/transformers/bert/modeling.py">paddlenlp-bert</a></p><h4 id="3-1-2-权重转换"><a href="#3-1-2-权重转换" class="headerlink" title="3.1.2 权重转换"></a>3.1.2 权重转换</h4><p><strong>【基本流程】</strong></p><p>组网代码转换完成之后，需要对模型权重进行转换，如果PyTorch repo中已经提供权重，那么可以直接下载并进行后续的转换；如果没有提供，则可以基于PyTorch代码，随机生成一个初始化权重(定义完model以后，使用<code>torch.save()</code> API保存模型权重)，然后进行权重转换。</p><p><strong>【注意事项】</strong></p><p>在权重转换的时候，需要注意<code>paddle.nn.Linear</code>以及<code>paddle.nn.BatchNorm2D</code>等API的权重保存格式和名称等与PyTorch稍有diff，具体内容可以参考<code>4.1章节</code>。</p><p><strong>【实战】</strong></p><p>BERT的代码转换脚本可以在这里查看：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/weights/torch2paddle.py%EF%BC%8C">https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/weights/torch2paddle.py，</a></p><p>注意：运行该代码需要首先下载Huggingface的BERT预训练模型到该目录下，下载地址为：<a href="https://huggingface.co/bert-base-uncased/blob/main/pytorch_model.bin">https://huggingface.co/bert-base-uncased/blob/main/pytorch_model.bin</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/weights/torch2paddle.py</span><br><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> paddlenlp.transformers <span class="hljs-keyword">import</span> BertForPretraining <span class="hljs-keyword">as</span> PDBertForMaskedLM<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertForMaskedLM <span class="hljs-keyword">as</span> PTBertForMaskedLM<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_pytorch_checkpoint_to_paddle</span>(<span class="hljs-params"></span><br><span class="hljs-params">        pytorch_checkpoint_path=<span class="hljs-string">&quot;pytorch_model.bin&quot;</span>,</span><br><span class="hljs-params">        paddle_dump_path=<span class="hljs-string">&quot;model_state.pdparams&quot;</span>,</span><br><span class="hljs-params">        version=<span class="hljs-string">&quot;old&quot;</span>, </span>):<br>    hf_to_paddle = &#123;<br>        <span class="hljs-string">&quot;embeddings.LayerNorm&quot;</span>: <span class="hljs-string">&quot;embeddings.layer_norm&quot;</span>,<br>        <span class="hljs-string">&quot;encoder.layer&quot;</span>: <span class="hljs-string">&quot;encoder.layers&quot;</span>,<br>        <span class="hljs-string">&quot;attention.self.query&quot;</span>: <span class="hljs-string">&quot;self_attn.q_proj&quot;</span>,<br>        <span class="hljs-string">&quot;attention.self.key&quot;</span>: <span class="hljs-string">&quot;self_attn.k_proj&quot;</span>,<br>        <span class="hljs-string">&quot;attention.self.value&quot;</span>: <span class="hljs-string">&quot;self_attn.v_proj&quot;</span>,<br>        <span class="hljs-string">&quot;attention.output.dense&quot;</span>: <span class="hljs-string">&quot;self_attn.out_proj&quot;</span>,<br>        <span class="hljs-string">&quot;intermediate.dense&quot;</span>: <span class="hljs-string">&quot;linear1&quot;</span>,<br>        <span class="hljs-string">&quot;output.dense&quot;</span>: <span class="hljs-string">&quot;linear2&quot;</span>,<br>        <span class="hljs-string">&quot;attention.output.LayerNorm&quot;</span>: <span class="hljs-string">&quot;norm1&quot;</span>,<br>        <span class="hljs-string">&quot;output.LayerNorm&quot;</span>: <span class="hljs-string">&quot;norm2&quot;</span>,<br>        <span class="hljs-string">&quot;predictions.decoder.&quot;</span>: <span class="hljs-string">&quot;predictions.decoder_&quot;</span>,<br>        <span class="hljs-string">&quot;predictions.transform.dense&quot;</span>: <span class="hljs-string">&quot;predictions.transform&quot;</span>,<br>        <span class="hljs-string">&quot;predictions.transform.LayerNorm&quot;</span>: <span class="hljs-string">&quot;predictions.layer_norm&quot;</span>,<br>    &#125;<br>    do_not_transpose = []<br>    <span class="hljs-keyword">if</span> version == <span class="hljs-string">&quot;old&quot;</span>:<br>        hf_to_paddle.update(&#123;<br>            <span class="hljs-string">&quot;predictions.bias&quot;</span>: <span class="hljs-string">&quot;predictions.decoder_bias&quot;</span>,<br>            <span class="hljs-string">&quot;.gamma&quot;</span>: <span class="hljs-string">&quot;.weight&quot;</span>,<br>            <span class="hljs-string">&quot;.beta&quot;</span>: <span class="hljs-string">&quot;.bias&quot;</span>,<br>        &#125;)<br>        do_not_transpose = do_not_transpose + [<span class="hljs-string">&quot;predictions.decoder.weight&quot;</span>]<br><br>    pytorch_state_dict = torch.load(<br>        pytorch_checkpoint_path, map_location=<span class="hljs-string">&quot;cpu&quot;</span>)<br>    paddle_state_dict = OrderedDict()<br>    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> pytorch_state_dict.items():<br>        is_transpose = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">if</span> k[-<span class="hljs-number">7</span>:] == <span class="hljs-string">&quot;.weight&quot;</span>:<br>            <span class="hljs-comment"># embeddings.weight and LayerNorm.weight do not transpose</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">all</span>(d <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> do_not_transpose):<br>                <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;.embeddings.&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;.LayerNorm.&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k:<br>                    <span class="hljs-keyword">if</span> v.ndim == <span class="hljs-number">2</span>:<br>                        v = v.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>                        is_transpose = <span class="hljs-literal">True</span><br>        oldk = k<br>        <span class="hljs-keyword">for</span> hf_name, pd_name <span class="hljs-keyword">in</span> hf_to_paddle.items():<br>            k = k.replace(hf_name, pd_name)<br><br>        <span class="hljs-comment"># add prefix `bert.`</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;bert.&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;cls.&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;classifier&quot;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> k:<br>            k = <span class="hljs-string">&quot;bert.&quot;</span> + k<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Converting: <span class="hljs-subst">&#123;oldk&#125;</span> =&gt; <span class="hljs-subst">&#123;k&#125;</span> | is_transpose <span class="hljs-subst">&#123;is_transpose&#125;</span>&quot;</span>)<br>        paddle_state_dict[k] = v.data.numpy()<br><br>    paddle.save(paddle_state_dict, paddle_dump_path)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compare</span>(<span class="hljs-params">out_torch, out_paddle</span>):<br>    out_torch = out_torch.detach().numpy()<br>    out_paddle = out_paddle.detach().numpy()<br>    <span class="hljs-keyword">assert</span> out_torch.shape == out_paddle.shape<br>    abs_dif = np.<span class="hljs-built_in">abs</span>(out_torch - out_paddle)<br>    mean_dif = np.mean(abs_dif)<br>    max_dif = np.<span class="hljs-built_in">max</span>(abs_dif)<br>    min_dif = np.<span class="hljs-built_in">min</span>(abs_dif)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mean_dif:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(mean_dif))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;max_dif:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(max_dif))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;min_dif:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(min_dif))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_forward</span>():<br>    paddle.set_device(<span class="hljs-string">&quot;cpu&quot;</span>)<br>    model_torch = PTBertForMaskedLM.from_pretrained(<span class="hljs-string">&quot;./bert-base-uncased&quot;</span>)<br>    model_paddle = PDBertForMaskedLM.from_pretrained(<span class="hljs-string">&quot;./bert-base-uncased&quot;</span>)<br>    model_torch.<span class="hljs-built_in">eval</span>()<br>    model_paddle.<span class="hljs-built_in">eval</span>()<br>    np.random.seed(<span class="hljs-number">42</span>)<br>    x = np.random.randint(<br>        <span class="hljs-number">1</span>, model_paddle.bert.config[<span class="hljs-string">&quot;vocab_size&quot;</span>], size=(<span class="hljs-number">4</span>, <span class="hljs-number">64</span>))<br>    input_torch = torch.tensor(x, dtype=torch.int64)<br>    out_torch = model_torch(input_torch)[<span class="hljs-number">0</span>]<br><br>    input_paddle = paddle.to_tensor(x, dtype=paddle.int64)<br>    out_paddle = model_paddle(input_paddle)[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;torch result shape:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(out_torch.shape))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;paddle result shape:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(out_paddle.shape))<br>    compare(out_torch, out_paddle)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    convert_pytorch_checkpoint_to_paddle(<br>        <span class="hljs-string">&quot;./bert-base-uncased/pytorch_model.bin&quot;</span>,<br>        <span class="hljs-string">&quot;./bert-base-uncased/model_state.pdparams&quot;</span>)<br>    test_forward()<br>    <span class="hljs-comment"># torch result shape:torch.Size([4, 64, 30522])</span><br>    <span class="hljs-comment"># paddle result shape:[4, 64, 30522]</span><br>    <span class="hljs-comment"># mean_dif:1.666686512180604e-05</span><br>    <span class="hljs-comment"># max_dif:0.00015211105346679688</span><br>    <span class="hljs-comment"># min_dif:0.0</span><br></code></pre></td></tr></table></figure><p>运行完成之后，会在当前目录生成<code>model_state.pdparams</code>文件，即为转换后的PaddlePaddle预训练模型。<br><strong>Tips</strong>: 由于paddlenlp中已有转换后的bert-base-uncased模型，因此可以一键加载，程序会自动下载对应权重！</p><h4 id="3-1-3-模型组网正确性验证"><a href="#3-1-3-模型组网正确性验证" class="headerlink" title="3.1.3 模型组网正确性验证"></a>3.1.3 模型组网正确性验证</h4><p><strong>【基本流程】</strong></p><ol><li>定义PyTorch模型，加载权重，固定seed，基于numpy生成随机数，转换为PyTorch可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li><li>定义PaddlePaddle模型，加载权重，固定seed，基于numpy生成随机数，转换为PaddlePaddle可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li>模型在前向对齐验证时，需要调用<code>model.eval()</code>方法，保证组网中的随机量被关闭，比如BatchNorm、Dropout等。</li><li>给定相同的输入数据，为保证可复现性，如果有随机数生成，固定相关的随机种子。</li><li>输出diff可以使用<code>np.mean(np.abs(o1 - o2))</code>进行计算，一般小于1e-6的话，可以认为前向没有问题。如果最终输出结果diff较大，可以使用二分的方法进行排查，比如说BERT，包含1个embdding层、12个transformer-block以及最后的MLM head层，那么完成模型组网和权重转换之后，如果模型输出没有对齐，可以尝试输出中间某一个transformer-block的tensor进行对比，如果相同，则向后进行排查；如果不同，则继续向前进行排查，以此类推，直到找到导致没有对齐的操作。</li></ul><p><strong>【实战】</strong></p><p>BERT模型组网正确性验证可以参考如下示例代码：<br><a href="https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline/Step1">https://github.com/JunnYu/BERT-SST2-Prod/tree/main/pipeline/Step1</a></p><p><strong>【验收】</strong></p><p>对于待复现的项目，前向对齐验收流程如下。</p><ol><li>准备输入：fake data</li></ol><ul><li><ul><li>使用参考代码的dataloader，生成一个batch的数据，保存下来，在前向对齐时，直接从文件中读入。</li><li>固定随机数种子，生成numpy随机矩阵，转化tensor</li></ul></li></ul><ol><li>保存输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为tensor的值。最后将dict保存到文件中。建议命名为<code>forward_paddle.npy</code>和<code>forward_torch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>forward_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：新建文件夹，将<code>forward_paddle.npy</code>、<code>forward_torch.npy</code>与<code>forward_diff_log.txt</code>文件放在文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>PaddlePaddle与PyTorch保存的dict的key需要保持相同，否则report过程可能会提示key无法对应，从而导致report失败，之后的<code>【验收】</code>环节也是如此。</li><li>如果是固定随机数种子，建议将fake data保存到dict中，方便check参考代码和PaddlePaddle的输入是否一致。</li></ul></li></ul><h3 id="3-2-验证-测试集数据读取对齐"><a href="#3-2-验证-测试集数据读取对齐" class="headerlink" title="3.2 验证&#x2F;测试集数据读取对齐"></a>3.2 验证&#x2F;测试集数据读取对齐</h3><p><strong>【基本流程】</strong></p><p>对于一个数据集，一般有以下一些信息需要重点关注</p><ul><li>数据集名称、下载地址</li><li>训练集&#x2F;验证集&#x2F;测试集</li></ul><p>PaddlePaddle中数据集相关的API为<code>paddle.io.Dataset</code>，PyTorch中对应为<code>torch.utils.data.Dataset</code>，二者功能一致，在绝大多数情况下，可以使用该类构建数据集。它是描述Dataset方法和行为的抽象类，在具体实现的时候，需要继承这个基类，实现其中的<code>__getitem__</code>和<code>__len__</code>方法。除了参考代码中相关实现，也可以参考待复现论文中的说明。</p><p>复现完Dataset之后，可以构建Dataloader，对数据进行组batch、批处理，送进网络进行计算。</p><p><code>paddle.io.DataLoader</code>可以进行数据加载，将数据分成批数据，并提供加载过程中的采样。PyTorch对应的实现为<code>torch.utils.data.DataLoader</code>，二者在功能上一致，只是在参数方面稍有diff：（1）PaddlePaddle缺少对<code>pin_memory</code>等参数的支持；（2）PaddlePaddle增加了<code>use_shared_memory</code>参数来选择是否使用共享内存加速数据加载过程。</p><p><strong>【注意事项】</strong></p><p>论文中一般会提供数据集的名称以及基本信息。复现过程中，我们在下载完数据之后，建议先检查下是否和论文中描述一致，否则可能存在的问题有：</p><ul><li>数据集版本不同，比如论文中使用了cnn_dailymail的v3.0.0版本数据集，但是我们下载的是cnn_dailymail的v1.0.0版本数据集，如果不对其进行检查，可能会导致我们最终训练的数据量等与论文中有diff</li><li>数据集使用方式不同，有些论文中，可能只是抽取了该数据集的子集进行方法验证，此时需要注意抽取方法，需要保证抽取出的子集完全相同。</li><li>在评估指标对齐时，我们可以固定batch size，关闭Dataloader的shuffle操作。</li></ul><p>构建数据集时，可以使用PaddleNLP中的数据集加载方式，具体可以参考：<a href="https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html">如何自定义数据集</a>。对应地，PyTorch中的数据处理api可以参考：<a href="https://huggingface.co/docs/datasets/about_dataset_load.html#building-a-dataset">huggingface的datasets自定义数据集</a>。对于其中之一，可以找到另一个平台的实现。</p><p>此外，</p><ul><li>有些自定义的数据处理方法，如果不涉及到深度学习框架的部分，可以直接复用。</li><li>对于特定任务中的数据预处理方法，比如说Tokenizer，如果没有现成的API可以调用，可以参考PaddleNLP套件中的一些实现方法，比如<code>BertTokenizer</code>, <code>XLNetTokenizer</code>等。</li></ul><p><strong>【实战】</strong></p><p>BERT模型复现过程中，数据预处理和Dataset、Dataloader的检查可以参考该文件：<br><a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step2/test_data.py">https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step2/test_data.py</a></p><p>使用方法可以参考<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step2/README.md">数据检查文档</a>。</p><h3 id="3-3-评估指标对齐"><a href="#3-3-评估指标对齐" class="headerlink" title="3.3 评估指标对齐"></a>3.3 评估指标对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle提供了一系列Metric计算类，比如说<code>Accuracy</code>, <code>Auc</code>, <code>Precision</code>, <code>Recall</code>等，而PyTorch中，目前可以通过组合的方式实现metric计算，或者调用<a href="https://huggingface.co/docs/datasets/about_metrics.html?highlight=metric">huggingface-datasets</a>，在论文复现的过程中，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。具体流程如下。</p><ol><li>构建fake数据</li><li>使用PyTorch的指标获取评估结果，使用reprod_log保存结果。</li><li>使用PaddlePaddle的指标获取评估结果，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><p>在评估指标对齐之前，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。</p><p><strong>【实战】</strong></p><p>评估指标对齐检查方法可以参考文档：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step2/README.md#%E6%95%B0%E6%8D%AE%E8%AF%84%E4%BC%B0%E5%AF%B9%E9%BD%90%E6%B5%81%E7%A8%8B">评估指标对齐检查方法文档</a></p><p><strong>【验收】</strong></p><p>对于待复现的项目，评估指标对齐验收流程如下。</p><ol><li>输入：dataloader, model</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>metric_paddle.npy</code>和<code>metric_torch.npy</code>。</li><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>metric_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li></ul></li></ul><ol><li>提交内容：将<code>metric_paddle.npy</code>、<code>metric_torch.npy</code>与<code>metric_diff_log.txt</code>文件备份到<code>3.1节验收环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>数据需要是真实数据</li><li>需要检查论文是否只是抽取了验证集&#x2F;测试集中的部分文件，如果是的话，则需要保证PaddlePaddle和参考代码中dataset使用的数据集一致。</li></ul></li></ul><h3 id="3-4-损失函数对齐"><a href="#3-4-损失函数对齐" class="headerlink" title="3.4 损失函数对齐"></a>3.4 损失函数对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle与PyTorch均提供了很多loss function，用于模型训练，具体的API映射表可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html#lossapi">Loss类API映射列表</a>。以CrossEntropyLoss为例，主要区别为：</p><ul><li>PaddlePaddle提供了对软标签、指定softmax计算纬度的支持。</li></ul><p>如果论文中使用的loss function没有指定的API，则可以尝试通过组合API的方式，实现自定义的loss function。</p><p>具体流程如下。</p><ol><li>定义PyTorch模型，加载权重，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PyTorch可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li><li>定义PaddlePaddle模型，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PaddlePaddle可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li>计算loss的时候，建议设置<code>model.eval()</code>，避免模型中随机量的问题。</li></ul><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step3/README.md%E3%80%82">https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step3/README.md。</a></p><p><strong>【验收】</strong></p><p>对于待复现的项目，损失函数对齐验收流程如下。</p><ol><li>输入：fake data &amp; label</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>loss_paddle.npy</code>和<code>loss_torch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>loss_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>loss_paddle.npy</code>、<code>loss_torch.npy</code>与<code>loss_diff_log.txt</code>文件备份到<code>3.1节验收环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li></ol><h3 id="3-5-优化器对齐"><a href="#3-5-优化器对齐" class="headerlink" title="3.5 优化器对齐"></a>3.5 优化器对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle中的optimizer有<code>paddle.optimizer</code>等一系列实现，PyTorch中则有<code>torch.Optim</code>等一系列实现。</p><p><strong>【注意事项】</strong></p><p>以SGD等优化器为例，PaddlePaddle与Pytorch的优化器区别主要如下。</p><ul><li>PaddlePaddle在优化器中增加了对梯度裁剪的支持，在训练GAN或者一些NLP、多模态任务中，这个用到的比较多。</li><li>PaddlePaddle的SGD不支持动量更新、动量衰减和Nesterov动量，这里需要使用<code>paddle.optimizer.Momentum</code> API实现这些功能。</li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html">PaddlePaddle优化器API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p><h3 id="3-6-学习率对齐"><a href="#3-6-学习率对齐" class="headerlink" title="3.6 学习率对齐"></a>3.6 学习率对齐</h3><p><strong>【基本流程】</strong></p><ul><li>学习率策略主要用于指定训练过程中的学习率变化曲线，这里可以将定义好的学习率策略，不断step，即可得到对应的学习率值，可以将学习率值保存在列表或者矩阵中，使用<code>reprod_log</code>工具判断二者是否对齐。</li></ul><p><strong>【注意事项】</strong></p><p>PaddlePaddle中，需要首先构建学习率策略，再传入优化器对象中；对于PyTorch，如果希望使用更丰富的学习率策略，需要先构建优化器，再传入学习率策略类API。</p><p><strong>【实战】</strong></p><p>学习率复现对齐，可以参考代码：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step4/README.md#%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%B9%E9%BD%90%E9%AA%8C%E8%AF%81">学习率对齐验证文档</a>。</p><h3 id="3-7-正则化策略对齐"><a href="#3-7-正则化策略对齐" class="headerlink" title="3.7 正则化策略对齐"></a>3.7 正则化策略对齐</h3><p><strong>【基本流程】</strong></p><p>L2正则化策略用于模型训练，可以防止模型对训练数据过拟合，L1正则化可以用于得到稀疏化的权重矩阵，PaddlePaddle中有<code>paddle.regularizer.L1Decay</code>与<code>paddle.regularizer.L2Decay</code> API。PyTorch中，torch.optim集成的优化器只有L2正则化方法，直接在构建optimizer的时候，传入<code>weight_decay</code>参数即可。</p><p><strong>【注意事项】</strong></p><ul><li>PaddlePaddle的optimizer中支持L1Decay&#x2F;L2Decay。</li><li>PyTorch的optimizer支持不同参数列表的学习率分别设置，params传入字典即可，而PaddlePaddle的2.1.0版本目前尚未支持这种行为，可以通过设置<code>ParamAttr</code>的<code>learning_rate</code>参数，来确定相对学习率倍数。PaddlePaddle的2.2.0版本中虽然实现该功能，但是模型收敛速度较慢，不建议使用。<a href="https://github.com/PaddlePaddle/Paddle/issues/36915">优化器收敛速度慢</a></li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/regularizer/L2Decay_cn.html">PaddlePaddle正则化API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p><h3 id="3-8-反向对齐"><a href="#3-8-反向对齐" class="headerlink" title="3.8 反向对齐"></a>3.8 反向对齐</h3><p><strong>【基本流程】</strong></p><p>此处可以通过numpy生成假的数据和label（推荐），也可以准备固定的真实数据。具体流程如下。</p><ol><li>检查两个代码的训练超参数全部一致，如优化器及其超参数、学习率、BatchNorm&#x2F;LayerNorm中的eps等。</li><li>将PaddlePaddle与PyTorch网络中涉及的所有随机操作全部关闭，如dropout、drop_path等，推荐将模型设置为eval模式（<code>model.eval()</code>）</li><li>加载相同的weight dict（可以通过PyTorch来存储随机的权重），将准备好的数据分别传入网络并迭代，观察二者loss是否一致（此处batch-size要一致，如果使用多个真实数据，要保证传入网络的顺序一致）</li><li>如果经过2轮以上，loss均可以对齐，则基本可以认为反向对齐。</li></ol><p><strong>【注意事项】</strong></p><ul><li>如果第一轮loss就没有对齐，则需要仔细排查一下模型前向部分。</li><li>如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证并反馈。</li></ul><p>梯度的打印方法示例代码如下所示，注释掉的内容即为打印网络中所有参数的梯度shape。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 代码地址：https://github.com/JunnYu/BERT-SST2-Prod/blob/2c372656bb1b077b0073c50161771d9fa9d8de5a/pipeline/Step4/test_bp.py#L12</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pd_train_some_iters</span>(<span class="hljs-params">model,</span><br><span class="hljs-params">                    criterion,</span><br><span class="hljs-params">                    optimizer,</span><br><span class="hljs-params">                    fake_data,</span><br><span class="hljs-params">                    fake_label,</span><br><span class="hljs-params">                    max_iter=<span class="hljs-number">2</span></span>):<br>    model = PDBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, num_classes=<span class="hljs-number">2</span>)<br>    classifier_weights = paddle.load(<span class="hljs-string">&quot;../classifier_weights/paddle_classifier_weights.bin&quot;</span>)<br>    model.load_dict(classifier_weights)<br>    model.<span class="hljs-built_in">eval</span>()<br>    criterion = paddle.nn.CrossEntropy()<br>    decay_params = [<br>        p.name <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> model.named_parameters()<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;bias&quot;</span>, <span class="hljs-string">&quot;norm&quot;</span>])<br>    ]<br>    optimizer = paddle.optimizer.AdamW(learning_rate=<span class="hljs-number">3e-5</span>, parameters=model.parameters(),<br>        weight_decay=<span class="hljs-number">1e-2</span>,<br>        epsilon=<span class="hljs-number">1e-6</span>,<br>        apply_decay_param_fun=<span class="hljs-keyword">lambda</span> x: x <span class="hljs-keyword">in</span> decay_params)<br>    loss_list = []<br>    <span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iter):<br>        input_ids = paddle.to_tensor(fake_data)<br>        labels = paddle.to_tensor(fake_label)<br><br>        output = model(input_ids)<br>        loss = criterion(output, labels)<br>        loss.backward()<br>        optimizer.step()<br>        optimizer.clear_grad()<br>        loss_list.append(loss)<br>    <span class="hljs-keyword">return</span> loss_list<br></code></pre></td></tr></table></figure><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step4/README.md#%E5%8F%8D%E5%90%91%E5%AF%B9%E9%BD%90%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95">反向对齐操作文档</a>。</p><p><strong>【验收】</strong></p><p>对于待复现的项目，反向对齐验收流程如下。</p><ol><li>输入：fake data &amp; label</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体loss的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>bp_align_paddle.npy</code>和<code>bp_align_torch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>bp_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>bp_align_paddle.npy</code>、<code>bp_align_torch.npy</code>与<code>bp_align_diff_log.txt</code>文件备份到<code>3.1节验收环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>loss需要保存至少2轮以上。</li><li>在迭代的过程中，需要保证模型的batch size等超参数完全相同</li><li>在迭代的过程中，需要设置<code>model.eval()</code>，使用固定的假数据，同时加载相同权重的预训练模型。</li></ul></li></ul><h3 id="3-9-训练集数据读取对齐"><a href="#3-9-训练集数据读取对齐" class="headerlink" title="3.9 训练集数据读取对齐"></a>3.9 训练集数据读取对齐</h3><p><strong>【基本流程】</strong></p><p>该部分内容与3.2节内容基本一致，参考PyTorch的代码，实现训练集数据读取与预处理模块即可。</p><p><strong>【注意事项】</strong></p><p>该部分内容，可以参考3.8节的自测方法，将输入的<code>fake data &amp; label</code>替换为训练的dataloader，但是需要注意的是：</p><ul><li>在使用train dataloader的时候，建议设置random seed，对于PyTorch来说</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#initialize random seed</span><br>torch.manual_seed(config.SEED)<br>torch.cuda.manual_seed_all(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure><p>对于PaddlePaddle来说</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">paddle.seed(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure><h3 id="3-10-网络初始化对齐"><a href="#3-10-网络初始化对齐" class="headerlink" title="3.10 网络初始化对齐"></a>3.10 网络初始化对齐</h3><p><strong>【基本流程】</strong></p><ul><li>下面给出了部分初始化API的映射表。</li></ul><table><thead><tr><th>PaddlePaddle API</th><th>PyTorch API</th></tr></thead><tbody><tr><td>paddle.nn.initializer.KaimingNormal</td><td>torch.nn.init.kaiming_normal_</td></tr><tr><td>paddle.nn.initializer.KaimingUniform</td><td>torch.nn.init.kaiming_uniform_</td></tr><tr><td>paddle.nn.initializer.XavierNormal</td><td>torch.nn.init.xavier_normal_</td></tr><tr><td>paddle.nn.initializer.XavierUniform</td><td>torch.nn.init.xavier_uniform_</td></tr></tbody></table><p><strong>【注意事项】</strong></p><ul><li>更多初始化API可以参考<a href="https://pytorch.org/docs/stable/nn.init.html">PyTorch初始化API文档</a>以及<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle初始化API文档</a>。</li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle 初始化API文档</a>与参考代码的初始化实现对齐。</p><h3 id="3-11-模型训练对齐"><a href="#3-11-模型训练对齐" class="headerlink" title="3.11 模型训练对齐"></a>3.11 模型训练对齐</h3><p><strong>【基本流程】</strong></p><p>完成前面的步骤之后，就可以开始全量数据的训练对齐任务了。按照下面的步骤进行训练对齐。</p><ol><li>准备train&#x2F;eval data, loader, model</li><li>对model按照论文所述进行初始化(如果论文中提到加载了预训练模型，则按需加载pretrained model)</li><li>加载配置，开始训练，迭代得到最终模型与评估指标，将评估指标使用reprod_log保存到文件中。</li><li>将PaddlePaddle提供的参考指标使用reprod_log提交到另一个文件中。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li><p>【强烈】建议先做完反向对齐之后再进行模型训练对齐，二者之间的不确定量包括：数据集、PaddlePaddle与参考代码在模型training mode下的区别，初始化参数。</p></li><li><p>在训练对齐过程中，受到较多随机量的影响，精度有少量diff是正常的，以SST-2数据集的分类为例，diff在0.15%以内可以认为是正常的，这里可以根据不同的任务，适当调整对齐检查的阈值(<code>ReprodDiffHelper.report</code>函数中的<code>diff_threshold</code>参数)。</p></li><li><p>训练过程中的波动是正常的，如果最终收敛结果不一致，可以 </p></li><li><ul><li>仔细排查Dropout、BatchNorm以及其他组网模块及超参是否无误。</li><li>基于参考代码随机生成一份预训练模型，转化为PaddlePaddle的模型，并使用PaddlePaddle加载训练，对比二者的收敛曲线与最终结果，排查初始化影响。</li><li>使用参考代码的Dataloader生成的数据，进行模型训练，排查train dataloader的影响。</li></ul></li></ul><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/Step5/README.md">训练对齐操作文档</a>。</p><p><strong>【验收】</strong></p><p>对于待复现的项目，训练对齐验收流程如下。</p><ol><li>输入：train&#x2F;eval dataloader, model</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle：dict，key为保存值的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_paddle.npy</code>。</li><li>benchmark：dict，key为保存值的name（自定义），value为论文复现赛的评估指标要求的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_benchmark.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>train_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>train_align_paddle.npy</code>、<code>train_align_benchmark.npy</code>与<code>train_align_diff_log.txt</code>文件备份到<code>3.1节验收环节</code>新建的文件夹中，最终一并打包上传即可。</li></ol><h3 id="3-12-单机多卡训练"><a href="#3-12-单机多卡训练" class="headerlink" title="3.12 单机多卡训练"></a>3.12 单机多卡训练</h3><p>如果希望使用单机多卡提升训练效率，可以从以下几个过程对代码进行修改。</p><h4 id="3-12-1-数据读取"><a href="#3-12-1-数据读取" class="headerlink" title="3.12.1 数据读取"></a>3.12.1 数据读取</h4><p>对于PaddlePaddle来说，多卡数据读取这块主要的变化在sampler</p><p>对于单机单卡，sampler实现方式如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train_sampler = paddle.io.RandomSampler(dataset)<br>train_batch_sampler = paddle.io.BatchSampler(<br>    sampler=train_sampler, batch_size=args.batch_size)<br></code></pre></td></tr></table></figure><p>对于单机多卡任务，sampler实现方式如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">train_batch_sampler = paddle.io.DistributedBatchSampler(<br>        dataset=dataset,<br>        batch_size=args.batch_size,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">False</span><br>    )<br></code></pre></td></tr></table></figure><p>注意：在这种情况下，单机多卡的代码仍然能够以单机单卡的方式运行，因此建议以这种sampler方式进行论文复现。</p><h4 id="3-12-2-多卡模型初始化"><a href="#3-12-2-多卡模型初始化" class="headerlink" title="3.12.2 多卡模型初始化"></a>3.12.2 多卡模型初始化</h4><p>如果以多卡的方式运行，需要初始化并行训练环境，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>        paddle.distributed.init_parallel_env()<br></code></pre></td></tr></table></figure><p>在模型组网并初始化参数之后，需要使用<code>paddle.DataParallel()</code>对模型进行封装，使得模型可以通过数据并行的模式被执行。代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>    model = paddle.DataParallel(model)<br></code></pre></td></tr></table></figure><h4 id="3-12-3-模型保存、日志保存等其他模块"><a href="#3-12-3-模型保存、日志保存等其他模块" class="headerlink" title="3.12.3 模型保存、日志保存等其他模块"></a>3.12.3 模型保存、日志保存等其他模块</h4><p>以模型保存为例，我们只需要在0号卡上保存即可，否则多个trainer同时保存的话，可能会造成写冲突，导致最终保存的模型不可用。</p><h4 id="3-12-4-程序启动方式"><a href="#3-12-4-程序启动方式" class="headerlink" title="3.12.4 程序启动方式"></a>3.12.4 程序启动方式</h4><p>对于单机单卡或者单机多卡的启动脚本可以参考：<a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/bert">https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/bert</a></p><p>对于单机单卡，启动脚本如下所示</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">unset CUDA_VISIBLE_DEVICES<br>python -m paddle.distributed.launch --gpus &quot;0&quot; run_glue.py \<br>    --model_type bert \<br>    --model_name_or_path bert-base-uncased \<br>    --task_name SST-2 \<br>    --max_seq_length 128 \<br>    --batch_size 32   \<br>    --learning_rate 2e-5 \<br>    --num_train_epochs 3 \<br>    --logging_steps 1 \<br>    --save_steps 500 \<br>    --output_dir ./tmp/ \<br>    --device gpu \<br>    --use_amp False<br></code></pre></td></tr></table></figure><p>对于单机多卡（示例中为4卡训练），启动脚本如下所示：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">unset CUDA_VISIBLE_DEVICES<br>python -m paddle.distributed.launch --gpus &quot;0,1,2,3&quot; run_glue.py \<br>    --model_type bert \<br>    --model_name_or_path bert-base-uncased \<br>    --task_name SST-2 \<br>    --max_seq_length 128 \<br>    --batch_size 32   \<br>    --learning_rate 2e-5 \<br>    --num_train_epochs 3 \<br>    --logging_steps 1 \<br>    --save_steps 500 \<br>    --output_dir ./tmp/ \<br>    --device gpu \<br>    --use_amp False<br></code></pre></td></tr></table></figure><p>注意：这里4卡训练时，虽然单卡的batch size没有变化(32)，但是总卡的batch size相当于是单卡的4倍，因此学习率也设置为了单卡时的4倍。</p><p><strong>【实战】</strong></p><p>本部分可以参考paddlenlp库中的例子：<a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/language_model/bert">单机多卡训练</a>。</p><h3 id="3-13-TIPC基础链条测试接入"><a href="#3-13-TIPC基础链条测试接入" class="headerlink" title="3.13 TIPC基础链条测试接入"></a>3.13 TIPC基础链条测试接入</h3><p><strong>【基本流程】</strong></p><ul><li><p>完成模型的训练、导出inference、基于PaddleInference的推理过程的文档与代码。参考链接： </p></li><li><ul><li><a href="https://github.com/deepinsight/insightface/blob/master/recognition/arcface_paddle/README_cn.md">insightface训练预测使用文档</a></li><li><a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/05_inference_deployment/inference/inference_cn.html">PaddleInference使用文档</a></li></ul></li><li><p>基于<a href="https://github.com/PaddlePaddle/models/blob/tipc/docs/tipc_test/development_specification_docs/train_infer_python.md">TIPC基础链条测试接入规范</a>，完成该模型的TIPC基础链条开发以及测试文档&#x2F;脚本，目录为<code>test_tipc</code>，测试脚本名称为<code>test_train_inference_python.sh</code>，该任务中只需要完成<code>少量数据训练模型，少量数据预测</code>的模式即可，用于测试TIPC流程的模型和少量数据需要放在当前repo中。</p></li></ul><p><strong>【注意事项】</strong></p><ul><li>基础链条测试接入时，只需要验证<code>少量数据训练模型，少量数据预测</code>的模式，只需要在Linux下验证通过即可。</li><li>在文档中需要给出一键测试的脚本与使用说明。</li></ul><p><strong>【实战】</strong></p><p>TIPC基础链条测试接入用例可以参考：<a href="https://github.com/deepinsight/insightface/blob/master/recognition/arcface_paddle/test_tipc/readme.md">InsightFace-paddle TIPC基础链条测试开发文档</a>。</p><p><strong>【验收】</strong></p><ul><li>TIPC基础链条测试文档清晰，<code>test_train_inference_python.sh</code>脚本可以成功执行并返回正确结果。</li></ul><h2 id="4-论文复现注意事项与FAQ"><a href="#4-论文复现注意事项与FAQ" class="headerlink" title="4. 论文复现注意事项与FAQ"></a>4. 论文复现注意事项与FAQ</h2><h3 id="4-1-通用注意事项"><a href="#4-1-通用注意事项" class="headerlink" title="4.1 通用注意事项"></a>4.1 通用注意事项</h3><ul><li>需要仔细对照PaddlePaddle与参考代码的优化器参数实现，确保优化器参数严格对齐。</li><li>如果遇到一些Paddle不支持的API操作，可以尝试使用替代实现进行复现。如下面的PyTorch代码，PaddlePaddle中可以通过slice + concat API的组合形式进行功能实现。同时，对于这个问题，建议优先给Paddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，开发人员会根据优先级进行开发。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.stack([<br>    per_locations[:, <span class="hljs-number">0</span>] - per_box_regression[:, <span class="hljs-number">0</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] - per_box_regression[:, <span class="hljs-number">1</span>],<br>    per_locations[:, <span class="hljs-number">0</span>] + per_box_regression[:, <span class="hljs-number">2</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] + per_box_regression[:, <span class="hljs-number">3</span>],<br>], dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><ul><li><p>如果遇到Paddle不包含的OP或者API，比如(1) 如果是某些算法实现存在调用了外部OP，而且Paddle也不包含该OP实现；(2) 其他框架存在的API或者OP，但是Paddle中没有这些OP。此时： </p></li><li><ul><li>对于Paddle资深用户来说，可以尝试使用Paddle的自定义算子功能，存在一定的代码开发量。</li><li>对于初学者来说，可以给Paddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，Paddle开发人员会根据优先级进行实现。</li></ul></li><li><p>PaddlePaddle与PyTorch对于不同名称的API，实现的功能可能是相同的，复现的时候注意，比如<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/lr/StepDecay_cn.html#stepdecay">paddle.optimizer.lr.StepDecay</a>与<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR">torch.optim.lr_scheduler.StepLR</a> ，关于PaddlePaddle与PyTorch更多API的映射关系可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">API映射表</a>。</p></li><li><p>对于PaddlePaddle来说，通过<code>paddle.set_device</code>函数（全局）来确定模型结构是运行在什么设备上，对于torch来说，是通过<code>model.to(&quot;device&quot;)</code> （局部）来确定模型结构的运行设备，这块在复现的时候需要注意。</p></li></ul><h3 id="4-2-模型结构对齐"><a href="#4-2-模型结构对齐" class="headerlink" title="4.2 模型结构对齐"></a>4.2 模型结构对齐</h3><h4 id="4-2-1-API"><a href="#4-2-1-API" class="headerlink" title="4.2.1 API"></a>4.2.1 API</h4><ul><li>对于 <code>paddle.nn.Linear</code> 层的weight参数，PaddlePaddle与PyTorch的保存方式不同，在转换时需要进行转置，示例代码可以参考<a href="https://github.com/JunnYu/BERT-SST2-Prod/blob/main/pipeline/weights/torch2paddle.py">BERT权重转换脚本</a>。</li><li><code>torch.masked_fill</code>函数的功能目前可以使用<code>paddle.where</code>进行实现，可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/faq/train_cn.html#paddletorch-masked-fillapi">链接</a>。</li><li><code>pack_padded_sequence</code>和<code>pad_packed_sequence</code>这两个API目前PaddlePaddle中没有实现，可以直接在RNN或者LSTM的输入中传入<code>sequence_length</code>来实现等价的功能。</li></ul><h4 id="4-2-2-权重转换"><a href="#4-2-2-权重转换" class="headerlink" title="4.2.2 权重转换"></a>4.2.2 权重转换</h4><ul><li>在权重转换的时候，不能只关注参数的名称，比如说有些<code>paddle.nn.Linear</code>层，但是定义的变量名称为<code>conv</code>，这种也是需要进行权重转置的。</li><li>权重转换时，建议同时打印 Paddle 和 PyTorch 对应权重的shape，以防止名称相似但是shape不同的参数权重转换报错。</li></ul><h4 id="4-2-3-模型组网正确性验证"><a href="#4-2-3-模型组网正确性验证" class="headerlink" title="4.2.3 模型组网正确性验证"></a>4.2.3 模型组网正确性验证</h4><ul><li>在论文复现的过程中，可能会遇到一些经典的模型结构，比如Transformer等，Paddle官方也提供了Transformer的实现，但是这里建议自己根据PyTorch代码重新实现一遍，一方面是对整体的模型结构更加熟悉，另一方面也保证模型结构和权重完全对齐。</li><li>在复杂的网络结构中，如果前向结果对不齐，可以按照模块排查问题，比如依次获取embedding、transformer-block、mlm-head输出等，看下问题具体出现在哪个子模块，再进到子模块详细排查。</li><li>网络结构对齐后，尽量使用训练好的预训练模型和真实的数据进行前向diff计算，这样更准确。</li></ul><h3 id="4-3-验证-测试集数据读取对齐"><a href="#4-3-验证-测试集数据读取对齐" class="headerlink" title="4.3 验证&#x2F;测试集数据读取对齐"></a>4.3 验证&#x2F;测试集数据读取对齐</h3><ul><li>需要仔细排查数据预处理，不仅包含的预处理方法相同，也需要保证预处理的流程相同，比如padding策略不同和截断策略的不同会导致得到最终的结果是不同的。</li></ul><h3 id="4-4-评估指标对齐"><a href="#4-4-评估指标对齐" class="headerlink" title="4.4 评估指标对齐"></a>4.4 评估指标对齐</h3><ul><li>真实数据评估时，需要注意评估时 <code>paddle.io.DataLoader</code> 的 <code>drop_last</code> 参数是否打开(文档<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#dataloader">链接</a>)，复现代码需要与参考代码保持一致，否则最后不够batch-size的数据的评估会有diff。</li><li>在识别或者检索过程中，为了加速评估过程，往往会将评估函数由CPU实现改为GPU实现，由此会带来评估函数输出的不一致。这是由于sort函数对于相同值的排序结果不同带来的。在复现的过程中，如果可以接受轻微的指标不稳定，可以使用PaddlePaddle的sort函数，如果对于指标非常敏感，同时对速度性能要求很高，可以给PaddlePaddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，由研发人员高优开发。</li></ul><h3 id="4-5-损失函数对齐"><a href="#4-5-损失函数对齐" class="headerlink" title="4.5 损失函数对齐"></a>4.5 损失函数对齐</h3><ul><li>部分算法的损失函数中会用到 bool 索引，这时候可以使用<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/where_cn.html#where">paddle.where</a> 代替。</li><li><code>paddle.nn.CrossEntropyLoss</code> 默认是在最后一维(axis&#x3D;-1)计算损失函数，而 <code>torch.nn.CrossEntropyLoss</code> 是在axis&#x3D;1的地方计算损失函数，因此如果输入的维度大于2，这里需要保证计算的维(axis)相同，否则可能会出错。</li><li>在生成模型中会遇到梯度损失，需要对模型中的算子求二次梯度，目前<code>MaxPooling</code>暂时不支持二次梯度，如果复现的过程中遇到了需要对<code>MaxPooling</code>求二次梯度的情况，可以和Paddle官方开发同学反馈，进一步确认解决方案。</li><li>在保存损失函数值的时候，注意要使用<code>paddle.no_grad</code>，或者仅仅保存转换成 numpy 的数组，避免损失没有析构导致内存泄漏问题。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 错误示范</span><br>loss = celoss(pred, label)<br>avg_loss += loss<br><span class="hljs-comment"># 正确示范1</span><br>loss = celoss(pred, label)<br>avg_loss += loss.numpy()<br><span class="hljs-comment"># 正确示范2</span><br>loss = celoss(pred, label)<br><span class="hljs-keyword">with</span> paddle.no_grad()<br>    avg_loss += loss<br></code></pre></td></tr></table></figure><h3 id="4-6-优化器对齐"><a href="#4-6-优化器对齐" class="headerlink" title="4.6 优化器对齐"></a>4.6 优化器对齐</h3><ul><li>Paddle目前支持在 <code>optimizer</code> 中通过设置 <code>params_groups</code> 的方式设置不同参数的更新方式，可以参考<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/optimizer/optimizer.py#L107">代码示例</a> 。</li><li>有些模型训练时，会使用梯度累加策略，即累加到一定step数量之后才进行参数更新，这时在实现上需要注意对齐。</li><li>在某些任务中，比如说深度学习可视化、可解释性等任务中，一般只要求模型前向过程，不需要训练，此时优化器、学习率等用于模型训练的模块对于该类论文复现是不需要的。</li><li>在文本分类领域，大多数Transformer模型都采用了AdamW优化器，并且会设置weigh decay，同时部分参数设置为no weight decay，例如位置编码的参数通常设置为no weight decay，no weight decay参数设置不正确，最终会有明显的精度损失，需要特别注意。一般可以通过分析模型权重来发现该问题，分别计算官方模型和复现模型每层参数权重的平均值、方差，对每一层依次对比，有显著差异的层可能存在问题，因为在weight decay的作用下，参数权重数值会相对较小，而未正确设置no weight decay，则会造成该层参数权重数值异常偏小。</li></ul><h3 id="4-7-学习率对齐"><a href="#4-7-学习率对齐" class="headerlink" title="4.7 学习率对齐"></a>4.7 学习率对齐</h3><ul><li>PaddlePaddle 中参数的学习率受到优化器学习率和<code>ParamAttr</code>中设置的学习率影响，因此跟踪学习率需要将二者结合进行跟踪。</li><li>对于复现代码和参考代码，学习率在整个训练过程中在相同的轮数相同的iter下应该保持一致，可以通过<code>reprod_log</code>工具、打印学习率值或者可视化二者学习率的log来查看diff。</li><li>有些网络的学习率策略比较细致，比如带warmup的学习率策略，这里需要保证起始学习率等参数都完全一致。</li></ul><h3 id="4-8-正则化策略对齐"><a href="#4-8-正则化策略对齐" class="headerlink" title="4.8 正则化策略对齐"></a>4.8 正则化策略对齐</h3><ul><li>在如Transformer或者少部分CNN模型中，存在一些参数不做正则化(正则化系数为0)的情况。这里需要找到这些参数并对齐取消实施正则化策略，可以参考<a href="https://github.com/PaddlePaddle/PaddleClas/blob/release%2F2.3/ppcls/arch/backbone/model_zoo/resnest.py#L72">这里</a>，对特定参数进行修改。</li></ul><h3 id="4-9-反向对齐"><a href="#4-9-反向对齐" class="headerlink" title="4.9 反向对齐"></a>4.9 反向对齐</h3><ul><li>反向对齐时，如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证。第3章中给出了获取所有参数的梯度方法，如果只希望打印特定参数的梯度，可以用下面的方式。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> paddle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_hook_fn</span>(<span class="hljs-params">grad</span>):<br>    <span class="hljs-built_in">print</span>(grad)<br><br>x = paddle.to_tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>], stop_gradient=<span class="hljs-literal">False</span>)<br>h = x.register_hook(print_hook_fn)<br>w = x * <span class="hljs-number">4</span><br>w.backward()<br><span class="hljs-comment"># backward之后会输出下面的内容</span><br><span class="hljs-comment">#     Tensor(shape=[4], dtype=float32, place=CPUPlace, stop_gradient=False,</span><br><span class="hljs-comment">#            [4., 4., 4., 4.])</span><br></code></pre></td></tr></table></figure><h3 id="4-10-训练集数据读取对齐"><a href="#4-10-训练集数据读取对齐" class="headerlink" title="4.10 训练集数据读取对齐"></a>4.10 训练集数据读取对齐</h3><h4 id="4-10-1-API"><a href="#4-10-1-API" class="headerlink" title="4.10.1 API"></a>4.10.1 API</h4><ul><li>在前向过程中，如果数据预处理过程运行出错，请先将 <code>paddle.io.DataLoader</code> 的 <code>num_workers</code> 参数设为0，然后根据单个进程下的报错日志定位出具体的bug。</li></ul><h4 id="4-10-2-数据预处理"><a href="#4-10-2-数据预处理" class="headerlink" title="4.10.2 数据预处理"></a>4.10.2 数据预处理</h4><ul><li>如果数据处理过程中涉及到随机数生成，建议固定seed (<code>np.random.seed(0)</code>, <code>random.seed(0)</code>)，查看复现代码和参考代码处理后的数据是否有diff。</li><li>对文本进行tokenizer处理时，需要确定文本的截断策略，padding策略。</li></ul><h3 id="4-11-网络初始化对齐"><a href="#4-11-网络初始化对齐" class="headerlink" title="4.11 网络初始化对齐"></a>4.11 网络初始化对齐</h3><ul><li>对于不同的深度学习框架，网络初始化在大多情况下，即使值的分布完全一致，也无法保证值完全一致，这里也是论文复现中不确定性比较大的地方。如果十分怀疑初始化导致的问题，建议将参考的初始化权重转成paddle模型，加载该初始化模型训练，看下收敛精度。</li><li>CNN对于模型初始化相对来说没有那么敏感，在迭代轮数与数据集足够的情况下，最终精度指标基本接近；而transformer系列模型对于初始化比较敏感，在transformer系列模型训练对齐过程中，建议对这一块进行重点检查。</li></ul><h3 id="4-12-模型训练对齐"><a href="#4-12-模型训练对齐" class="headerlink" title="4.12 模型训练对齐"></a>4.12 模型训练对齐</h3><h4 id="4-12-1-训练对齐通用问题"><a href="#4-12-1-训练对齐通用问题" class="headerlink" title="4.12.1 训练对齐通用问题"></a>4.12.1 训练对齐通用问题</h4><ul><li><p>有条件的话，复现工作之前最好先基于官方代码完成训练，保证与官方指标能够对齐，并且将训练策略和训练过程中的关键指标记录保存下来，比如每个epoch的学习率、Train Loss、Eval Loss、Eval Acc等，在复现网络的训练过程中，将关键指标保存下来，这样可以将两次训练中关键指标的变化曲线绘制出来，能够很方便的进行对比。</p></li><li><p>训练过程中可以对loss或者acc进行可视化，和竞品loss或者acc进行直观的对比；如果训练较大的数据集，1次完整训练的成本比较高，此时可以隔一段时间查看一下，如果精度差异比较大，建议先停掉实验，排查原因。</p></li><li><p>如果训练的过程中出nan，一般是因为除0或者log0的情况， 可以着重看下几个部分： </p></li><li><ul><li>如果有预训练模型的话，可以确认下是否加载正确</li><li>模型结构中计算loss的部分是否有考虑到正样本为0的情况</li><li>也可能是某个API的数值越界导致的，可以测试较小的输入是否还会出现nan。</li></ul></li><li><p>如果训练过程中如果出现不收敛的情况，可以 </p></li><li><ul><li>简化网络和数据，实验是否收敛；</li><li>如果是基于原有实现进行改动，可以尝试控制变量法，每次做一个改动，逐个排查；</li><li>检查学习率是否过大、优化器设置是否合理，排查下weight decay是否设置正确；</li><li>保存不同step之间的模型参数，观察模型参数是否更新。</li></ul></li></ul><h4 id="4-12-2-细分场景特定问题"><a href="#4-12-2-细分场景特定问题" class="headerlink" title="4.12.2 细分场景特定问题"></a>4.12.2 细分场景特定问题</h4><ul><li>小数据上指标波动可能比较大，时间允许的话，可以跑多次实验，取平均值。</li></ul><h3 id="4-13-TIPC基础链条测试接入"><a href="#4-13-TIPC基础链条测试接入" class="headerlink" title="4.13 TIPC基础链条测试接入"></a>4.13 TIPC基础链条测试接入</h3><ul><li>在接入时，建议将少量用于测试的数据打包(<code>tar -zcf lite_data.tar data/</code>)，放在data目录下，后续在进行环境准备的时候，直接解压该压缩包即可。</li><li>接入过程中，需要依赖于inference模型，因此建议首先提供模型导出和基于inference模型的预测脚本，之后再接入TIPC测试代码与文档。</li></ul><h2 id="来源："><a href="#来源：" class="headerlink" title="来源："></a>来源：</h2><p><a href="https://github.com/PaddlePaddle/">https://github.com/PaddlePaddle/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> paddle </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CV论文复现-paddle指南</title>
      <link href="/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/"/>
      <url>/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="论文复现指南-CV方向"><a href="#论文复现指南-CV方向" class="headerlink" title="论文复现指南-CV方向"></a>论文复现指南-CV方向</h1><p>本文为针对 <code>CV</code> 方向的复现指南</p><h2 id="1-总览"><a href="#1-总览" class="headerlink" title="1. 总览"></a>1. 总览</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><ul><li><p>以深度学习为核心的人工智能技术仍在高速发展，通过论文复现，开发者可以获得 </p></li><li><ul><li>学习成长：自我能力提升</li><li>技术积累：对科研或工作有所帮助和启发</li><li>社区荣誉：成果被开发者广泛使用</li></ul></li></ul><h3 id="1-2-前序工作"><a href="#1-2-前序工作" class="headerlink" title="1.2 前序工作"></a>1.2 前序工作</h3><p>基于本指南复现论文过程中，建议开发者准备以下内容。</p><ul><li><p>了解该模型输入输出格式。以AlexNet图像分类任务为例，通过阅读论文与参考代码，了解到模型输入为<code>[batch_size, 3, 224, 244]</code>的tensor，类型为<code>float32</code>或者<code>float16</code>，label为<code>[batch, ]</code>的label，类型为<code>int64</code>。</p></li><li><p>准备好训练&#x2F;验证数据集，用于模型训练与评估</p></li><li><p>准备好fake input data以及label，与模型输入shape、type等保持一致，用于后续模型前向对齐。 </p></li><li><ul><li>在对齐模型前向过程中，我们不需要考虑数据集模块等其他模块，此时使用fake data是将模型结构和数据部分解耦非常合适的一种方式。</li><li>将fake data以文件的形式存储下来，也可以保证PaddlePaddle与参考代码的模型结构输入是完全一致的，更便于排查问题。</li><li>在该步骤中，以AlexNet为例，生成fake data的脚本可以参考：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/fake_data/gen_fake_data.py">gen_fake_data.py</a>。</li></ul></li><li><p>在特定设备(CPU&#x2F;GPU)上，跑通参考代码的预测过程(前向)以及至少2轮(iteration)迭代过程，保证后续基于PaddlePaddle复现论文过程中可对比。</p></li><li><p>本文档基于 <code>AlexNet-Prod</code> 代码以及<code>reprod_log</code> whl包进行说明与测试。如果希望体验，建议参考<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/README.md">AlexNet-Reprod文档</a>进行安装与测试。</p></li><li><p>在复现的过程中，只需要将PaddlePaddle的复现代码以及打卡日志上传至github，不能在其中添加<code>参考代码的实现</code>，在核验通过之后，需要删除打卡日志。建议在初期复现的时候，就将<strong>复现代码与参考代码分成2个文件夹进行管理</strong>。</p></li></ul><h2 id="2-整体框图"><a href="#2-整体框图" class="headerlink" title="2. 整体框图"></a>2. 整体框图</h2><h3 id="2-1-流程概览"><a href="#2-1-流程概览" class="headerlink" title="2.1 流程概览"></a>2.1 流程概览</h3><p>面对一篇计算机视觉论文，复现该论文的整体流程如下图所示。</p><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240110100310487.png" alt="image-20240110100310487"></p><p>总共包含13个步骤。为了高效复现论文，设置了6个核验点。如上图中黄色框所示。后续章节会详细介绍上述步骤和核验点，具体内容安排如下：</p><ul><li>第3章：介绍13个复现步骤的理论知识、实战以及核验流程。</li><li>第4章：针对复现流程过程中每个步骤可能出现的问题，本章会进行详细介绍。</li></ul><h3 id="2-2-reprod-log-whl包"><a href="#2-2-reprod-log-whl包" class="headerlink" title="2.2 reprod_log whl包"></a>2.2 reprod_log whl包</h3><h4 id="2-2-1-reprod-log工具简介"><a href="#2-2-1-reprod-log工具简介" class="headerlink" title="2.2.1 reprod_log工具简介"></a>2.2.1 reprod_log工具简介</h4><p><code>reprod_log</code>是用于论文复现赛中辅助自查和核验工具。该工具源代码地址在：<a href="https://github.com/WenmuZhou/reprod_log%E3%80%82%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD%E5%A6%82%E4%B8%8B%EF%BC%9A">https://github.com/WenmuZhou/reprod_log。主要功能如下：</a></p><ul><li>存取指定节点的输入输出tensor</li><li>基于文件的tensor读写</li><li>2个字典的对比验证</li><li>对比结果的输出与记录</li></ul><p>更多API与使用方法可以参考：<a href="https://github.com/WenmuZhou/reprod_log/blob/master/README.md">reprod_log API使用说明</a>。</p><h4 id="2-2-2-reprod-log使用demo"><a href="#2-2-2-reprod-log使用demo" class="headerlink" title="2.2.2 reprod_log使用demo"></a>2.2.2 reprod_log使用demo</h4><p>下面基于代码：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/reprod_log_demo%EF%BC%8C%E7%BB%99%E5%87%BA%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%A5%E5%B7%A5%E5%85%B7%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/reprod_log_demo，给出如何使用该工具。</a></p><p>文件夹中包含<code>write_log.py</code>和<code>check_log_diff.py</code>文件，其中<code>write_log.py</code>中给出了<code>ReprodLogger</code>类的使用方法，<code>check_log_diff.py</code>给出了<code>ReprodDiffHelper</code>类的使用方法，依次运行两个python文件，使用下面的方式运行代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">进入文件夹</span><br>cd pipeline/reprod_log_demo<br><span class="hljs-meta prompt_"># </span><span class="language-bash">随机生成矩阵，写入文件中</span><br>python3.7 write_log.py<br><span class="hljs-meta prompt_"># </span><span class="language-bash">进行文件对比，输出日志</span><br>python3.7 check_log_diff.py<br></code></pre></td></tr></table></figure><p>最终会输出以下内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">2021-09-28 01:07:44,832 - reprod_log.utils - INFO - demo_test_1:<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO -     mean diff: check passed: True, value: 0.0<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO - demo_test_2:<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO -     mean diff: check passed: False, value: 0.3336232304573059<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO - diff check failed<br></code></pre></td></tr></table></figure><p>可以看出：对于key为<code>demo_test_1</code>的矩阵，由于diff为0，小于设置的阈值<code>1e-6</code>，核验成功；对于key为<code>demo_test_2</code>的矩阵，由于diff为0.33，大于设置的阈值<code>1e-6</code>，核验失败。</p><h4 id="2-2-3-reprod-log在论文复现中应用"><a href="#2-2-3-reprod-log在论文复现中应用" class="headerlink" title="2.2.3 reprod_log在论文复现中应用"></a>2.2.3 reprod_log在论文复现中应用</h4><p>在论文复现中，基于reprod_log的结果记录模块，产出下面若干文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plain">log_reprod<br>├── forward_paddle.npy<br>├── forward_torch.npy    # 与forward_paddle.npy作为一并核查的文件对<br>├── metric_paddle.npy<br>├── metric_torch.npy     # 与metric_paddle.npy作为一并核查的文件对<br>├── loss_paddle.npy<br>├── loss_torch.npy       # 与loss_paddle.npy作为一并核查的文件对<br>├── bp_align_paddle.npy<br>├── bp_align_torch.npy   # 与bp_align_paddle.npy作为一并核查的文件对<br>├── train_align_paddle.npy<br>├── train_align_benchmark.npy # PaddlePaddle提供的参考评估指标<br></code></pre></td></tr></table></figure><p>基于reprod_log的<code>ReprodDiffHelper</code>模块，产出下面5个日志文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">├── forward_diff.log     # forward_paddle.npy与forward_torch.npy生成的diff结果文件<br>├── metric_diff.log      # metric_paddle.npy与metric_torch.npy生成的diff结果文件<br>├── loss_diff.log          # loss_paddle.npy与loss_torch.npy生成的diff结果文件<br>├── bp_align_diff.log    # bp_align_paddle.npy与bp_align_torch.npy生成的diff结果文件<br>├── train_align_diff.log # train_align_paddle.npy与train_align_benchmark.npy生成的diff结果文件<br></code></pre></td></tr></table></figure><p>上述文件的生成代码都需要开发者进行开发，核验时需要提供上面罗列的所有文件（不需要提供产生这些文件的可运行程序）以及完整的模型训练评估程序和日志。</p><p>AlexNet-Prod项目提供了基于reprod_log的前5个核验点对齐核验示例，参考代码地址为：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E7%9A%84README.md%E6%96%87%E6%A1%A3%E6%8F%90%E4%BE%9B%E4%BA%86%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/，每个文件夹中的README.md文档提供了使用说明。</a></p><h2 id="3-论文复现理论知识及实战"><a href="#3-论文复现理论知识及实战" class="headerlink" title="3. 论文复现理论知识及实战"></a>3. 论文复现理论知识及实战</h2><h3 id="3-1-模型结构对齐"><a href="#3-1-模型结构对齐" class="headerlink" title="3.1 模型结构对齐"></a>3.1 模型结构对齐</h3><p>对齐模型结构时，一般有3个主要步骤：</p><ul><li>网络结构代码转换</li><li>权重转换</li><li>模型组网正确性验证</li></ul><p>下面详细介绍这3个部分。</p><h4 id="3-1-1-网络结构代码转换"><a href="#3-1-1-网络结构代码转换" class="headerlink" title="3.1.1 网络结构代码转换"></a>3.1.1 网络结构代码转换</h4><p><strong>【基本流程】</strong></p><p>由于PyTorch的API和PaddlePaddle的API非常相似，可以参考<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">PyTorch-PaddlePaddle API映射表</a><br>，组网部分代码直接进行手动转换即可。</p><p><strong>【注意事项】</strong></p><p>如果遇到PaddlePaddle没有的API，可以尝试用多种API来组合，也可以给PaddlePaddle团队提<a href="https://github.com/PaddlePaddle/Paddle/issues">ISSUE</a>，获得支持。</p><p><strong>【实战】</strong></p><p>AlexNet网络结构的PyTorch实现: <a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step1/AlexNet_torch/torchvision/models/alexnet.py">alexnet-pytorch</a></p><p>对应转换后的PaddlePaddle实现: <a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step1/AlexNet_paddle/paddlevision/models/alexnet.py">alexnet-paddle</a></p><h4 id="3-1-2-权重转换"><a href="#3-1-2-权重转换" class="headerlink" title="3.1.2 权重转换"></a>3.1.2 权重转换</h4><p><strong>【基本流程】</strong></p><p>组网代码转换完成之后，需要对模型权重进行转换，如果PyTorch repo中已经提供权重，那么可以直接下载并进行后续的转换；如果没有提供，则可以基于PyTorch代码，随机生成一个初始化权重(定义完model以后，使用<code>torch.save()</code> API保存模型权重)，然后进行权重转换。</p><p><strong>【注意事项】</strong></p><p>在权重转换的时候，需要注意<code>paddle.nn.Linear</code>以及<code>paddle.nn.BatchNorm2D</code>等API的权重保存格式和名称等与PyTorch稍有diff，具体内容可以参考<code>4.1章节</code>。</p><p><strong>【实战】</strong></p><p>AlexNet的代码转换脚本可以在这里查看：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py%EF%BC%8C">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py，</a></p><p>注意：运行该代码需要首先下载PyTorch的AlexNet预训练模型到该目录下，下载地址为：<a href="https://download.pytorch.org/models/alexnet-owt-7be5be79.pth">https://download.pytorch.org/models/alexnet-owt-7be5be79.pth</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> paddle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">transfer</span>():<br>    input_fp = <span class="hljs-string">&quot;alexnet-owt-7be5be79.pth&quot;</span><br>    output_fp = <span class="hljs-string">&quot;alexnet_paddle.pdparams&quot;</span><br>    torch_dict = torch.load(input_fp)<br>    paddle_dict = &#123;&#125;<br>    fc_names = [<br>        <span class="hljs-string">&quot;classifier.1.weight&quot;</span>, <span class="hljs-string">&quot;classifier.4.weight&quot;</span>, <span class="hljs-string">&quot;classifier.6.weight&quot;</span><br>    ]<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> torch_dict:<br>        weight = torch_dict[key].cpu().detach().numpy()<br>        flag = [i <span class="hljs-keyword">in</span> key <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> fc_names]<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(flag):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;weight &#123;&#125; need to be trans&quot;</span>.<span class="hljs-built_in">format</span>(key))<br>            weight = weight.transpose()<br>        paddle_dict[key] = weight<br>    paddle.save(paddle_dict, output_fp)<br><br>transfer()<br></code></pre></td></tr></table></figure><p>运行完成之后，会在当前目录生成<code>alexnet_paddle.pdparams</code>文件，即为转换后的PaddlePaddle预训练模型。</p><h4 id="3-1-3-模型组网正确性验证"><a href="#3-1-3-模型组网正确性验证" class="headerlink" title="3.1.3 模型组网正确性验证"></a>3.1.3 模型组网正确性验证</h4><p><strong>【基本流程】</strong></p><ol><li>定义PyTorch模型，加载权重，固定seed，基于numpy生成随机数，转换为PyTorch可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li><li>定义PaddlePaddle模型，加载权重，固定seed，基于numpy生成随机数，转换为PaddlePaddle可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li>模型在前向对齐验证时，需要调用<code>model.eval()</code>方法，保证组网中的随机量被关闭，比如BatchNorm、Dropout等。</li><li>给定相同的输入数据，为保证可复现性，如果有随机数生成，固定相关的随机种子。</li><li>输出diff可以使用<code>np.mean(np.abs(o1 - o2))</code>进行计算，一般小于1e-6的话，可以认为前向没有问题。如果最终输出结果diff较大，可以使用二分的方法进行排查，比如说ResNet50，包含1个stem、4个res-stage、global avg-pooling以及最后的fc层，那么完成模型组网和权重转换之后，如果模型输出没有对齐，可以尝试输出中间某一个res-stage的tensor进行对比，如果相同，则向后进行排查；如果不同，则继续向前进行排查，以此类推，直到找到导致没有对齐的操作。</li></ul><p><strong>【实战】</strong></p><p>AlexNet模型组网正确性验证可以参考如下示例代码：<br><a href="https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/Step1">https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/Step1</a></p><p><strong>【核验】</strong></p><p>对于待复现的项目，前向对齐核验流程如下。</p><ol><li>准备输入：fake data</li></ol><ul><li><ul><li>使用参考代码的dataloader，生成一个batch的数据，保存下来，在前向对齐时，直接从文件中读入。</li><li>固定随机数种子，生成numpy随机矩阵，转化tensor</li></ul></li></ul><ol><li>保存输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为tensor的值。最后将dict保存到文件中。建议命名为<code>forward_paddle.npy</code>和<code>forward_pytorch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>forward_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：新建文件夹，将<code>forward_paddle.npy</code>、<code>forward_pytorch.npy</code>与<code>forward_diff_log.txt</code>文件放在文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>PaddlePaddle与PyTorch保存的dict的key需要保持相同，否则report过程可能会提示key无法对应，从而导致report失败，之后的<code>【核验】</code>环节也是如此。</li><li>如果是固定随机数种子，建议将fake data保存到dict中，方便check参考代码和PaddlePaddle的输入是否一致。</li></ul></li></ul><h3 id="3-2-准备小数据集，验证集数据读取对齐"><a href="#3-2-准备小数据集，验证集数据读取对齐" class="headerlink" title="3.2 准备小数据集，验证集数据读取对齐"></a>3.2 准备小数据集，验证集数据读取对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle中数据集相关的API为<code>paddle.io.Dataset</code>，使用该接口可以完成数据集的单个样本读取。</p><p>复现完Dataset之后，可以使用<code>paddle.io.DataLoader</code>，构建Dataloader，对数据进行组batch、批处理，送进网络进行计算。</p><p>为后续的快速验证(训练&#x2F;评估&#x2F;预测)，建议准备一个小数据集（训练集和验证集各8~16张图像即可，压缩后数据大小建议在<code>20M</code>以内），放在<code>lite_data</code>文件夹下。</p><p><strong>【注意事项】</strong></p><p>对于一个数据集，一般有以下一些信息需要重点关注</p><ul><li>数据集名称、下载地址</li><li>训练集&#x2F;验证集&#x2F;测试集图像数量、类别数量、分辨率等</li><li>数据集标注格式、标注信息</li><li>数据集通用的预处理方法</li></ul><p>论文中一般会提供数据集的名称以及基本信息。复现过程中，我们在下载完数据之后，建议先检查下是否和论文中描述一致，否则可能存在的问题有：</p><ul><li>数据集年份不同，比如论文中使用了MS-COCO2014数据集，但是我们下载的是MS-COCO2017数据集，如果不对其进行检查，可能会导致我们最终训练的数据量等与论文中有diff</li><li>数据集使用方式不同，有些论文中，可能只是抽取了该数据集的子集进行方法验证，此时需要注意抽取方法，需要保证抽取出的子集完全相同。</li><li>在评估指标对齐时，我们可以固定batch size，关闭Dataloader的shuffle操作。</li></ul><p>构建数据集时，也会涉及到一些预处理方法，以CV领域为例，PaddlePaddle提供了一些现成的视觉类操作api，具体可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html">paddle.vision类API</a>。对应地，PyTorch中的数据处理api可以参考：<a href="https://pytorch.org/vision/stable/transforms.html">torchvision.transforms类API</a>。对于其中之一，可以找到另一个平台的实现。</p><p>此外，</p><ul><li>有些自定义的数据处理方法，如果不涉及到深度学习框架的部分，可以直接复用。</li><li>对于特定任务中的数据预处理方法，比如说图像分类、检测、分割等，如果没有现成的API可以调用，可以参考官方模型套件中的一些实现方法，比如PaddleClas、PaddleDetection、PaddleSeg等。</li></ul><p><strong>【实战】</strong></p><p>AlexNet复现过程中，准备<code>ImageNet小数据集</code>的脚本可以参考<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/tipc/pipeline/Step2/prepare.py">prepare.py</a>。</p><p>AlexNet模型复现过程中，数据预处理和Dataset、Dataloader的检查可以参考该文件：<br><a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/test_data.py%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/test_data.py。</a></p><p>使用方法可以参考<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/README.md">数据检查文档</a>。</p><h3 id="3-3-评估指标对齐"><a href="#3-3-评估指标对齐" class="headerlink" title="3.3 评估指标对齐"></a>3.3 评估指标对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle提供了一系列Metric计算类，比如说<code>Accuracy</code>, <code>Auc</code>, <code>Precision</code>, <code>Recall</code>等，而PyTorch中，目前可以通过组合的方式实现metric计算，或者调用<a href="https://torchmetrics.readthedocs.io/en/latest/">torchmetrics</a>，在论文复现的过程中，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。具体流程如下。</p><ol><li>定义PyTorch模型，加载训练好的权重（需要是官网repo提供好的），获取评估结果，使用reprod_log保存结果。</li><li>定义PaddlePaddle模型，加载训练好的权重（需要是从PyTorch转换得到），获取评估结果，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><p>在评估指标对齐之前，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。</p><p><strong>【实战】</strong></p><p>评估指标对齐检查方法可以参考文档：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/README.md#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">评估指标对齐检查方法文档</a></p><p><strong>【核验】</strong></p><p>对于待复现的项目，评估指标对齐核验流程如下。</p><ol><li>输入：dataloader, model</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>metric_paddle.npy</code>和<code>metric_pytorch.npy</code>。</li><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>metric_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li></ul></li></ul><ol><li>提交内容：将<code>metric_paddle.npy</code>、<code>metric_pytorch.npy</code>与<code>metric_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>数据需要是真实数据</li><li>需要检查论文是否只是抽取了验证集&#x2F;测试集中的部分文件，如果是的话，则需要保证PaddlePaddle和参考代码中dataset使用的数据集一致。</li></ul></li></ul><h3 id="3-4-损失函数对齐"><a href="#3-4-损失函数对齐" class="headerlink" title="3.4 损失函数对齐"></a>3.4 损失函数对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle与PyTorch均提供了很多loss function，用于模型训练，具体的API映射表可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html#lossapi">Loss类API映射列表</a>。以CrossEntropyLoss为例，主要区别为：</p><ul><li>PaddlePaddle提供了对软标签、指定softmax计算纬度的支持。</li></ul><p>如果论文中使用的loss function没有指定的API，则可以尝试通过组合API的方式，实现自定义的loss function。</p><p>具体流程如下。</p><ol><li>定义PyTorch模型，加载权重，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PyTorch可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li><li>定义PaddlePaddle模型，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PaddlePaddle可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li>计算loss的时候，建议设置<code>model.eval()</code>，避免模型中随机量的问题。</li></ul><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step3/README.md%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step3/README.md。</a></p><p><strong>【核验】</strong></p><p>对于待复现的项目，损失函数对齐核验流程如下。</p><ol><li>输入：fake data &amp; label</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>loss_paddle.npy</code>和<code>loss_pytorch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>loss_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>loss_paddle.npy</code>、<code>loss_pytorch.npy</code>与<code>loss_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li></ol><h3 id="3-5-优化器对齐"><a href="#3-5-优化器对齐" class="headerlink" title="3.5 优化器对齐"></a>3.5 优化器对齐</h3><p><strong>【基本流程】</strong></p><p>PaddlePaddle中的optimizer有<code>paddle.optimizer</code>等一系列实现，PyTorch中则有<code>torch.Optim</code>等一系列实现。</p><p><strong>【注意事项】</strong></p><p>以SGD等优化器为例，PaddlePaddle与Pytorch的优化器区别主要如下。</p><ul><li>PaddlePaddle在优化器中增加了对梯度裁剪的支持，在训练GAN或者一些NLP、多模态任务中，这个用到的比较多。</li><li>PaddlePaddle的SGD不支持动量更新、动量衰减和Nesterov动量，这里需要使用<code>paddle.optimizer.Momentum</code> API实现这些功能。</li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html">PaddlePaddle优化器API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p><h3 id="3-6-学习率对齐"><a href="#3-6-学习率对齐" class="headerlink" title="3.6 学习率对齐"></a>3.6 学习率对齐</h3><p><strong>【基本流程】</strong></p><ul><li>学习率策略主要用于指定训练过程中的学习率变化曲线，这里可以将定义好的学习率策略，不断step，即可得到对应的学习率值，可以将学习率值保存在列表或者矩阵中，使用<code>reprod_log</code>工具判断二者是否对齐。</li></ul><p><strong>【注意事项】</strong></p><p>PaddlePaddle中，需要首先构建学习率策略，再传入优化器对象中；对于PyTorch，如果希望使用更丰富的学习率策略，需要先构建优化器，再传入学习率策略类API。</p><p><strong>【实战】</strong></p><p>学习率复现对齐，可以参考代码：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step4/README.md#%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%B9%E9%BD%90%E9%AA%8C%E8%AF%81">学习率对齐验证文档</a>。</p><h3 id="3-7-正则化策略对齐"><a href="#3-7-正则化策略对齐" class="headerlink" title="3.7 正则化策略对齐"></a>3.7 正则化策略对齐</h3><p><strong>【基本流程】</strong></p><p>L2正则化策略用于模型训练，可以防止模型对训练数据过拟合，L1正则化可以用于得到稀疏化的权重矩阵，PaddlePaddle中有<code>paddle.regularizer.L1Decay</code>与<code>paddle.regularizer.L2Decay</code> API。PyTorch中，torch.optim集成的优化器只有L2正则化方法，直接在构建optimizer的时候，传入<code>weight_decay</code>参数即可。</p><p><strong>【注意事项】</strong></p><ul><li>PaddlePaddle的optimizer中支持L1Decay&#x2F;L2Decay。</li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/regularizer/L2Decay_cn.html">PaddlePaddle正则化API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p><h3 id="3-8-反向对齐"><a href="#3-8-反向对齐" class="headerlink" title="3.8 反向对齐"></a>3.8 反向对齐</h3><p><strong>【基本流程】</strong></p><p>此处可以通过numpy生成假的数据和label（推荐），也可以准备固定的真实数据。具体流程如下。</p><ol><li>检查两个代码的训练超参数全部一致，如优化器及其超参数、学习率、BatchNorm&#x2F;LayerNorm中的eps等。</li><li>将PaddlePaddle与PyTorch网络中涉及的所有随机操作全部关闭，如dropout、drop_path等，推荐将模型设置为eval模式（<code>model.eval()</code>）</li><li>加载相同的weight dict（可以通过PyTorch来存储随机的权重），将准备好的数据分别传入网络并迭代，观察二者loss是否一致（此处batch-size要一致，如果使用多个真实数据，要保证传入网络的顺序一致）</li><li>如果经过2轮以上，loss均可以对齐，则基本可以认为反向对齐。</li></ol><p><strong>【注意事项】</strong></p><ul><li>如果第一轮loss就没有对齐，则需要仔细排查一下模型前向部分。</li><li>如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证并反馈。</li></ul><p>梯度的打印方法示例代码如下所示，注释掉的内容即为打印网络中所有参数的梯度shape。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 代码地址：https://github.com/littletomatodonkey/AlexNet-Prod/blob/63184b258eda650e7a8b7f2610b55f4337246630/pipeline/Step4/AlexNet_paddle/train.py#L93</span><br>loss_list = []<br><span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iter):<br>    image = paddle.to_tensor(fake_data)<br>    target = paddle.to_tensor(fake_label)<br><br>    output = model(image)<br>    loss = criterion(output, target)<br>    loss.backward()<br>    <span class="hljs-comment"># for name, tensor in model.named_parameters():</span><br>    <span class="hljs-comment">#     grad = tensor.grad</span><br>    <span class="hljs-comment">#     print(name, tensor.grad.shape)</span><br>    <span class="hljs-comment">#     break</span><br>    optimizer.step()<br>    optimizer.clear_grad()<br>    loss_list.append(loss)<br></code></pre></td></tr></table></figure><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step4/README.md#%E5%8F%8D%E5%90%91%E5%AF%B9%E9%BD%90%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95">反向对齐操作文档</a>。</p><p><strong>【核验】</strong></p><p>对于待复现的项目，反向对齐核验流程如下。</p><ol><li>输入：fake data &amp; label</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体loss的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>bp_align_paddle.npy</code>和<code>bp_align_pytorch.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>bp_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>bp_align_paddle.npy</code>、<code>bp_align_pytorch.npy</code>与<code>bp_align_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li><li>注意：</li></ol><ul><li><ul><li>loss需要保存至少2轮以上。</li><li>在迭代的过程中，需要保证模型的batch size等超参数完全相同</li><li>在迭代的过程中，需要设置<code>model.eval()</code>，使用固定的假数据，同时加载相同权重的预训练模型。</li></ul></li></ul><h3 id="3-9-训练集数据读取对齐"><a href="#3-9-训练集数据读取对齐" class="headerlink" title="3.9 训练集数据读取对齐"></a>3.9 训练集数据读取对齐</h3><p><strong>【基本流程】</strong></p><p>该部分内容与3.2节内容基本一致，参考PyTorch的代码，实现训练集数据读取与预处理模块即可。</p><p><strong>【注意事项】</strong></p><p>该部分内容，可以参考3.8节的自测方法，将输入的<code>fake data &amp; label</code>替换为训练的dataloader，但是需要注意的是：</p><ul><li>在使用train dataloader的时候，建议设置random seed，对于PyTorch来说</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#initialize random seed</span><br>torch.manual_seed(config.SEED)<br>torch.cuda.manual_seed_all(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure><p>对于PaddlePaddle来说</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">paddle.seed(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html">PaddlePaddle vision高层API文档</a>与参考代码的数据预处理实现进行对齐，用之后的训练对齐统一验证该模块的正确性。</p><h3 id="3-10-网络初始化对齐"><a href="#3-10-网络初始化对齐" class="headerlink" title="3.10 网络初始化对齐"></a>3.10 网络初始化对齐</h3><p><strong>【基本流程】</strong></p><ul><li>下面给出了部分初始化API的映射表。</li></ul><table><thead><tr><th>PaddlePaddle API</th><th>PyTorch API</th></tr></thead><tbody><tr><td>paddle.nn.initializer.KaimingNormal</td><td>torch.nn.init.kaiming_normal_</td></tr><tr><td>paddle.nn.initializer.KaimingUniform</td><td>torch.nn.init.kaiming_uniform_</td></tr><tr><td>paddle.nn.initializer.XavierNormal</td><td>torch.nn.init.xavier_normal_</td></tr><tr><td>paddle.nn.initializer.XavierUniform</td><td>torch.nn.init.xavier_uniform_</td></tr></tbody></table><p><strong>【注意事项】</strong></p><ul><li>更多初始化API可以参考<a href="https://pytorch.org/docs/stable/nn.init.html">PyTorch初始化API文档</a>以及<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle初始化API文档</a>。</li></ul><p><strong>【实战】</strong></p><p>本部分对齐建议对照<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle 初始化API文档</a>与参考代码的初始化实现对齐。</p><h3 id="3-11-模型训练对齐"><a href="#3-11-模型训练对齐" class="headerlink" title="3.11 模型训练对齐"></a>3.11 模型训练对齐</h3><p><strong>【基本流程】</strong></p><p>完成前面的步骤之后，就可以开始全量数据的训练对齐任务了。按照下面的步骤进行训练对齐。</p><ol><li>准备train&#x2F;eval data, loader, model</li><li>对model按照论文所述进行初始化(如果论文中提到加载pretrain，则按需加载pretrained model)</li><li>加载配置，开始训练，迭代得到最终模型与评估指标，将评估指标使用reprod_log保存到文件中。</li><li>将PaddlePaddle提供的参考指标使用reprod_log提交到另一个文件中。</li><li>使用reprod_log排查diff，小于阈值，即可完成自测。</li></ol><p><strong>【注意事项】</strong></p><ul><li><p>【强烈】建议先做完反向对齐之后再进行模型训练对齐，二者之间的不确定量包括：数据集、PaddlePaddle与参考代码在模型training mode下的区别，初始化参数。</p></li><li><p>在训练对齐过程中，受到较多随机量的影响，精度有少量diff是正常的，以ImageNet1k数据集的分类为例，diff在0.15%以内可以认为是正常的，这里可以根据不同的任务，适当调整对齐检查的阈值(<code>ReprodDiffHelper.report</code>函数中的<code>diff_threshold</code>参数)。</p></li><li><p>训练过程中的波动是正常的，如果最终收敛结果不一致，可以 </p></li><li><ul><li>仔细排查Dropout、BatchNorm以及其他组网模块及超参是否无误。</li><li>基于参考代码随机生成一份预训练模型，转化为PaddlePaddle的模型，并使用PaddlePaddle加载训练，对比二者的收敛曲线与最终结果，排查初始化影响。</li><li>使用参考代码的Dataloader生成的数据，进行模型训练，排查train dataloader的影响。</li></ul></li></ul><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step5/README.md">训练对齐操作文档</a>。</p><p><strong>【核验】</strong></p><p>对于待复现的项目，训练对齐核验流程如下。</p><ol><li>输入：train&#x2F;eval dataloader, model</li><li>输出：</li></ol><ul><li><ul><li>PaddlePaddle：dict，key为保存值的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_paddle.npy</code>。</li><li>benchmark：dict，key为保存值的name（自定义），value为论文复现赛的评估指标要求的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_benchmark.npy</code>。</li></ul></li></ul><ol><li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>train_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li><li>提交内容：将<code>train_align_paddle.npy</code>、<code>train_align_benchmark.npy</code>与<code>train_align_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，最终一并打包上传即可。</li></ol><h3 id="3-12-规范训练日志"><a href="#3-12-规范训练日志" class="headerlink" title="3.12 规范训练日志"></a>3.12 规范训练日志</h3><p><strong>【背景】</strong></p><p>训练过程中，损失函数(<code>loss</code>)可以直接反映目前网络的收敛情况，数据耗时(<code>reader_cost</code>)对于分析GPU利用率非常重要，一个batch训练耗时(<code>batch_cost</code>)对于我们判断模型的整体训练时间非常重要，因此希望在训练中添加这些统计信息，便于分析模型的收敛和资源利用情况。</p><p><strong>【基本流程】</strong></p><ol><li>在训练代码中添加日志统计信息，对训练中的信息进行统计。</li></ol><ul><li>必选项：损失值<code>loss</code>, 训练耗时<code>batch_cost</code>, 数据读取耗时<code>reader_cost</code>。</li><li>建议项：当前<code>epoch</code>, 当前迭代次数<code>iter</code>，学习率(<code>lr</code>), 准确率(<code>acc</code>)等。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain">[2021/12/04 05:16:13] root INFO: [epoch 0, iter 0][TRAIN]avg_samples: 32.0 , avg_reader_cost: 0.0010543 sec, avg_batch_cost: 0.0111100 sec, loss: 0.3450000 , avg_ips: 2880.2952878 images/sec<br>[2021/12/04 05:16:13] root INFO: [epoch 0, iter 0][TRAIN]avg_samples: 32.0 , avg_reader_cost: 0.0010542 sec, avg_batch_cost: 0.0111101 sec, loss: 0.2450000 , avg_ips: 2880.2582019 images/sec<br></code></pre></td></tr></table></figure><ol><li>如果训练中同时包含评估过程，则也需要在日志里添加模型的<code>评估结果</code>信息。</li></ol><p><strong>【注意事项】</strong></p><ul><li>日志打印也比较耗时，这里不建议统计其耗时，防止对统计结果造成影响。</li></ul><p><strong>【实战】</strong></p><p>参考代码：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/d0eab851603a8d9097b1b8d6089f26d96c6707b0/pipeline/Step5/AlexNet_paddle/train.py#L204">train.py</a>。</p><p>具体地，规范化的训练日志可以按照如下所示的方式实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_one_epoch</span>(<span class="hljs-params">model,</span><br><span class="hljs-params">                    criterion,</span><br><span class="hljs-params">                    optimizer,</span><br><span class="hljs-params">                    data_loader,</span><br><span class="hljs-params">                    epoch,</span><br><span class="hljs-params">                    print_freq</span>):<br>    model.train()<br>    <span class="hljs-comment"># training log</span><br>    train_reader_cost = <span class="hljs-number">0.0</span><br>    train_run_cost = <span class="hljs-number">0.0</span><br>    total_samples = <span class="hljs-number">0</span><br>    acc = <span class="hljs-number">0.0</span><br>    reader_start = time.time()<br>    batch_past = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> batch_idx, (image, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data_loader):<br>        train_reader_cost += time.time() - reader_start<br>        train_start = time.time()<br>        output = model(image)<br>        loss = criterion(output, target)<br>        loss.backward()<br>        optimizer.step()<br>        optimizer.clear_grad()<br>        train_run_cost += time.time() - train_start<br>        acc = utils.accuracy(output, target).item()<br>        total_samples += image.shape[<span class="hljs-number">0</span>]<br>        batch_past += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> batch_idx &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> batch_idx % print_freq == <span class="hljs-number">0</span>:<br>            msg = <span class="hljs-string">&quot;[Epoch &#123;&#125;, iter: &#123;&#125;] acc: &#123;:.5f&#125;, lr: &#123;:.5f&#125;, loss: &#123;:.5f&#125;, avg_reader_cost: &#123;:.5f&#125; sec, avg_batch_cost: &#123;:.5f&#125; sec, avg_samples: &#123;&#125;, avg_ips: &#123;:.5f&#125; images/sec.&quot;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, batch_idx, acc / batch_past,<br>                optimizer.get_lr(),<br>                loss.item(), train_reader_cost / batch_past,<br>                (train_reader_cost + train_run_cost) / batch_past,<br>                total_samples / batch_past,<br>                total_samples / (train_reader_cost + train_run_cost))<br>            <span class="hljs-comment"># just log on 1st device</span><br>            <span class="hljs-keyword">if</span> paddle.distributed.get_rank() &lt;= <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(msg)<br>            sys.stdout.flush()<br>            train_reader_cost = <span class="hljs-number">0.0</span><br>            train_run_cost = <span class="hljs-number">0.0</span><br>            total_samples = <span class="hljs-number">0</span><br>            acc = <span class="hljs-number">0.0</span><br>            batch_past = <span class="hljs-number">0</span><br><br>        reader_start = time.time()<br></code></pre></td></tr></table></figure><h3 id="3-13-预测程序开发"><a href="#3-13-预测程序开发" class="headerlink" title="3.13 预测程序开发"></a>3.13 预测程序开发</h3><p><strong>【基本流程】</strong></p><p>模型训练完成之后，对图像使用该模型基于训练引擎进行预测，主要包含</p><ol><li>定义模型结构，加载模型权重；</li><li>加载图像，对其进行数据预处理；</li><li>模型预测；</li><li>对模型输出进行后处理，获取最终输出结果。</li></ol><p><strong>【注意事项】</strong></p><ul><li>在模型评估过程中，为了保证数据可以组batch，我们一般会使用resize&#x2F;crop&#x2F;padding等方法去保持尺度的一致性，在预测推理过程中，需要注意crop是否合适，比如OCR识别任务中，crop的操作会导致识别结果不全。</li></ul><p><strong>【实战】</strong></p><p>AlexNet的预测程序：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/tipc/pipeline/Step5/AlexNet_paddle/tools/predict.py">predict.py</a>。</p><p><strong>【核验】</strong></p><p>预测程序按照文档中的命令操作可以正常跑通，文档中给出预测结果可视化结果或者终端输出结果。</p><h3 id="3-14-单机多卡训练"><a href="#3-14-单机多卡训练" class="headerlink" title="3.14 单机多卡训练"></a>3.14 单机多卡训练</h3><p>如果希望使用单机多卡提升训练效率，可以从以下几个过程对代码进行修改。</p><h4 id="3-14-1-数据读取"><a href="#3-14-1-数据读取" class="headerlink" title="3.14.1 数据读取"></a>3.14.1 数据读取</h4><p>对于PaddlePaddle来说，多卡数据读取这块主要的变化在sampler</p><p>对于单机单卡，sampler实现方式如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train_sampler = paddle.io.RandomSampler(dataset)<br>train_batch_sampler = paddle.io.BatchSampler(<br>    sampler=train_sampler, batch_size=args.batch_size)<br></code></pre></td></tr></table></figure><p>对于单机多卡任务，sampler实现方式如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">train_batch_sampler = paddle.io.DistributedBatchSampler(<br>        dataset=dataset,<br>        batch_size=args.batch_size,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">False</span><br>    )<br></code></pre></td></tr></table></figure><p>注意：在这种情况下，单机多卡的代码仍然能够以单机单卡的方式运行，因此建议以这种sampler方式进行论文复现。</p><h4 id="3-14-2-多卡模型初始化"><a href="#3-14-2-多卡模型初始化" class="headerlink" title="3.14.2 多卡模型初始化"></a>3.14.2 多卡模型初始化</h4><p>如果以多卡的方式运行，需要初始化并行训练环境，代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>        paddle.distributed.init_parallel_env()<br></code></pre></td></tr></table></figure><p>在模型组网并初始化参数之后，需要使用<code>paddle.DataParallel()</code>对模型进行封装，使得模型可以通过数据并行的模式被执行。代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>    model = paddle.DataParallel(model)<br></code></pre></td></tr></table></figure><h4 id="3-14-3-模型保存、日志保存等其他模块"><a href="#3-14-3-模型保存、日志保存等其他模块" class="headerlink" title="3.14.3 模型保存、日志保存等其他模块"></a>3.14.3 模型保存、日志保存等其他模块</h4><p>以模型保存为例，我们只需要在0号卡上保存即可，否则多个trainer同时保存的话，可能会造成写冲突，导致最终保存的模型不可用。</p><h4 id="3-14-4-程序启动方式"><a href="#3-14-4-程序启动方式" class="headerlink" title="3.14.4 程序启动方式"></a>3.14.4 程序启动方式</h4><p>对于单机单卡，启动脚本如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CUDA_VISIBLE_DEVICES=0<br>python3.7 train.py \<br>    --data-path /paddle/data/ILSVRC2012_torch \<br>    --lr 0.00125 \<br>    --batch-size 32 \<br>    --output-dir &quot;./output/&quot;<br></code></pre></td></tr></table></figure><p>对于单机多卡（示例中为8卡训练），启动脚本如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7<br><br>python3.7 -m paddle.distributed.launch \<br>    --gpus=&quot;0,1,2,3,4,5,6,7&quot; \<br>    train.py \<br>    --data-path /paddle/data/ILSVRC2012_torch \<br>    --lr 0.01 \<br>    --batch-size 32 \<br>    --output-dir &quot;./output/&quot;<br></code></pre></td></tr></table></figure><p>注意：这里8卡训练时，虽然单卡的batch size没有变化(32)，但是总卡的batch size相当于是单卡的8倍，因此学习率也设置为了单卡时的8倍。</p><p><strong>【实战】</strong></p><p>本部分可以参考文档：<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step5/AlexNet_paddle/shell/train_dist.sh">单机多卡训练脚本</a>。</p><h2 id="4-论文复现注意事项与FAQ"><a href="#4-论文复现注意事项与FAQ" class="headerlink" title="4. 论文复现注意事项与FAQ"></a>4. 论文复现注意事项与FAQ</h2><h3 id="4-1-通用注意事项"><a href="#4-1-通用注意事项" class="headerlink" title="4.1 通用注意事项"></a>4.1 通用注意事项</h3><ul><li>需要仔细对照PaddlePaddle与参考代码的优化器参数实现，确保优化器参数严格对齐。</li><li>如果遇到一些Paddle不支持的API操作，可以尝试使用替代实现进行复现。如下面的PyTorch代码，PaddlePaddle中可以通过slice + concat API的组合形式进行功能实现。同时，对于这个问题，建议优先给Paddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，开发人员会根据优先级进行开发。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.stack([<br>    per_locations[:, <span class="hljs-number">0</span>] - per_box_regression[:, <span class="hljs-number">0</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] - per_box_regression[:, <span class="hljs-number">1</span>],<br>    per_locations[:, <span class="hljs-number">0</span>] + per_box_regression[:, <span class="hljs-number">2</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] + per_box_regression[:, <span class="hljs-number">3</span>],<br>], dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><ul><li><p>如果遇到Paddle不包含的OP或者API，比如(1) 如果是某些算法实现存在调用了外部OP，而且Paddle也不包含该OP实现；(2) 其他框架存在的API或者OP，但是Paddle中没有这些OP。此时： </p></li><li><ul><li>对于Paddle资深用户来说，可以尝试使用Paddle的自定义算子功能，存在一定的代码开发量。</li><li>对于初学者来说，可以给Paddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，Paddle开发人员会根据优先级进行实现。</li></ul></li><li><p>PaddlePaddle与PyTorch对于不同名称的API，实现的功能可能是相同的，复现的时候注意，比如<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/lr/StepDecay_cn.html#stepdecay">paddle.optimizer.lr.StepDecay</a>与<a href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR">torch.optim.lr_scheduler.StepLR</a> ，关于PaddlePaddle与PyTorch更多API的映射关系可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">API映射表</a>。 </p></li><li><p>对于PaddlePaddle来说，通过<code>paddle.set_device</code>函数（全局）来确定模型结构是运行在什么设备上，对于torch来说，是通过<code>model.to(&quot;device&quot;)</code> （局部）来确定模型结构的运行设备，这块在复现的时候需要注意。 </p></li><li><p>安装paddle的develop版本：在 Paddle 修复了框架的问题或者新增了API和功能之后，如果需要马上使用，可以采用以下方式安装最新的 develop 版本： </p></li><li><ul><li>进入 <a href="https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html">Paddle 官网</a>，选择develop版本，并根据自己的情况选择其他字段，根据生成的安装信息安装，当选择 Linux-pip-CUDA10.2字段后，就可以按照下面的信息安装。</li></ul></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python -m pip install paddlepaddle-gpu==0.0.0.post102 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html<br></code></pre></td></tr></table></figure><ul><li><ul><li>如果不确定自己安装的是否是最新版本，可以进入<a href="https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html">网站</a>下载对应的包并查看时间戳。</li></ul></li><li><p>如果遇到复现时间较长的论文，我们建议： </p></li><li><ul><li>根据自己的时间、资源、战略部署评估是否复现这个论文复现；</li><li>在决定复现的情况下，参照本复现指南中的对齐操作对模型、数据、优化方式等对齐，以最快的时间排除问题。</li></ul></li></ul><h3 id="4-2-模型结构对齐"><a href="#4-2-模型结构对齐" class="headerlink" title="4.2 模型结构对齐"></a>4.2 模型结构对齐</h3><h4 id="4-2-1-API"><a href="#4-2-1-API" class="headerlink" title="4.2.1 API"></a>4.2.1 API</h4><ul><li><p>对于 <code>paddle.nn.Linear</code> 层的weight参数，PaddlePaddle与PyTorch的保存方式不同，在转换时需要进行转置，示例代码可以参考<a href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/e3855e0b1992332c2765ccf627d0c5f5f68232fe/pipeline/weights/torch2paddle.py#L19">AlexNet权重转换脚本</a>。</p></li><li><p><code>paddle.nn.BatchNorm2D</code> 包含4个参数<code>weight</code>, <code>bias</code>, <code>_mean</code>, <code>_variance</code>，torch.nn.BatchNorm2d包含4个参数<code>weight</code>,  <code>bias</code>, <code>running_mean</code>, <code>running_var</code>, <code>num_batches_tracked</code>。 其中，<code>num_batches_tracked</code>在PaddlePaddle中没有用到，剩下4个的对应关系为 </p></li><li><ul><li><code>weight</code> -&gt; <code>weight</code></li><li><code>bias</code> -&gt; <code>bias</code></li><li><code>_variance</code> -&gt; <code>running_var</code></li><li><code>_mean</code> -&gt; <code>running_mean</code></li></ul></li><li><p><code>paddle.nn.AvgPool2D</code>需要将 <code>exclusive</code> 参数设为 <code>False</code> ，结果才能 PyTorch 的默认行为一致。</p></li><li><p><code>torch.masked_fill</code>函数的功能目前可以使用<code>paddle.where</code>进行实现，可以参考：<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/faq/train_cn.html#paddletorch-masked-fillapi">链接</a>。</p></li><li><p><code>pack_padded_sequence</code>和<code>pad_packed_sequence</code>这两个API目前PaddlePaddle中没有实现，可以直接在RNN或者LSTM的输入中传入<code>sequence_length</code>来实现等价的功能。</p></li></ul><h4 id="4-2-2-权重转换"><a href="#4-2-2-权重转换" class="headerlink" title="4.2.2 权重转换"></a>4.2.2 权重转换</h4><ul><li>在权重转换的时候，不能只关注参数的名称，比如说有些<code>paddle.nn.Linear</code>层，但是定义的变量名称为<code>conv</code>，这种也是需要进行权重转置的。</li><li>权重转换时，建议同时打印 Paddle 和 PyTorch 对应权重的shape，以防止名称相似但是shape不同的参数权重转换报错。</li></ul><h4 id="4-2-3-模型组网正确性验证"><a href="#4-2-3-模型组网正确性验证" class="headerlink" title="4.2.3 模型组网正确性验证"></a>4.2.3 模型组网正确性验证</h4><ul><li>在论文复现的过程中，可能会遇到一些经典的模型结构，比如ResNet等，Paddle官方也提供了ResNet的实现，但是这里建议自己根据PyTorch代码重新实现一遍，一方面是对整体的模型结构更加熟悉，另一方面也保证模型结构和权重完全对齐。</li><li>在复杂的网络结构中，如果前向结果对不齐，可以按照模块排查问题，比如依次获取backbone、neck、head输出等，看下问题具体出现在哪个子模块，再进到子模块详细排查。</li><li>网络结构对齐后，尽量使用训练好的预训练模型和真实的图片进行前向diff计算，这样更准确。</li></ul><h3 id="4-3-验证-测试集数据读取对齐"><a href="#4-3-验证-测试集数据读取对齐" class="headerlink" title="4.3 验证&#x2F;测试集数据读取对齐"></a>4.3 验证&#x2F;测试集数据读取对齐</h3><ul><li>如果使用 PaddlePaddle 提供的数据集API，比如 <code>paddle.vision.datasets.Cifar10</code>等，可能无法完全与参考代码在数据顺序上保持一致，但是这些数据集的实现都是经过广泛验证的，可以使用。此时对数据预处理和后处理进行排查就好。<code>数据集+数据处理</code>的部分可以通过评估指标对齐完成自查。</li><li>需要仔细排查数据预处理，不仅包含的预处理方法相同，也需要保证预处理的流程相同，比如先padding再做归一化与先做归一化再padding，得到的结果是不同的。</li></ul><h3 id="4-4-评估指标对齐"><a href="#4-4-评估指标对齐" class="headerlink" title="4.4 评估指标对齐"></a>4.4 评估指标对齐</h3><ul><li>真实数据评估时，需要注意评估时 <code>paddle.io.DataLoader</code> 的 <code>drop_last</code> 参数是否打开(文档<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#dataloader">链接</a>)，复现代码需要与参考代码保持一致，否则最后不够batch-size的数据的评估会有diff。</li><li>在识别或者检索过程中，为了加速评估过程，往往会将评估函数由CPU实现改为GPU实现，由此会带来评估函数输出的不一致。这是由于sort函数对于相同值的排序结果不同带来的。在复现的过程中，如果可以接受轻微的指标不稳定，可以使用PaddlePaddle的sort函数，如果对于指标非常敏感，同时对速度性能要求很高，可以给PaddlePaddle提<a href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，由研发人员高优开发。</li><li>在检测任务中，评估流程往往和训练流程有一定差异，例如RPN阶段NMS的参数等，这里需要仔细检查评估时的超参数，不要将训练超参和评估超参弄混淆。</li><li>在OCR等任务中，需要注意评估过程也会对gt信息进行修正，比如大小写等，也会过滤掉一些样本，这里需要注意过滤规则，确保有效评估数据集一致。</li></ul><h3 id="4-5-损失函数对齐"><a href="#4-5-损失函数对齐" class="headerlink" title="4.5 损失函数对齐"></a>4.5 损失函数对齐</h3><ul><li>部分算法的损失函数中会用到 bool 索引，这时候可以使用<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/where_cn.html#where">paddle.where</a> 代替。</li><li><code>paddle.nn.CrossEntropyLoss</code> 默认是在最后一维(axis&#x3D;-1)计算损失函数，而 <code>torch.nn.CrossEntropyLoss</code> 是在axis&#x3D;1的地方计算损失函数，因此如果输入的维度大于2，这里需要保证计算的维(axis)相同，否则可能会出错。</li><li>在生成模型中会遇到梯度损失，需要对模型中的算子求二次梯度，目前<code>MaxPooling</code>暂时不支持二次梯度，如果复现的过程中遇到了需要对<code>MaxPooling</code>求二次梯度的情况，可以和Paddle官方开发同学反馈，进一步确认解决方案。</li><li>在保存损失函数值的时候，注意要使用<code>paddle.no_grad</code>，或者仅仅保存转换成 numpy 的数组，避免损失没有析构导致内存泄漏问题。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 错误示范</span><br>loss = celoss(pred, label)<br>avg_loss += loss<br><span class="hljs-comment"># 正确示范1</span><br>loss = celoss(pred, label)<br>avg_loss += loss.numpy()<br><span class="hljs-comment"># 正确示范2</span><br>loss = celoss(pred, label)<br><span class="hljs-keyword">with</span> paddle.no_grad()<br>    avg_loss += loss<br></code></pre></td></tr></table></figure><ul><li>目前PaddlePaddle中没有HingeEmbeddingLoss API，可以使用组合的方式进行实现，参考实现：<a href="https://github.com/ImportPaddle/DiscoGAN-Paddle/blob/main/discogan/loss_fn.py">链接</a>。</li></ul><h3 id="4-6-优化器对齐"><a href="#4-6-优化器对齐" class="headerlink" title="4.6 优化器对齐"></a>4.6 优化器对齐</h3><ul><li>Paddle目前支持在 <code>optimizer</code> 中通过设置 <code>params_groups</code> 的方式设置不同参数的更新方式，可以参考<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/optimizer/optimizer.py#L107">代码示例</a> 。</li><li>有些模型训练时，会使用梯度累加策略，即累加到一定step数量之后才进行参数更新，这时在实现上需要注意对齐。</li><li>在某些任务中，比如说深度学习可视化、可解释性等任务中，一般只要求模型前向过程，不需要训练，此时优化器、学习率等用于模型训练的模块对于该类论文复现是不需要的。</li><li>在图像分类领域，大多数Vision Transformer模型都采用了AdamW优化器，并且会设置weigh decay，同时部分参数设置为no weight decay，例如位置编码的参数通常设置为no weight decay，no weight decay参数设置不正确，最终会有明显的精度损失，需要特别注意。一般可以通过分析模型权重来发现该问题，分别计算官方模型和复现模型每层参数权重的平均值、方差，对每一层依次对比，有显著差异的层可能存在问题，因为在weight decay的作用下，参数权重数值会相对较小，而未正确设置no weight decay，则会造成该层参数权重数值异常偏小。</li><li>在OCR识别等任务中，<code>Adadelta</code>优化器常常被使用，该优化器与PyTorch实现目前稍有不同，但是不影响模型训练精度对齐，在做前反向对齐时，需要注意可以将该优化器替换为Adam等优化器（PaddlePaddle与参考代码均需要替换）；对齐完成之后，再使用<code>Adadelta</code>优化器进行训练对齐。</li></ul><h3 id="4-7-学习率对齐"><a href="#4-7-学习率对齐" class="headerlink" title="4.7 学习率对齐"></a>4.7 学习率对齐</h3><ul><li>PaddlePaddle 中参数的学习率受到优化器学习率和<code>ParamAttr</code>中设置的学习率影响，因此跟踪学习率需要将二者结合进行跟踪。</li><li>对于复现代码和参考代码，学习率在整个训练过程中在相同的轮数相同的iter下应该保持一致，可以通过<code>reprod_log</code>工具、打印学习率值或者可视化二者学习率的log来查看diff。</li><li>有些网络的学习率策略比较细致，比如带warmup的学习率策略，这里需要保证起始学习率等参数都完全一致。</li><li><code>torch.optim.lr_scheduler.MultiplicativeLR</code> API目前PaddlePaddle中没有实现，可以使用<code>paddle.optimizer.lr.LambdaDecay</code>替换实现，参考代码：<a href="https://github.com/Paddle-Team-7/PixelCNN-Paddle/blob/607ef1d1ca6a489cecdcd2182d3acc5b2df7c779/src/pixel_cnn.py#L161">链接</a>。</li></ul><h3 id="4-8-正则化策略对齐"><a href="#4-8-正则化策略对齐" class="headerlink" title="4.8 正则化策略对齐"></a>4.8 正则化策略对齐</h3><ul><li>在如Transformer或者少部分CNN模型中，存在一些参数不做正则化(正则化系数为0)的情况。这里需要找到这些参数并对齐取消实施正则化策略，可以参考<a href="https://github.com/PaddlePaddle/PaddleClas/blob/release%2F2.3/ppcls/arch/backbone/model_zoo/resnest.py#L72">这里</a>，对特定参数进行修改。</li></ul><h3 id="4-9-反向对齐"><a href="#4-9-反向对齐" class="headerlink" title="4.9 反向对齐"></a>4.9 反向对齐</h3><ul><li>Paddle打印反向和参数更新，可以参考<a href="https://github.com/jerrywgz/PaddleDetection/blob/debug_gfl/ppdet/modeling/backbones/resnet.py#L581">代码实例</a>；PyTorch打印反向和参数更新，可以参考<a href="https://github.com/jerrywgz/mmdetection/blob/debug_gfl/mmdet/models/backbones/resnet.py#L630">代码实例</a>。</li><li>反向对齐时，如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证。第3章中给出了获取所有参数的梯度方法，如果只希望打印特定参数的梯度，可以用下面的方式。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> paddle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_hook_fn</span>(<span class="hljs-params">grad</span>):<br>    <span class="hljs-built_in">print</span>(grad)<br><br>x = paddle.to_tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>], stop_gradient=<span class="hljs-literal">False</span>)<br>h = x.register_hook(print_hook_fn)<br>w = x * <span class="hljs-number">4</span><br>w.backward()<br><span class="hljs-comment"># backward之后会输出下面的内容</span><br><span class="hljs-comment">#     Tensor(shape=[4], dtype=float32, place=CPUPlace, stop_gradient=False,</span><br><span class="hljs-comment">#            [4., 4., 4., 4.])</span><br></code></pre></td></tr></table></figure><h3 id="4-10-训练集数据读取对齐"><a href="#4-10-训练集数据读取对齐" class="headerlink" title="4.10 训练集数据读取对齐"></a>4.10 训练集数据读取对齐</h3><h4 id="4-10-1-API"><a href="#4-10-1-API" class="headerlink" title="4.10.1 API"></a>4.10.1 API</h4><ul><li>在前向过程中，如果数据预处理过程运行出错，请先将 <code>paddle.io.DataLoader</code> 的 <code>num_workers</code> 参数设为0，然后根据单个进程下的报错日志定位出具体的bug。</li><li>如果使用PaddlePaddle提供的数据集API，比如<code>paddle.vision.datasets.Cifar10</code>等，可能无法完全与参考代码在数据顺序上保持一致，如果是全量数据使用，对结果不会有影响，如果是按照比例选取子集进行训练，则建议重新根据参考代码实现数据读取部分，保证子集完全一致。</li></ul><h4 id="4-10-2-数据预处理"><a href="#4-10-2-数据预处理" class="headerlink" title="4.10.2 数据预处理"></a>4.10.2 数据预处理</h4><ul><li>数据读取需要注意图片读取方式是opencv还是PIL.Image，图片格式是RGB还是BGR，复现时，需要保证复现代码和参考代码完全一致。</li><li>如果数据处理过程中涉及到随机数生成，建议固定seed (<code>np.random.seed(0)</code>, <code>random.seed(0)</code>)，查看复现代码和参考代码处理后的数据是否有diff。</li><li>不同的图像预处理库，使用相同的插值方式可能会有diff，建议使用相同的库对图像进行resize。</li><li>视频解码时，不同库解码出来的图像数据会有diff，注意区分解码库是opencv、decord还是pyAV，需要保证复现代码和参考代码完全一致。</li></ul><h3 id="4-11-网络初始化对齐"><a href="#4-11-网络初始化对齐" class="headerlink" title="4.11 网络初始化对齐"></a>4.11 网络初始化对齐</h3><h4 id="4-11-1-网络初始化通用问题"><a href="#4-11-1-网络初始化通用问题" class="headerlink" title="4.11.1 网络初始化通用问题"></a>4.11.1 网络初始化通用问题</h4><ul><li>对于不同的深度学习框架，网络初始化在大多情况下，即使值的分布完全一致，也无法保证值完全一致，这里也是论文复现中不确定性比较大的地方。如果十分怀疑初始化导致的问题，建议将参考的初始化权重转成paddle模型，加载该初始化模型训练，看下收敛精度。 </li><li>Paddle中目前没有<code>torch.nn.init.constant_()</code>的方法，如果希望对参数赋值为常数，可以使用<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/initializer/Constant_cn.html#constant">paddle.nn.initializer.Constant</a>API；或者可以参考下面的实现。更加具体的解释可以参考：<a href="https://github.com/PaddlePaddle/Paddle/issues/37578">链接</a>。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Define the linear layer.</span><br>m = paddle.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(m.bias)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Layer):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;set m.bias&quot;</span>)<br>    m.bias.set_value(np.ones(shape=m.bias.shape, dtype=<span class="hljs-string">&quot;float32&quot;</span>))<br>    <span class="hljs-built_in">print</span>(m.bias)<br></code></pre></td></tr></table></figure><h4 id="4-11-2-细分场景特定问题"><a href="#4-11-2-细分场景特定问题" class="headerlink" title="4.11.2 细分场景特定问题"></a>4.11.2 细分场景特定问题</h4><ul><li>CNN对于模型初始化相对来说没有那么敏感，在迭代轮数与数据集足够的情况下，最终精度指标基本接近；而transformer系列模型对于初始化比较敏感，在transformer系列模型训练对齐过程中，建议对这一块进行重点检查。</li><li>生成模型尤其是超分模型，对初始化比较敏感，建议对初始化重点检查。</li><li>领域自适应算法由于需要基于初始模型生成伪标签，因此对初始网络敏感，建议加载预训练的模型进行训练。</li></ul><h3 id="4-12-模型训练对齐"><a href="#4-12-模型训练对齐" class="headerlink" title="4.12 模型训练对齐"></a>4.12 模型训练对齐</h3><h4 id="4-12-1-训练对齐通用问题"><a href="#4-12-1-训练对齐通用问题" class="headerlink" title="4.12.1 训练对齐通用问题"></a>4.12.1 训练对齐通用问题</h4><ul><li><p>有条件的话，复现工作之前最好先基于官方代码完成训练，保证与官方指标能够对齐，并且将训练策略和训练过程中的关键指标记录保存下来，比如每个epoch的学习率、Train Loss、Eval Loss、Eval Acc等，在复现网络的训练过程中，将关键指标保存下来，这样可以将两次训练中关键指标的变化曲线绘制出来，能够很方便的进行对比。</p></li><li><p>训练过程中可以对loss或者acc进行可视化，和竞品loss或者acc进行直观的对比；如果训练较大的数据集，1次完整训练的成本比较高，此时可以隔一段时间查看一下，如果精度差异比较大，建议先停掉实验，排查原因。</p></li><li><p>如果训练的过程中出nan，一般是因为除0或者log0的情况， 可以着重看下几个部分： </p></li><li><ul><li>如果有预训练模型的话，可以确认下是否加载正确</li><li>确认下reader的预处理中是否会出现box（或mask）为空的情况</li><li>模型结构中计算loss的部分是否有考虑到正样本为0的情况</li><li>也可能是某个API的数值越界导致的，可以测试较小的输入是否还会出现nan。</li></ul></li><li><p>如果训练过程中出现不收敛的情况，可以 </p></li><li><ul><li>简化网络和数据，实验是否收敛；</li><li>如果是基于原有实现进行改动，可以尝试控制变量法，每次做一个改动，逐个排查；</li><li>检查学习率是否过大、优化器设置是否合理，排查下weight decay是否设置正确；</li><li>保存不同step之间的模型参数，观察模型参数是否更新。</li></ul></li></ul><h4 id="4-12-2-细分场景特定问题"><a href="#4-12-2-细分场景特定问题" class="headerlink" title="4.12.2 细分场景特定问题"></a>4.12.2 细分场景特定问题</h4><ul><li>小数据上指标波动可能比较大，时间允许的话，可以跑多次实验，取平均值。</li><li>transformer 系列模型对于数据增广与模型初始化非常敏感，因此在保证前反向对齐后，如果训练仍无法对齐，可以考虑使用官方的PyTorch模型训练代码，结合复现的Paddle组网代码进行训练，这样可以验证是否是数据预处理&#x2F;数据增强策略存在问题。</li><li>检测、分割等任务中，训练通常需要加载backbone的权重作为预训练模型，注意在完成模型对齐后，将转换的权重修改为backbone权重。</li><li>生成任务中，训练时经常需要固定一部分网络参数。对于一个参数<code>param</code>，可以通过<code>param.trainable = False</code>来固定。</li><li>在训练GAN时，通常通过GAN的loss较难判断出训练是否收敛，建议每训练几次迭代保存一下训练生成的图像，通过可视化判断训练是否收敛。</li><li>在训练GAN时，如果PaddlePaddle实现的代码已经可以与参考代码完全一致，参考代码和PaddlePaddle代码均难以收敛，则可以在训练的时候，可以判断一下loss，如果loss大于一个阈值或者直接为NAN，说明训崩了，就终止训练，使用最新存的参数重新继续训练。可以参考该链接的实现：<a href="https://github.com/JennyVanessa/Paddle-GI">链接</a>。</li></ul><h3 id="4-13-规范训练日志"><a href="#4-13-规范训练日志" class="headerlink" title="4.13 规范训练日志"></a>4.13 规范训练日志</h3><ul><li><code>autolog</code>支持训练和预测的日志规范化，更多关于<code>autolog</code>的使用可以参考：<a href="https://github.com/LDOUBLEV/AutoLog%E3%80%82">https://github.com/LDOUBLEV/AutoLog。</a></li></ul><h3 id="4-14-预测程序开发"><a href="#4-14-预测程序开发" class="headerlink" title="4.14 预测程序开发"></a>4.14 预测程序开发</h3><h3 id="4-15-常见bug汇总"><a href="#4-15-常见bug汇总" class="headerlink" title="4.15 常见bug汇总"></a>4.15 常见bug汇总</h3><p>在论文复现中，可能因为各种原因出现报错，下面我们列举了常见的问题和解决方法，从而提供debug的方向：</p><h4 id="4-15-1-显存泄露"><a href="#4-15-1-显存泄露" class="headerlink" title="4.15.1 显存泄露"></a>4.15.1 显存泄露</h4><p>显存泄露会在 <code>nvidia-smi</code> 等命令下，明显地观察到显存的增加，最后会因为 <code>out of memory</code> 的错误而程序终止。</p><ul><li>可能原因：</li></ul><ol><li>Tensor 切片的时候增加变量引用，导致显存增加。解决方法如下：<br>   使用 where, gather 函数替代原有的 slice 方式：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a = paddle.<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)<br>c = paddle.ones([<span class="hljs-number">3</span>])<br>b = a&gt;<span class="hljs-number">1</span><br><span class="hljs-comment"># 会增加引用的一种写法</span><br>c[b] = <span class="hljs-number">0</span><br><span class="hljs-comment"># 修改后</span><br>paddle.where(b, paddle.zeros(c.shape), c)<br></code></pre></td></tr></table></figure><h4 id="4-15-2-内存泄露"><a href="#4-15-2-内存泄露" class="headerlink" title="4.15.2 内存泄露"></a>4.15.2 内存泄露</h4><p>内存泄露和显存泄露相似，并不能立即察觉，而是在使用 <code>top</code> 命令时，观察到内存显著增加，最后会因为 <code>can&#39;t allocate memory</code> 的错误而程序终止，如图所示是 <code>top</code> 命令下观察内存变化需要检查的字段。</p><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240110100108616.png" alt="image-20240110100108616"></p><p>可能原因：</p><ol><li>对在计算图中的 tensor 进行了不需要的累加、保存等操作，导致反向传播中计算图没有析构，解决方法如下：<br>   <strong>预测阶段</strong>：在predict函数上增加装饰器@paddle.no_grad()；在预测部分的代码前加上 with paddle.no_grad()<br>   <strong>训练阶段</strong>：对于不需要进行加入计算图的计算，将tensor detach出来；对于不需要使用tensor的情形，将 tensor 转换为numpy进行操作，例如下面的代码：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">cross_entropy_loss = paddle.nn.CrossEntropyLoss()<br>loss = cross_entropy_loss(pred, gt)<br><span class="hljs-comment"># 会导致内存泄露的操作</span><br>loss_total += loss<br><span class="hljs-comment"># 修改后</span><br>loss_total += loss.numpy() <span class="hljs-comment"># 如果可以转化为numpy</span><br>loss_total += loss.detach().clone() <span class="hljs-comment"># 如果需要持续使用tensor</span><br></code></pre></td></tr></table></figure><p>排查方法：</p><ol><li>在没有使用 paddle.no_grad 的代码中，寻找对模型参数和中间计算结果的操作；</li><li>考虑这些操作是否应当加入计算图中（即对最后损失产生影响）；</li><li>如果不需要，则需要对操作中的参数或中间计算结果进行<code>.detach().clone()</code>或者<code>.numpy</code> 后操作。</li></ol><h4 id="4-15-3-dataloader-加载数据时间长"><a href="#4-15-3-dataloader-加载数据时间长" class="headerlink" title="4.15.3 dataloader 加载数据时间长"></a>4.15.3 dataloader 加载数据时间长</h4><ul><li><strong>解决方式</strong>：增大 num_worker 的值，提升io速度，一般建议设置 4 或者 8。</li></ul><h4 id="4-15-4-单机多卡报错信息不明确"><a href="#4-15-4-单机多卡报错信息不明确" class="headerlink" title="4.15.4 单机多卡报错信息不明确"></a>4.15.4 单机多卡报错信息不明确</h4><ul><li><strong>解决方式</strong>：前往 log 下寻找 worklog.x 进行查看，其中 worklog.x 代表第 x 卡的报错信息。</li></ul><h2 id="来源："><a href="#来源：" class="headerlink" title="来源："></a>来源：</h2><p><a href="https://github.com/PaddlePaddle/">https://github.com/PaddlePaddle/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文复现 </tag>
            
            <tag> paddle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python内存管理</title>
      <link href="/2024/01/09/python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
      <url>/2024/01/09/python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h2><p>python中的内存分配采用<strong>内存池</strong>的方式。（ 内存池：当创建大量消耗小内存的对象时，频繁调用new&#x2F;malloc会导致大量的内存碎片，致使效率降低。内存池的作用就是预先在内存中申请一定数量的，大小相等的内存块留作备用，当有新的内存需求时，就先从内存池中分配内存给这个需求，不够之后再申请新的内存。这样做最显著的优势就是能够减少内存碎片，提升效率。)</p><p>如图，为cpython(python解释器的内存架构图)：</p><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1704788303972-1c525237-a1d9-4f99-b193-4c4607094a94.png" alt="img"></p><ul><li>level 0 以下为系统层内存管理；python实现的内存管理机制主要位于level 1~level 3;</li><li>level 3: python对于每一类内置的对象（int、float、list、dict、string）设置<strong>对象间独立</strong>的私有内存池，即内存池不共享，int释放的内存，不会被分配给float使用；</li><li>level 2: 当申请的内存大小小于256KB时，内存分配主要由 Python 对象分配器（Python’s object allocator）实施;</li><li>level 1: 当申请的内存大小大于256KB时，由Python原生的内存分配器进行分配，本质上是调用C标准库中的malloc&#x2F;realloc等函数;</li></ul><h2 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h2><p>在内存回收方面，python同样使用内存池机制释放内存，当对象引用计数变为0，调用析构函数，从内存池申请到的内存会被归还到内存池中，以避免频繁地申请和释放动作。</p><p>标准的 CPython GC 有两个组件：</p><ul><li>**引用计数收集器(reference counting collector)**：主要的、基础模块、不可控，不能禁用。</li><li>**分代垃圾收集器(generational garbage collector)**：辅助的、可以手动触发和禁用，即 gc module。</li></ul><p>CPython GC 的策略是：</p><ol><li>对每个对象维护引用计数</li><li>通过一个辅助算法来定期检测循环引用，释放无用对象</li><li>引入分代策略来优化此检测，提高性能</li></ol><h3 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h3><p>顾名思义，引用计数即记录对象被其他使用的对象引用的次数。python设置内部跟踪变量即引用计数器，记录每个变量有多少个引用。当某个对象的引用计数为0时，就进入垃圾回收队列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> sys<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)  <span class="hljs-comment">## 获取对象a的引用次数</span><br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>b=a<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">3</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> b  <span class="hljs-comment">## 删除b的引用</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>c=<span class="hljs-built_in">list</span>()<br><span class="hljs-meta">&gt;&gt;&gt; </span>c.append(a) <span class="hljs-comment">## 加入到容器中</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">3</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> c  <span class="hljs-comment">## 删除容器，引用-1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>b=a<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">3</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a=[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]  <span class="hljs-comment">## 重新赋值</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>注：<strong>当把a作为参数传递给getrefcount时，会产生一个临时的引用，因此得出来的结果比真实情况+1</strong></p><p><strong>引用计数增加：</strong></p><ul><li>赋值运算符（例如：a&#x3D;[1,2]）</li><li>参数传递</li><li>将对象（作为元素）append 到容器中（例如：c.append(a)）</li></ul><p><strong>引用计数减少：</strong></p><ul><li>使用del语句对对象别名显式的销毁(例如：del b)</li><li>对象所在的容器被销毁或从容器中删除对象（例如：del c ）</li><li>引用超出作用域或被重新赋值（例如：a&#x3D;[3,4]）</li></ul><p><strong>全局变量：</strong></p><ul><li><p>全局变量会一直存在直到 Python 进程结束为止。因此，由全局变量引用的对象的引用计数永远不会降为零，所有全局变量都存储在字典中，你可以通过调用 globals() 函数来获取它们。</p></li><li><p>在某一个『块』中定义的局部变量，如 function、class 或 with（context’s enter&#x2F;exit) 语句具有局部作用域，当解释器从该块中退出时，会释放在该块内部创建的局部变量及其引用。</p></li></ul><h3 id="循环引用"><a href="#循环引用" class="headerlink" title="循环引用"></a>循环引用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>b=[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(b)<br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>a.append(b)<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(b)<br><span class="hljs-number">3</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>b.append(a)<br><span class="hljs-meta">&gt;&gt;&gt; </span>sys.getrefcount(a)<br><span class="hljs-number">3</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> a<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">del</span> b<br></code></pre></td></tr></table></figure><p>注意 : </p><ol><li>a引用b, b引用a, 此时两个对象各自被引用了2次（去除getrefcout()的临时引用）</li></ol><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1704790008501-4d09f8c4-d850-4dfb-bd2c-129f8821887a.png" alt="img"></p><ol start="2"><li>执行del之后，对象a,b的引用次数都-1，此时各自的引用计数器都为1，陷入循环引用</li></ol><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1704790073385-223e2086-a5ba-4e3b-b4be-91767b137b9f.png" alt="img"></p><ol start="3"><li>标记：找到其中的一端a, 因为它有一个对b的引用，则将b的引用计数-1。再沿着引用到b, b有一个a的引用, 将a的引用计数-1，此时对象a和b的引用次数全部为0，被标记为不可达（Unreachable）</li></ol><p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/1704790159698-7c040994-0c91-40bc-b3f4-add0fab3fe52.png" alt="img"></p><ol start="4"><li>清除：被标记为不可达的对象就是真正需要被释放的对象</li></ol><h3 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h3><p>*标记清除过程会暂停整个应用程序，等待标记清除结束后才会恢复应用程序的运行。为了减少应用程序暂停的时间，Python 通过“**分代回收”(Generational Collection)*<em>以空间换时间的方法提高垃圾回收效率。</em></p><p><strong>分代回收</strong>基于这样的一个统计事实：对于程序，存在一定比例的内存块的生存周期比较短；而剩下的内存块，生存周期会比较长，甚至会从程序开始一直持续到程序结束。生存期较短对象的比例通常在 80%～90%之间。 因此，简单地认为：对象存在时间越长，越可能不是垃圾，应该越少去收集。这样在执行标记清除算法时可以有效减小遍历的对象数，从而提高垃圾回收的速度，<strong>是一种以空间换时间的方法策略</strong>。</p><p>Python将所有的对象分为年轻代（第0代）、中年代（第1代）、老年代（第2代）三代。所有的新建对象默认是第0代对象。当在第0代的GC扫描中存活下来的对象将被移至第1代，在第1代的GC扫描中存活下来的对象将被移至第2代。</p><p>当某一代中被分配的对象与被释放的对象之差达到某一阈值时，就会触发当前一代的GC扫描。当某一代被扫描时，比它年轻的一代也会被扫描，因此，第2代的GC扫描发生时，第0，1代的GC扫描也会发生，即为全代扫描。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> gc <br><span class="hljs-meta">&gt;&gt;&gt; </span>gc.get_threshold() <span class="hljs-comment">## 分代回收机制的参数阈值设置</span><br>(<span class="hljs-number">700</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<br><span class="hljs-comment"># 700=新分配的对象数量-释放的对象数量，第0代gc扫描被触发</span><br><span class="hljs-comment"># 第一个10：第0代gc扫描发生10次，则第1代的gc扫描被触发</span><br><span class="hljs-comment"># 第二个10：第1代的gc扫描发生10次，则第2代的gc扫描被触发</span><br></code></pre></td></tr></table></figure><h3 id="标记清除-PyPy"><a href="#标记清除-PyPy" class="headerlink" title="标记清除(PyPy)"></a>标记清除(PyPy)</h3><p><em>引用计数能够解决大多数垃圾回收的问题，但是遇到两个对象相互引用的情况，del语句可以减少引用次数，但是引用计数不会归0，对象也就不会被销毁，从而造成了内存泄漏问题。</em></p><p><strong>标记清除</strong>用来解决引用计数机制产生的循环引用，进而导致内存泄漏的问题 。（ <strong>循环引用</strong>只有在容器对象才会产生，比如字典，元组，列表等。）</p><ul><li>标记阶段，遍历所有的对象，如果是可达的（reachable），也就是还有对象引用它，那么就标记该对象为可达。</li><li>清除阶段，再次遍历对象，如果发现某个对象没有标记为可达（即为Unreachable），则就将其回收。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CPython 的大部分垃圾收集是通过引用计数完成的，我们无法对其进行干涉调整，通过辅助的分代 GC 来处理循环引用，其可控，参考 <a href="https://docs.python.org/3/library/gc.html">gc module</a>。</p><p>参考： </p><ol><li><a href="https://zhuanlan.zhihu.com/p/164627977">https://zhuanlan.zhihu.com/p/164627977</a></li><li><a href="https://zhuanlan.zhihu.com/p/295062531">https://zhuanlan.zhihu.com/p/295062531</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 内存管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>参数初始化</title>
      <link href="/2023/11/13/%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
      <url>/2023/11/13/%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h2 id="一、参数初始化"><a href="#一、参数初始化" class="headerlink" title="一、参数初始化"></a>一、参数初始化</h2><h3 id="1-1-原因"><a href="#1-1-原因" class="headerlink" title="1.1 原因"></a>1.1 原因</h3><p><strong>参数初始化</strong>又称为<strong>权重初始化</strong>（weight initialization）或<strong>权值初始化</strong>。参数初始化指的是在网络模型训练之前，对各个节点的权重和偏置进行初始化赋值的过程，用于解决梯度消失或者梯度爆炸，有利于模型的收敛速度和性能表现, 同时也可以加入自己相关领域的先验进行权重初始化。当定义好网络模型之后，需要进行权重初始化，恰当的权重初始化方法，可以加快模型的收敛，不恰当的初始化方法，可能导致梯度消失或爆炸，导致模型不可用。如果权重太小，则输入信号通过网络中的每一层时，其方差就会开始减小，输入最终会降低到非常低的值，导致梯度消失。如果权重太大，则输入数据的方差往往会随着每个传递层而迅速增加。最终，变得很大以至于梯度爆炸。</p><h3 id="1-2-参数初始化方法"><a href="#1-2-参数初始化方法" class="headerlink" title="1.2 参数初始化方法"></a>1.2 参数初始化方法</h3><p><strong>参数梯度不应该为0</strong>。而我们知道在全连接的神经网络中，参数梯度和反向传播得到的状态梯度以及入激活值有关——<strong>激活值饱和会导致该层状态梯度信息为0</strong>，然后导致下面所有层的参数梯度为0；<strong>入激活值为0会导致对应参数梯度为0</strong>。所以如果要保证<strong>参数梯度不等于0</strong>，那么参数初始化应该使得各层<strong>激活值不会出现饱和现象且激活值不为0</strong>。我们把这两个条件总结为参数初始化条件：</p><ul><li>初始化必要条件一：各层<strong>激活值不</strong>会出现<strong>饱和</strong>现象。</li><li>初始化必要条件二：各层激活值<strong>不为0</strong>。</li></ul><h4 id="（1）全0初始化"><a href="#（1）全0初始化" class="headerlink" title="（1）全0初始化"></a><strong>（1）全0初始化</strong></h4><p><strong>没有隐层时, 可以将所有的参数初始化为0，即深度模型都不会使用0初始化所有参数</strong></p><p>在神经网络中，把W初始化为0是不可以的。这是因为如果把W初始化，那么在前向传播过程中，每一层的神经元学到的东西都是一样的（激活值均为0），而在bp的时候，不同维度的参数会得到相同的更新，因为他们的gradient相同，称之为“对称失效”。同样常数初始化在这种情况也不行，因为gradient相同，weight update也相同，这样会令更新后的参数仍然保持一样的状态，但是可以初始化bias的值。</p><h4 id="（2）标准随机初始化"><a href="#（2）标准随机初始化" class="headerlink" title="（2）标准随机初始化"></a><strong>（2）标准随机初始化</strong></h4><p>希望所有参数的期望接近0。遵循这个原则，可以将参数设置为接近0的很小的随机数（有正有负），在实际中，随机参数服从高斯分布&#x2F;正态分布（Gaussian distribution &#x2F; normal distribution）和均匀分布（uniform distribution）都是有效的初始化方法。</p><p>但是一旦随机分布选择不当，就会导致网络优化陷入困境，引起梯度消失。</p><h4 id="（3）Glorot条件"><a href="#（3）Glorot条件" class="headerlink" title="（3）Glorot条件"></a><strong>（3）Glorot条件</strong></h4><ol><li>各个层的激活值h（输出值）的方差要保持一致</li><li>各个层对状态z的梯度的方差要保持一致</li></ol><h4 id="（4）参数初始化的几点要求"><a href="#（4）参数初始化的几点要求" class="headerlink" title="（4）参数初始化的几点要求"></a>（4）<strong>参数初始化的几点要求</strong></h4><ol><li><strong>参数不能全部初始化为0，也不能全部初始化同一个值</strong>；</li><li>最好保证参数初始化的<strong>均值为0，正负交错，正负参数大致上数量相等</strong>；</li><li>初始化参数<strong>不能太大或者是太小</strong>，参数太小会导致特征在每层间逐渐缩小而难以产生作用，参数太大会导致数据在逐层间传递时逐渐放大而导致梯度消失发散，不能训练；</li><li>如果有可能<strong>满足Glorot条件</strong>也是不错的；</li></ol><h3 id="1-3-seed与随机初始化"><a href="#1-3-seed与随机初始化" class="headerlink" title="1.3 seed与随机初始化"></a>1.3 seed与随机初始化</h3><p>seed在深度学习代码中叫随机种子，设置seed的目的是由于深度学习网络模型中初始的权值参数通常都是初始化成随机数。设置随机种子的方法能够近似的完全复现作者的开源深度学习代码，随机种子的选择能够减少一定程度上算法结果的随机性，即产生随机种子意味着每次运行实验，产生的随机数都是相同的吗，给复现算法提供了极大的帮助！</p><p>随机种子的设定对大部分的模型并不会产生特别大的实质性影响，神经网络更多会和迭代次数，学习率等相关。然而对于预训练模型而言，非常依赖参数的随机初始化过程，那么，随机种子的设定就显得非常重要。</p><p>随机种子输入分布生成函数tensor.normal_ , tensor.uniform_ 等，从而产生神经网络初始化参数。</p><h2 id="二、Xavier初始化"><a href="#二、Xavier初始化" class="headerlink" title="二、Xavier初始化"></a>二、Xavier初始化</h2><p>“Xavier”初始化方法是 2010 年提出的，针对有非线性激活函数时的权值初始化方法，是工程tricks中的一种，方法来源于论文<a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">《Understanding the difficulty of training deep feedforward neural networks》</a>，目的是为了使得网络中信息更好的流动，每一层输出的方差应该尽量相等。</p><ul><li>目标是保持数据的方差维持在 1 左右</li><li>针对<a href="https://www.zhihu.com/search?q=%E9%A5%B1%E5%92%8C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:3121171401%7D">饱和激活函数</a>如 sigmoid 和 tanh 等。</li></ul><p>整个大型前馈神经网络无非就是一个超级大映射，将原始样本<strong>稳定的</strong>映射成它的类别。也就是将样本空间映射到类别空间。试想，如果样本空间与类别空间的分布差异很大，比如说类别空间特别稠密，样本空间特别稀疏辽阔，那么在类别空间得到的用于反向传播的误差丢给样本空间后简直变得微不足道，也就是会导致模型的训练非常缓慢。同样，如果类别空间特别稀疏，样本空间特别稠密，那么在类别空间算出来的误差丢给样本空间后简直是爆炸般的存在，即导致模型发散震荡，无法收敛。因此，我们要让样本空间与类别空间的分布差异（密度差别）不要太大，<strong>也就是要让它们的方差尽可能相等</strong>。</p><p>优势：</p><ol><li><strong>梯度消失和爆炸</strong>：在深度网络中，梯度消失和梯度爆炸是一个常见的问题。如果每一层都将方差放大，那么在多层网络中，梯度可能会很快增长至非常大的值（爆炸），或者减小至接近零（消失）。Xavier 初始化试图使得每一层的输出的方差接近于其输入的方差，从而避免梯度消失或梯度爆炸的问题。</li><li><strong>加速收敛</strong>：Xavier 初始化使得每一层的输出的方差接近于其输入的方差，从而使得每一层的梯度的方差接近于 1。这样，每一层的参数更新的幅度就不会相差太大，从而加速收敛。</li></ol><p>劣势：</p><p>​Xavier初始化主要用于tanh，softsign等奇函数、线性函数(Taylor展开)，不适用于ReLU，sigmod函数等非奇函数、线性函数。</p><p>原因在于Xavier方法的推导过程基于两点假设：</p><ul><li>(1) 激活函数是线性的，因此并不适应于ReLU，sigmoid等非线性激活函数</li><li>(2) 激活函数是关于0对称（奇函数）的，因此不适应于ReLU，sigmoid等不是关于0对称的激活函数</li></ul><h2 id="三、kaiming初始化"><a href="#三、kaiming初始化" class="headerlink" title="三、kaiming初始化"></a>三、kaiming初始化</h2><p>   Kaiming初始化的发明人kaiming he，在<a href="https://cloud.tencent.com/developer/tools/blog-entry?target=https://links.jianshu.com/go?to=https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>论文中提出了针对relu的kaiming初始化。 </p><p>Xavier在tanh函数上表现可以，但对 ReLU 等激活函数效果不好，何凯明引入了一种更鲁棒的权重初始化方法–He Initialization。</p><p>He Initialization也有两种变体：</p><p><strong>He Normal：</strong>正态分布的均值为0、方差为sqrt( 2&#x2F;fan_in )。</p><p><strong>He Uniform：</strong>均匀分布的区间为【-sqrt( 6&#x2F;fan_in) , sqrt(6&#x2F;fan_in) 】</p><p><strong>He Initialization适用于使用ReLU、Leaky ReLU这样的非线性激活函数的网络。</strong></p><p>He Initialization和Xavier Initialization 两种方法都使用类似的理论分析：它们为从中提取初始参数的分布找到了很好的方差。该方差适用于所使用的激活函数，并且在不明确考虑分布类型的情况下导出。</p><h2 id="四、pytorch参数初始化方法"><a href="#四、pytorch参数初始化方法" class="headerlink" title="四、pytorch参数初始化方法"></a>四、pytorch参数初始化方法</h2><p>pytorch中的各种参数层（Linear、Conv2d、BatchNorm等）在__init__方法中定义后，不需要手动初始化就可以直接使用，这是因为Pytorch对这些层都会进行默认初始化, 绝大部分为kaiming初始化yyds。</p><h3 id="初始化函数"><a href="#初始化函数" class="headerlink" title="初始化函数"></a>初始化函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">kaiming_uniform_</span>(<span class="hljs-params">tensor, a=<span class="hljs-number">0</span>, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;leaky_relu&#x27;</span></span>):<br>    fan = _calculate_correct_fan(tensor, mode)<br>    gain = calculate_gain(nonlinearity, a)<br>    std = gain / math.sqrt(fan)<br>    bound = math.sqrt(<span class="hljs-number">3.0</span>) * std  <span class="hljs-comment"># Calculate uniform bounds from standard deviation</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">return</span> tensor.uniform_(-bound, bound)<br></code></pre></td></tr></table></figure><p>kaiming_uniform_按照均匀分布初始化tensor，在U (−bound, bound)中采样，其中</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131240977.png" alt="img" style="zoom: 25%;" /><p>同样的，fan_in在tensor为二维时，是tensor.size(1)，注意，上面给出的初始化公式均是在mode和nonlinearity在默认参数下的结果</p><h3 id="Linear的初始化"><a href="#Linear的初始化" class="headerlink" title="Linear的初始化"></a>Linear的初始化</h3><p>Linear自带的初始化函数为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reset_parameters</span>(<span class="hljs-params">self</span>):<br>        init.kaiming_uniform_(self.weight, a=math.sqrt(<span class="hljs-number">5</span>))<br>        <span class="hljs-keyword">if</span> self.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)<br>            bound = <span class="hljs-number">1</span> / math.sqrt(fan_in)<br>            init.uniform_(self.bias, -bound, bound)<br></code></pre></td></tr></table></figure><p>W在U (−bound, bound)中采样，其中</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131240891.png" alt="img" style="zoom:25%;" /><p>fan_in即为W的第二维大小，即Linear所作用的输入向量的维度</p><p>bias也在U (−bound,bound)中采样，且bound与W一样</p><h3 id="Conv的初始化"><a href="#Conv的初始化" class="headerlink" title="Conv的初始化"></a>Conv的初始化</h3><p>以二维为例，卷积层的参数实际上是一个四维tensor：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> transposed:<br>    self.weight = Parameter(torch.Tensor(<br>        in_channels, out_channels // groups, *kernel_size))<br><span class="hljs-keyword">else</span>:<br>    self.weight = Parameter(torch.Tensor(<br>        out_channels, in_channels // groups, *kernel_size))<br><span class="hljs-keyword">if</span> bias:<br>    self.bias = Parameter(torch.Tensor(out_channels))<br><span class="hljs-keyword">else</span>:<br>    self.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p>比如一个输入channel为3，输出channel为64，kernel size&#x3D;3的卷积层，其权值即为一个3×64×3×3的向量，它会这样进行初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reset_parameters</span>(<span class="hljs-params">self</span>):<br>    init.kaiming_uniform_(self.weight, a=math.sqrt(<span class="hljs-number">5</span>))<br>    <span class="hljs-keyword">if</span> self.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)<br>        bound = <span class="hljs-number">1</span> / math.sqrt(fan_in)<br>        init.uniform_(self.bias, -bound, bound)<br></code></pre></td></tr></table></figure><p>同样默认使用kaiming_uniform，在U (−bound, bound)中采样，其中</p><img src="https://cdn.nlark.com/yuque/0/2023/png/33777925/1699794020071-ef3798da-f1e1-4848-b2eb-1e7ea823761d.png" alt="img" style="zoom:25%;" /><p>对于fan_in的计算：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">num_input_fmaps = tensor.size(<span class="hljs-number">1</span>)<br>num_output_fmaps = tensor.size(<span class="hljs-number">0</span>)<br>receptive_field_size = <span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> tensor.dim() &gt; <span class="hljs-number">2</span>:<br>    receptive_field_size = tensor[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].numel()<br>fan_in = num_input_fmaps * receptive_field_size<br>fan_out = num_output_fmaps * receptive_field_size<br></code></pre></td></tr></table></figure><p>即：<img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131242162.png" alt="img" style="zoom:25%;" /></p><h3 id="BatchNorm层初始化"><a href="#BatchNorm层初始化" class="headerlink" title="BatchNorm层初始化"></a>BatchNorm层初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reset_parameters</span>(<span class="hljs-params">self</span>):<br>    self.reset_running_stats()<br>    <span class="hljs-keyword">if</span> self.affine:<br>        init.uniform_(self.weight)<br>        init.zeros_(self.bias)<br></code></pre></td></tr></table></figure><p>weight初始化为U (0, 1) ,bias初始化为0</p><h3 id="ResNet初始化"><a href="#ResNet初始化" class="headerlink" title="ResNet初始化"></a>ResNet初始化</h3><p>Resnet在定义各层之后，pytorch官方代码的__init__方法会对不同的层进行手动的初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>        nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm)):<br>        nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>        nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>首先对于所有卷积层，与之前不同，这里采用的mode是fan_out，nonlinearity是relu，且使用的初始化函数为kaiming_normal_，即参数在N (0,std)中采样，其中</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131243395.png" alt="img" style="zoom:25%;" /><p>卷积层的bias这里没有提到，因此采用的仍然是默认的初始化方法，而BatchNorm和GroupNorm的weight均初始化为1，bias初始化为0，区别于默认的weight在0～1中均匀采样，bias为0，剩下的Linear层未被提到，仍然采用默认的初始化方法</p><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>VGG的pytorch官方初始化方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_weights</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>            nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.BatchNorm2d):<br>            nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>            nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>            nn.init.normal_(m.weight, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)<br>            nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>卷积层的初始化方法同ResNet，只不过bias初始化为0，BatchNorm层初始化方法同ResNet，Linear层的weight初始化为N ( 0 , 0.01 ) N(0,0.01)N(0,0.01)，bias初始化为0</p><h2 id="五、pytorch初始化api"><a href="#五、pytorch初始化api" class="headerlink" title="五、pytorch初始化api"></a>五、pytorch初始化api</h2><h3 id="初始化方法汇总"><a href="#初始化方法汇总" class="headerlink" title="初始化方法汇总"></a>初始化方法汇总</h3><p>PyTorch 中提供了 11种初始化方法：</p><ol><li><ol><li>Xavier 均匀分布</li><li>Xavier 正态分布</li><li>Kaiming 均匀分布</li><li>Kaiming 正态分布</li><li>均匀分布</li><li>正态分布</li><li>常数分布</li><li>正交矩阵初始化</li><li>单位矩阵初始化</li><li>稀疏矩阵初始化</li><li>狄拉克δ函数初始化</li></ol></li></ol><h3 id="torch-nn-init-uniform-tensor-a-0-0-b-1-0"><a href="#torch-nn-init-uniform-tensor-a-0-0-b-1-0" class="headerlink" title="torch.nn.init.uniform_(tensor, a&#x3D;0.0, b&#x3D;1.0)"></a>torch.nn.init.uniform_(tensor, a&#x3D;0.0, b&#x3D;1.0)</h3><p>含义：从均匀分布 U ( a , b ) U(a, b)U(a,b)中生成值，填充输入的张量</p><p>参数：</p><p>（1）tensor - n 维的 torch.Tensor</p><p>（2）a - 均匀分布的下界</p><p>（3）b - 均匀分布的上界</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>torch.nn.init.uniform_(w, a=<span class="hljs-number">0</span>, b=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-normal-tensor-mean-0-std-1"><a href="#torch-nn-init-normal-tensor-mean-0-std-1" class="headerlink" title="torch.nn.init.normal_(tensor, mean&#x3D;0, std&#x3D;1)"></a>torch.nn.init.normal_(tensor, mean&#x3D;0, std&#x3D;1)</h3><p>含义：从给定均值和标准差的正态分布 N ( m e a n , s t d ) N(mean, std)N(mean,std)中生成值，填充输入的张量或变量</p><p>参数：</p><p>（1）tensor – n 维的 torch.Tensor</p><p>（2）mean – 正态分布的均值</p><p>（3）std – 正态分布的标准差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">from</span> torch <br><span class="hljs-keyword">import</span> nn w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>) <br>torch.nn.init.normal_(w, mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-constant-tensor-val"><a href="#torch-nn-init-constant-tensor-val" class="headerlink" title="torch.nn.init.constant_(tensor, val)"></a>torch.nn.init.constant_(tensor, val)</h3><p>含义：用 val 的值填充输入的张量或变量</p><p>参数：</p><p>（1）tensor – n 维的 torch.Tensor</p><p>（2）val – 用来填充张量的值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>torch.nn.init.constant_(w, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-eye-tensor"><a href="#torch-nn-init-eye-tensor" class="headerlink" title="torch.nn.init.eye_(tensor)"></a>torch.nn.init.eye_(tensor)</h3><p>含义：用单位矩阵来填充 2 维输入张量或变量。在线性层尽可能多的保存输入特性。<br>参数：<br>（1）tensor – 2 维的 torch.Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>torch.nn.init.eye_(w)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-dirac-tensor"><a href="#torch-nn-init-dirac-tensor" class="headerlink" title="torch.nn.init.dirac_(tensor)"></a>torch.nn.init.dirac_(tensor)</h3><p>含义：用 Dirac δ 函数来填充{3, 4, 5}维输入张量或变量。在卷积层尽可能多的保存输入通道特性。</p><p>参数：</p><p>（1）tensor – {3, 4, 5}维的 torch.Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)<br>nn.init.dirac_(w)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-xavier-uniform-tensor-gain-1"><a href="#torch-nn-init-xavier-uniform-tensor-gain-1" class="headerlink" title="torch.nn.init.xavier_uniform_(tensor, gain&#x3D;1)"></a>torch.nn.init.xavier_uniform_(tensor, gain&#x3D;1)</h3><p>含义：用一个均匀分布生成值，填充输入的张量或变量。结果张量中的值采样自 U(-a, a),  该方法也被称为 Glorot initialisation。</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131244377.png" alt="img" style="zoom:25%;" /><p>参数：</p><p>（1）tensor – n 维的 torch.Tensor</p><p>（2）gain - 可选的缩放因子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>nn.init.xavier_uniform_(w)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-xavier-normal-tensor-gain-1-："><a href="#torch-nn-init-xavier-normal-tensor-gain-1-：" class="headerlink" title="torch.nn.init.xavier_normal_(tensor, gain&#x3D;1)："></a>torch.nn.init.xavier_normal_(tensor, gain&#x3D;1)：</h3><p>含义：用一个正态分布生成值，填充输入的张量或变量。结果张量中的值采样自:</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131245665.png" alt="img" style="zoom:25%;" /><p>参数：</p><p>（1）tensor – n 维的 torch.Tensor</p><p>（2）gain - 可选的缩放因子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>nn.init.xavier_normal_(w, gain=nn.init.calculate_gain(<span class="hljs-string">&#x27;relu&#x27;</span>))<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-kaiming-uniform-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’"><a href="#torch-nn-init-kaiming-uniform-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’" class="headerlink" title="torch.nn.init.kaiming_uniform_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)"></a>torch.nn.init.kaiming_uniform_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)</h3><p>含义：用一个均匀分布生成值，填充输入的张量或变量。结果张量中的值采样自 U(-bound, bound)，其中</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131244176.png" alt="img" style="zoom:25%;" /><p>参数：</p><p>（1）tensor：n 维的 torch.Tensor</p><p>（2）a：leaky_relu的负斜率，只有在nonlinearity&#x3D;’leaky_relu’时候起作用</p><p>（3）mode：fan_in或者fan_out。fan_in保留forward传递中权重的方差大小，fan_out保留backward传递中权重的方差大小</p><p>（4）nonlinearity：nn.functional名称，推荐使用relu和leaky_relu。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">from</span> torch <br><span class="hljs-keyword">import</span> nn w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>) <br>torch.nn.init.kaiming_uniform_(w, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-kaiming-normal-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’"><a href="#torch-nn-init-kaiming-normal-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’" class="headerlink" title="torch.nn.init.kaiming_normal_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)"></a>torch.nn.init.kaiming_normal_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)</h3><p>含义：用一个均匀分布生成值，填充输入的张量或变量。结果张量中的值采样自 U(-bound, bound)，其中</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131245548.png" alt="img" style="zoom:25%;" /><p>参数：</p><p>（1）tensor：n 维的 torch.Tensor</p><p>（2）a：leaky_relu的负斜率，只有在nonlinearity&#x3D;’leaky_relu’时候起作用</p><p>（3）mode：fan_in或者fan_out。fan_in保留forward传递中权重的方差大小，fan_out保留backward传递中权重的方差大小</p><p>（4）nonlinearity：nn.functional名称，推荐使用relu和leaky_relu。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">from</span> torch <br><span class="hljs-keyword">import</span> nn w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>) <br>torch.nn.init.kaiming_uniform_(w, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-kaiming-normal-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’-1"><a href="#torch-nn-init-kaiming-normal-tensor-a-0-mode-’fan-in’-nonlinearity-’leaky-relu’-1" class="headerlink" title="torch.nn.init.kaiming_normal_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)"></a>torch.nn.init.kaiming_normal_(tensor, a&#x3D;0, mode&#x3D;’fan_in’, nonlinearity&#x3D;’leaky_relu’)</h3><p>​含义：用一个正态分布生成值，填充输入的张量或变量。结果张量中的值采样自:</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311131248480.png" alt="img" style="zoom:25%;" /><p>参数：</p><p>（1）tensor：n 维的 torch.Tensor</p><p>（2）a：leaky_relu的负斜率，只有在nonlinearity&#x3D;’leaky_relu’时候起作用</p><p>（3）mode：fan_in或者fan_out。fan_in保留forward传递中权重的方差大小，fan_out保留backward传递中权重的方差大小</p><p>（4）nonlinearity：nn.functional名称，推荐使用relu和leaky_relu。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>nn.init.kaiming_normal_(w, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-sparse-tensor-sparsity-std-0-01"><a href="#torch-nn-init-sparse-tensor-sparsity-std-0-01" class="headerlink" title="torch.nn.init.sparse_(tensor, sparsity, std&#x3D;0.01)"></a>torch.nn.init.sparse_(tensor, sparsity, std&#x3D;0.01)</h3><p>含义：将 2 维的输入张量或变量当做稀疏矩阵填充，结果张量中的值采样自N(0,0.01)，其中非零元素根据一个均值为 0，标准差为 std 的正态分布生成。</p><p>参数：</p><p>（1）tensor – n 维的 torch.Tensor</p><p>（2）sparsity - 每列中需要被设置成零的元素比例</p><p>（3）std - 用于生成非零值的正态分布的标准差</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>nn.init.sparse(w, sparsity=<span class="hljs-number">0.1</span>)<br></code></pre></td></tr></table></figure><h3 id="torch-nn-init-orthogonal-tensor-gain-1"><a href="#torch-nn-init-orthogonal-tensor-gain-1" class="headerlink" title="torch.nn.init.orthogonal_(tensor, gain&#x3D;1)"></a>torch.nn.init.orthogonal_(tensor, gain&#x3D;1)</h3><p>含义：用一个(半)正交矩阵初始化输入张量，参考Saxe, A. et al. (2013) - <a href="https://arxiv.org/abs/1312.6120">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</a>。输入张量必须至少有2维，对于大于2维的张量，超出的维度将被flatten化。正交初始化可以使得卷积核更加紧凑，可以去除相关性，使模型更容易学到有效的参数。</p><p>参数：</p><p>（1）tensor – n维需要初始化的张量，其中n&gt;&#x3D;2<br>（2）gain -可选放缩因子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch <span class="hljs-keyword">from</span> torch <br><span class="hljs-keyword">import</span> nn  w = torch.Tensor(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>) <br>torch.nn.init.orthogonal_(w)<br></code></pre></td></tr></table></figure><h3 id="自定义初始化"><a href="#自定义初始化" class="headerlink" title="自定义初始化"></a>自定义初始化</h3><p>可以用apply()函数初始化，可选用pytorch提供的多种初始化函数，apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">weights_init</span>(<span class="hljs-params">m</span>):<br>    classname=m.__class__.__name__<br>    <span class="hljs-keyword">if</span> classname.find(<span class="hljs-string">&#x27;Conv&#x27;</span>) != -<span class="hljs-number">1</span>:<br>        xavier(m.weight.data)<br>        xavier(m.bias.data)<br>net = Net()<br>net.apply(weights_init) <span class="hljs-comment">#apply函数会递归地搜索网络内的所有module并把参数表示的函数应用到所有的module上。   </span><br></code></pre></td></tr></table></figure><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><a href="https://blog.csdn.net/shuzfan/article/details/51338178">深度学习——Xavier初始化方法_xavier_uniform_-CSDN博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/27919794">深度前馈网络与Xavier初始化原理</a></li><li><a href="https://zhuanlan.zhihu.com/p/64464584">深度学习：Xavier and Kaiming Initialization</a></li><li><a href="https://blog.csdn.net/weixin_39653948/article/details/107950764#Paper_3">【精选】PyTorch中的Xavier以及He权重初始化方法解释_pytorch中he初始化-CSDN博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/336005430?utm_id=0">深度学习之参数初始化</a></li><li><a href="https://blog.csdn.net/luo3300612/article/details/97675312">Pytorch 默认参数初始化_pytorch中默认的参数初始化-CSDN博客</a></li><li><a href="https://blog.csdn.net/weixin_43229348/article/details/120332308">PyTorch常用函数(8)_nn.init.calculate_gain-CSDN博客</a></li><li><a href="https://blog.csdn.net/qq_42766639/article/details/125061803">seed在模型中的应用及用法_模型的seed什么作用_zyrlia的博客-CSDN博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/545344518">【调参侠的修炼笔记2】随机种子Seed的讲人话解释</a></li><li><a href="https://blog.csdn.net/qq_43679439/article/details/125134408">模型初始化与随机种子——Pytorch 炼丹技巧（随手记）_pytorch需要随机初始化吗-CSDN博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/355337178">权重&#x2F;参数初始化方法</a></li><li><a href="https://zhuanlan.zhihu.com/p/416922998">如何选择合适的初始化方法 | 神经网络的初始化方法总结</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 基础知识整理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mAP及相关概念</title>
      <link href="/2023/11/02/mAP%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/"/>
      <url>/2023/11/02/mAP%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="正例和负例"><a href="#正例和负例" class="headerlink" title="正例和负例"></a>正例和负例</h1><p>现在假设我们的分类目标只有两类，计为正例（positive）和负例（negtive），然后我们就能得到如下的四种情况：</p><p>（1）True positives(TP):  被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数（样本数）；</p><p>（2）True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。</p><p>（3）False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；</p><p>（4）False negatives(FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；</p><h1 id="P（精确率）"><a href="#P（精确率）" class="headerlink" title="P（精确率）"></a>P（精确率）</h1><p>P 代表 <strong>precision</strong>，即精确率，精确率表示<strong>预测样本中实际正样本数占所有正样本数的比例</strong>，计算公式为：</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021652287.png" alt="image-20231102165221257" style="zoom:33%;" /><h1 id="AP（平均精度）"><a href="#AP（平均精度）" class="headerlink" title="AP（平均精度）"></a>AP（平均精度）</h1><p>AP 代表  Average Precision，即平均精度。</p><h1 id="R（召回率）"><a href="#R（召回率）" class="headerlink" title="R（召回率）"></a>R（召回率）</h1><p>R 代表 <strong>recall</strong> ，即召回率，召回率表示<strong>预测样本中实际正样本数占所有预测的样本的比例</strong>，计算公式为：  </p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021651290.png" alt="image-20231102165133249" style="zoom: 33%;" /><p>一般来说，<strong>召回率越高，准确率越低</strong>。</p><h1 id="ACC（准确率）"><a href="#ACC（准确率）" class="headerlink" title="ACC（准确率）"></a>ACC（准确率）</h1><p>ACC 代表 <strong>Accuracy</strong>，即准确率，准确率表示<strong>预测样本中预测正确数占所有样本数的比例</strong>，计算公式为：</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021652324.png" alt="image-20231102165258263" style="zoom:33%;" /><h1 id="mAP（均值平均精度）"><a href="#mAP（均值平均精度）" class="headerlink" title="mAP（均值平均精度）"></a>mAP（<strong>均值平均精度</strong>）</h1><p>mAP 是 <strong>Mean Average Precision</strong> 的缩写，即 <strong>均值平均精度</strong>，即<strong>AP</strong>(<strong>A</strong>verage <strong>P</strong>recision)的平均值，作为 <strong>object dection</strong> 中衡量<strong>检测精度</strong>的指标。假设有K种类别，K&gt;1，那么<strong>mAP</strong>的计算公式为：</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021653133.png" alt="image-20231102165322106" style="zoom:33%;" /><h1 id="备注："><a href="#备注：" class="headerlink" title="备注："></a>备注：</h1><p>什么是精(Precision)，什么是准(Accuracy）</p><p><strong>Precision指精度</strong>，意味着随机误差(Random Error)小，即方差(Variance)小，描述了实际值的扰动情况。</p><p><strong>Accuracy指准度</strong>，意味着系统误差(System Error)小，即偏差(Bias) 小，描述了的实际值与真实结果的偏离程度</p><p>准确度高，意味着误差(Error)小，Error &#x3D; Bias + Variance</p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021433167.webp" alt="img"></p><p><strong>Precision</strong>是预测为正实际为正占预测为正的比例，Precision可以视作是模型找出来的数据的正确能力，Precision&#x3D;1表示模型找一个对一个，Presicion&#x3D;0.5表示模型找出2个，能对1个。</p><p><strong>Recall</strong>是预测为正实际为正占总体正样本的比例，Recall可以视作是模型在数据集中，检测出目标类型数据的能力，即是否把想找出来的都找出来了，Recall&#x3D;1表示已经把想找出来的数据全部找出来了。</p><p><strong>Accuracy</strong>是预测为正实际为正和预测为负实际负占总样本的比例。</p><p><strong>F1 Score</strong>是Precision与Recall的调和平均，是综合Precision与Recall的评估指标，避免Precision或Recall的单一极大值，用于综合反映整体的指标。</p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311021441820.webp" alt="img" style="zoom:67%;" /><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><p><a href="https://www.jianshu.com/p/fd9b1e89f983">https://www.jianshu.com/p/fd9b1e89f983</a></p></li><li><p><a href="https://blog.csdn.net/shuiyixin/article/details/86349643">【深度学习小常识】什么是mAP？_模型的map是什么的缩写-CSDN博客</a></p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 基础概念 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>主动学习笔记</title>
      <link href="/2023/11/01/%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2023/11/01/%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Burr Settles的文章《Active Learning Literature Survey》详细地介绍了主动学习：<strong>“主动学习是机器学习的一个子领域，在统计学领域也叫查询学习或最优实验设计”。</strong>为解决某些任务数据标签较少或打标签“代价”较高的问题而出现。主动学习方法尝试解决样本的标注瓶颈，通过主动优先选择最有价值的未标注样本进行标注，以尽可能少的标注样本达到模型的预期性能。其主要方式是模型通过与用户或专家进行交互，抛出”query”(unlabel data)让专家确定数据的标签，如此反复，以期让模型利用较少的标记数据获得较好“性能”。</p><p>主动学习方法是一个迭代式的交互训练过程，主要由五个核心部分组成，包括：<strong>未标注样本池（unlabeled pool，记为U）、筛选策略（select queries，记为Q）、标注者（human annotator，记为S），标注数据集（labeled training set，记为L），目标模型（machine learning model，记为G）。</strong></p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311012238748.png" alt="image (2)"></p><p>active learning与passive learning最大的不同是passive learning或supervised learning其首先就需要大量的专家标注样本训练模型，而active learning则是利用少量标注样本，大量未标注样本训练模型，然后由learner选择样本返回给Oracle或expert打标签，进而不断迭代以获得较好的模型，该过程必须要有专家的参与，这也是active learning区别于semi-supervised learning的不同之处。</p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311012236954.png" alt="img"></p><p>半监督学习一般不需要人工参与，是通过具有一定分类精度的基准分类器实现对未标注样例的自动标注；而主动学习有别于半监督学习的特点之一就是需要将挑选出的高价值样例进行人工准确标注。</p><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><h3 id="membership-query-synthesis"><a href="#membership-query-synthesis" class="headerlink" title="membership query synthesis"></a>membership query synthesis</h3><p>query samples可以为任意样本或随机生成（例如对图片样本进行旋转或添加“噪声”等，类似样本增强的策略），然后将其送个Oracle进行判断，策略并不是在数据池中挑选样本进行查询，而是自行生成新样本进行查询。其过程如下所示：</p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311012236782.png" alt="img"></p><p>由于在样本的随机生成过程中，其有较大的不确定性，因此在某些应用，如NLP中其生成的结果无任何意义，同时专家也无法标记，故这种方法对于某些应用场景有一定的局限性。</p><h3 id="stream-based-selective-sampling"><a href="#stream-based-selective-sampling" class="headerlink" title="stream-based selective sampling"></a>stream-based selective sampling</h3><p>假设样本的获得是“免费的”或代价较小的，数据以数据流的形式输入，主动学习策略需要确定对当前数据进行标记还是直接用现有模型预测。learner每次基于某种query strategy选择一个样本给专家进行标记，模型通过某种“informativeness measure”确定是否由专家标注样本，或舍弃该样本。如下：</p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311012236789.png" alt="img"></p><h3 id="pool-based-sampling"><a href="#pool-based-sampling" class="headerlink" title="pool-based sampling"></a>pool-based sampling</h3><p>Pool-Based Sampling每次确定一批unlabeled data，由专家标记。Pool-Based Sampling是active learning中应用最为广泛的一种framework。</p><p><img src="https://fastly.jsdelivr.net/gh/xieleixielei/picture/202311012236974.png" alt="img"></p><h2 id="Query-Strategy"><a href="#Query-Strategy" class="headerlink" title="Query Strategy"></a>Query Strategy</h2><p>如上文所述，learner需要根据一定的策略选择unlabeled data，在active learning中其主要包括以下几种：</p><h3 id="1-Uncertainty-Sampling"><a href="#1-Uncertainty-Sampling" class="headerlink" title="(1) Uncertainty Sampling"></a>(1) Uncertainty Sampling</h3><p>Uncertainty Sampling是最为广泛的一种query strategy（类似hard sample mining），其主要是将模型“最易混淆”或“信息量”最大、最有价值的样本返回给expert，以期获得较大的增益，用entropy衡量。</p><h3 id="2-Query-By—Committe"><a href="#2-Query-By—Committe" class="headerlink" title="(2) Query-By—Committe"></a>(2) Query-By—Committe</h3><p>Query-By—Committe的思想类似于模型集成和投票，不同的模型即为Committee，投票的divergence最大的样本即为“controversial sample”，利用vote entropy衡量。</p><h3 id="3-Expected-Model-Change"><a href="#3-Expected-Model-Change" class="headerlink" title="(3) Expected Model Change"></a>(3) Expected Model Change</h3><p>Expected Model Change其主要思想即对模型“改变”最大的标记样本为“有价值”的样本，这里对模型“改变”的衡量可以由梯度提升来体现，如“expected gradient length” (EGL)。</p><h3 id="4-Expected-Error-Reduction"><a href="#4-Expected-Error-Reduction" class="headerlink" title="(4) Expected Error Reduction"></a>(4) Expected Error Reduction</h3><p>类似与Expect Model Change，Expected Error Reduction的思想是通过增加一个标注的样本其loss减小最多。</p><h3 id="5-Variance-Reduction"><a href="#5-Variance-Reduction" class="headerlink" title="(5) Variance Reduction"></a>(5) Variance Reduction</h3><p>Expected Error Reduction需要判断每个样本对模型的“贡献程度”，其“成本”较高，而Variance Reduction其主要思想是使variance最小的样本，其“价值”最大。</p><h3 id="6-Density-Weighted-Methods"><a href="#6-Density-Weighted-Methods" class="headerlink" title="(6) Density-Weighted Methods"></a>(6) Density-Weighted Methods</h3><p>由uncertain strategy确定的样本其更多的是关注单个样本对模型的提升或“贡献”程度，然而很多候，其“模糊”的样本往往会是一些outliers或噪声，若让模型更多的关注或学习这些样本，其对性能的提升将不会产生帮助，在考虑individual时同时还需关注整体样本的分布，故提出了Density-Weighted Methods。</p><p> 参考：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/377045943">主动学习（Active Learning），看这一篇就够了</a></li><li><a href="https://zhuanlan.zhihu.com/p/79764678">主动学习（Active Learning）-少标签数据学习</a></li><li><a href="https://www.zhihu.com/question/352299820/answer/1860798696">https://www.zhihu.com/question/352299820/answer/1860798696</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 主动学习 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用数据集汇总</title>
      <link href="/2023/11/01/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B1%87%E6%80%BB/"/>
      <url>/2023/11/01/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="CIFAR-10"><a href="#CIFAR-10" class="headerlink" title="CIFAR-10"></a>CIFAR-10</h2><p>CIFAR-10 是由Hinton 的学生Alex Krizhevsky 和Ilya Sutskever 整理的一个用于识别普适物体的小型数据集。包含60000个32x32像素RGB三通道彩色图像，10个类别，每个类别6000个图像。 有50000张训练图像和10000张测试图像。</p><p>数据集地址如下：<a href="http://www.cs.toronto.edu/~kriz/cifar.html">The CIFAR-10 dataset</a></p><p><img src="https://cdn.jsdelivr.net/gh/xieleixielei/picture/202311012014102.png" alt="img"></p><p>与MNIST 数据集比， CIFAR-10 有以下不同点：</p><p>(1) CIFAR-10 是3 通道的彩色RGB 图像，而MNIST 是灰度图像。</p><p>(2) CIFAR-10 的图片尺寸为32 × 32，而MNIST 的图片尺寸为28 × 28，比MNIST 稍大。</p><p>(3) 相比于手写字符，CIFAR-10 含有的是现实世界中真实的物体，不仅噪声很大，而且物体的比例、特征都不尽相同，这为识别带来很大困难。MNIST数据集展示的是不同人的手写0~9数字。直接的线性模型如Softmax 在CIFAR-10 上表现得很差。</p><p>CIFAR10数据集结构组成可分为这四个部分：</p><ul><li>train_x:(50000, 32, 32, 3)——训练样本</li><li>train_y:(50000, 1)——训练样本标签</li><li>test_x:(10000, 32, 32, 3)——测试样本</li><li>test_y:(10000, 1)——测试样本标签</li></ul><h2 id="CIFAR-100"><a href="#CIFAR-100" class="headerlink" title="CIFAR-100"></a>CIFAR-100</h2><p>包含60000个32x32像素RGB三通道彩色图像，100个类别，每个类别600个图像。每个类有500个训练图像和100个测试图像。CIFAR-100中的100个子类被分为20个大类。每个图像都有一个“fine”标签(它所属的子类)和一个“coarse”标签(它所属的大类)。</p><p>地址：<a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p><table><thead><tr><th><strong>大类</strong></th><th><strong>子类</strong></th></tr></thead><tbody><tr><td>水栖哺乳动物</td><td>海狸，海豚，水獭，海豹，鲸鱼</td></tr><tr><td>鱼类</td><td>水族鱼，比目鱼，鳐，鲨鱼，鳟鱼</td></tr><tr><td>花</td><td>兰花，罂粟，玫瑰，向日葵，郁金香</td></tr><tr><td>食物容器</td><td>瓶子，碗，罐头，杯子，盘子</td></tr><tr><td>水果和蔬菜</td><td>苹果，蘑菇，橘子，梨，甜椒</td></tr><tr><td>家用电器</td><td>时钟，电脑键盘，灯，电话，电视</td></tr><tr><td>家居家具</td><td>床，椅子，沙发，桌子，衣柜</td></tr><tr><td>昆虫</td><td>蜜蜂、甲虫、蝴蝶、毛虫、蟑螂</td></tr><tr><td>大型食肉动物</td><td>熊，豹，狮子，老虎，狼</td></tr><tr><td>大型人造户外用品</td><td>桥梁、城堡、房屋、道路、摩天大楼</td></tr><tr><td>大型户外自然景观</td><td>云、森林、高山、平原、大海</td></tr><tr><td>大型杂食动物和食草动物</td><td>骆驼，牛，黑猩猩，大象，袋鼠</td></tr><tr><td>中型哺乳动物</td><td>狐狸，豪猪，负鼠，浣熊，臭鼬</td></tr><tr><td>非昆虫无脊椎动物</td><td>螃蟹，龙虾，蜗牛，蜘蛛，蠕虫</td></tr><tr><td>人类</td><td>宝贝，男孩，女孩，男人，女人</td></tr><tr><td>爬行动物</td><td>鳄鱼，恐龙，蜥蜴，蛇，乌龟</td></tr><tr><td>小型哺乳动物</td><td>仓鼠，老鼠，兔子，鼩鼱，松鼠</td></tr><tr><td>树木</td><td>枫树、橡树、棕榈树、松树、柳树</td></tr><tr><td>交通工具</td><td>自行车、公共汽车、摩托车、小货车、火车</td></tr><tr><td>其他车类</td><td>割草机，火箭，有轨电车，坦克，拖拉机</td></tr></tbody></table><h2 id="ImageNet-and-ILSVRC2012"><a href="#ImageNet-and-ILSVRC2012" class="headerlink" title="ImageNet and ILSVRC2012"></a>ImageNet and ILSVRC2012</h2><p><strong>ImageNet</strong>是斯坦福大学教授李飞飞为了解决机器学习中过拟合和泛化的问题而牵头构建的数据集。该数据集从2007年开始建立，直到2009年作为论文的形式在CVPR 2009上面发布。直到目前，该数据集仍然是深度学习领域中图像分类、检测、定位的最常用数据集之一。ImageNet本身有1500万张图片，2万分类。其中有<strong>超过100万张图片有明确类别标注和物体位置标注</strong>。</p><p>基于ImageNet的比赛称为ILSVRC，全称是ImageNet Large-Scale Visual Recognition Challenge，每年举办一次，每次从ImageNet数据集中抽取部分样本作为比赛的数据集。“ILSVRC”一词有时候也用来特指该比赛使用的数据集，即ImageNet的一个子集，其中最常用的是2012年的数据集，记为<strong>ILSVRC2012</strong>（常用）。</p><p>地址：<a href="https://www.image-net.org/download.php">https://www.image-net.org/download.php</a></p><table><thead><tr><th>ILSVRC2012训练集</th><th>1000个分类</th><th>120万张图片</th></tr></thead><tbody><tr><td>ILSVRC2012验证集</td><td>1000个分类</td><td>5万张图片</td></tr><tr><td>ILSVRC2012测试集</td><td>1000个分类</td><td>10万张图片</td></tr></tbody></table><h2 id="CIFAR10-C"><a href="#CIFAR10-C" class="headerlink" title="CIFAR10-C"></a>CIFAR10-C</h2><p>CIFAR10-C是自然分布鲁棒性数据集的一种，使用五种不同强度的各种人工合成噪声来破坏CIFAR-10的测试集。其中包含四种加性噪音：高斯噪声(Gaussian noise)、散粒噪声(shot noise)、散斑噪声(speckle noise)和脉冲噪声(impulse noise)。文章地址：<a href="https://github.com/tanimutomo/cifar10-c-eval">https://github.com/tanimutomo/cifar10-c-eval</a></p><p>数据集地址：<a href="https://zenodo.org/records/2535967#.XncuG5P7TUJ">https://zenodo.org/records/2535967#.XncuG5P7TUJ</a></p><p><img src="https://cdn.jsdelivr.net/gh/xieleixielei/picture/202311012101371.png" alt="image"></p><h2 id="CIFAR100-C"><a href="#CIFAR100-C" class="headerlink" title="CIFAR100-C"></a>CIFAR100-C</h2><p>文章地址：<a href="https://arxiv.org/abs/1807.01697">Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations</a></p><p>数据集地址：<a href="https://zenodo.org/records/3555552">https://zenodo.org/records/3555552</a></p><h2 id="ImageNet-C"><a href="#ImageNet-C" class="headerlink" title="ImageNet-C"></a>ImageNet-C</h2><p>ImageNet-C是自然分布鲁棒性数据集的一种，包含由算法生成的图片损坏：噪声、模糊、天气和数码类别。文章地址：<a href="https://github.com/hendrycks/robustness">https://github.com/hendrycks/robustness</a></p><p>下载链接：<a href="https://zenodo.org/records/2235448#.Y0jPtXZBxPY">https://zenodo.org/records/2235448#.Y0jPtXZBxPY</a></p><p><img src="https://cdn.jsdelivr.net/gh/xieleixielei/picture/202311012014159.png" alt="img"></p><h2 id="ImageNet-A"><a href="#ImageNet-A" class="headerlink" title="ImageNet-A"></a>ImageNet-A</h2><p>ImageNet-A收集了一系列来自真实世界的未经修改的图片，这些图片会被ResNet模型错误地分类。文章地址：<a href="https://github.com/hendrycks/natural-adv-examples">https://github.com/hendrycks/natural-adv-examples</a></p><p>数据集地址：<a href="https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar">https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar</a></p><p><img src="https://cdn.jsdelivr.net/gh/xieleixielei/picture/202311012102174.png" alt="image (1)"></p><h2 id="ObjectNet"><a href="#ObjectNet" class="headerlink" title="ObjectNet"></a>ObjectNet</h2><p>ObjectNet包含113种与ImageNet相同的类别，通过对不同背景、旋转角度、视角等情况下的日常家庭物品进行拍摄，组成了一个用于验证视觉系统的数据集。该数据集不包含训练集，仅包含五万张图片的测试集。人类视觉系统可以轻松地继续执行分类任务，而机器视觉系统在该数据集上会出现较大的掉点。</p><p>数据集地址：<a href="https://objectnet.dev/">https://objectnet.dev/</a></p><p><img src="https://cdn.jsdelivr.net/gh/xieleixielei/picture/202311012014050.webp" alt="img"></p><h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><ol><li><a href="https://blog.csdn.net/qq_41185868/article/details/82793025">Dataset之CIFAR-10：CIFAR-10数据集的简介、下载、使用方法之详细攻略-CSDN博客</a></li><li>[【精选】【神经网络与深度学习】CIFAR10数据集介绍，并使用卷积神经网络训练图像分类模型——<a href="https://blog.csdn.net/weixin_45954454/article/details/114519299">附完整训练代码]<em>路遥</em>.的博客-CSDN博客</a></li><li><a href="https://zhuanlan.zhihu.com/p/573479239">深度学习常用数据集介绍 (持续更新)</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo使用命令</title>
      <link href="/2023/10/08/hexo%E4%BD%BF%E7%94%A8/"/>
      <url>/2023/10/08/hexo%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>新建博客：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">hexo new post &quot;文章标题&quot;<br></code></pre></td></tr></table></figure><p>保存博客内容：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">hexo s<br></code></pre></td></tr></table></figure><p>预览：</p><p><a href="http://localhost:4000/">http://localhost:4000</a></p><p>发布：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">hexo g -d<br></code></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo使用命令</title>
      <link href="/2023/10/08/hello-world/"/>
      <url>/2023/10/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
