<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CV论文复现-paddle指南 | Xielei's Blog</title><meta name="author" content="xie lei"><meta name="copyright" content="xie lei"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="论文复现指南-CV方向本文为针对 CV 方向的复现指南 1. 总览1.1 背景 以深度学习为核心的人工智能技术仍在高速发展，通过论文复现，开发者可以获得    学习成长：自我能力提升 技术积累：对科研或工作有所帮助和启发 社区荣誉：成果被开发者广泛使用    1.2 前序工作基于本指南复现论文过程中，建议开发者准备以下内容。  了解该模型输入输出格式。以AlexNet图像分类任务为例，通过阅读论文">
<meta property="og:type" content="article">
<meta property="og:title" content="CV论文复现-paddle指南">
<meta property="og:url" content="http://example.com/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/index.html">
<meta property="og:site_name" content="Xielei&#39;s Blog">
<meta property="og:description" content="论文复现指南-CV方向本文为针对 CV 方向的复现指南 1. 总览1.1 背景 以深度学习为核心的人工智能技术仍在高速发展，通过论文复现，开发者可以获得    学习成长：自我能力提升 技术积累：对科研或工作有所帮助和启发 社区荣誉：成果被开发者广泛使用    1.2 前序工作基于本指南复现论文过程中，建议开发者准备以下内容。  了解该模型输入输出格式。以AlexNet图像分类任务为例，通过阅读论文">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/logo.jpg">
<meta property="article:published_time" content="2024-01-10T01:57:44.000Z">
<meta property="article:modified_time" content="2024-01-10T02:04:25.612Z">
<meta property="article:author" content="xie lei">
<meta property="article:tag" content="论文复现">
<meta property="article:tag" content="paddle">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/logo.jpg"><link rel="shortcut icon" href="/img/website_icon.png"><link rel="canonical" href="http://example.com/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CV论文复现-paddle指南',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-01-10 10:04:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Xielei's Blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/logo.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Xielei's Blog"><span class="site-name">Xielei's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CV论文复现-paddle指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-10T01:57:44.000Z" title="发表于 2024-01-10 09:57:44">2024-01-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-01-10T02:04:25.612Z" title="更新于 2024-01-10 10:04:25">2024-01-10</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>43分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CV论文复现-paddle指南"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="论文复现指南-CV方向"><a href="#论文复现指南-CV方向" class="headerlink" title="论文复现指南-CV方向"></a>论文复现指南-CV方向</h1><p>本文为针对 <code>CV</code> 方向的复现指南</p>
<h2 id="1-总览"><a href="#1-总览" class="headerlink" title="1. 总览"></a>1. 总览</h2><h3 id="1-1-背景"><a href="#1-1-背景" class="headerlink" title="1.1 背景"></a>1.1 背景</h3><ul>
<li><p>以深度学习为核心的人工智能技术仍在高速发展，通过论文复现，开发者可以获得 </p>
</li>
<li><ul>
<li>学习成长：自我能力提升</li>
<li>技术积累：对科研或工作有所帮助和启发</li>
<li>社区荣誉：成果被开发者广泛使用</li>
</ul>
</li>
</ul>
<h3 id="1-2-前序工作"><a href="#1-2-前序工作" class="headerlink" title="1.2 前序工作"></a>1.2 前序工作</h3><p>基于本指南复现论文过程中，建议开发者准备以下内容。</p>
<ul>
<li><p>了解该模型输入输出格式。以AlexNet图像分类任务为例，通过阅读论文与参考代码，了解到模型输入为<code>[batch_size, 3, 224, 244]</code>的tensor，类型为<code>float32</code>或者<code>float16</code>，label为<code>[batch, ]</code>的label，类型为<code>int64</code>。</p>
</li>
<li><p>准备好训练&#x2F;验证数据集，用于模型训练与评估</p>
</li>
<li><p>准备好fake input data以及label，与模型输入shape、type等保持一致，用于后续模型前向对齐。 </p>
</li>
<li><ul>
<li>在对齐模型前向过程中，我们不需要考虑数据集模块等其他模块，此时使用fake data是将模型结构和数据部分解耦非常合适的一种方式。</li>
<li>将fake data以文件的形式存储下来，也可以保证PaddlePaddle与参考代码的模型结构输入是完全一致的，更便于排查问题。</li>
<li>在该步骤中，以AlexNet为例，生成fake data的脚本可以参考：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/fake_data/gen_fake_data.py">gen_fake_data.py</a>。</li>
</ul>
</li>
<li><p>在特定设备(CPU&#x2F;GPU)上，跑通参考代码的预测过程(前向)以及至少2轮(iteration)迭代过程，保证后续基于PaddlePaddle复现论文过程中可对比。</p>
</li>
<li><p>本文档基于 <code>AlexNet-Prod</code> 代码以及<code>reprod_log</code> whl包进行说明与测试。如果希望体验，建议参考<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/README.md">AlexNet-Reprod文档</a>进行安装与测试。</p>
</li>
<li><p>在复现的过程中，只需要将PaddlePaddle的复现代码以及打卡日志上传至github，不能在其中添加<code>参考代码的实现</code>，在核验通过之后，需要删除打卡日志。建议在初期复现的时候，就将<strong>复现代码与参考代码分成2个文件夹进行管理</strong>。</p>
</li>
</ul>
<h2 id="2-整体框图"><a href="#2-整体框图" class="headerlink" title="2. 整体框图"></a>2. 整体框图</h2><h3 id="2-1-流程概览"><a href="#2-1-流程概览" class="headerlink" title="2.1 流程概览"></a>2.1 流程概览</h3><p>面对一篇计算机视觉论文，复现该论文的整体流程如下图所示。</p>
<p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240110100310487.png" alt="image-20240110100310487"></p>
<p>总共包含13个步骤。为了高效复现论文，设置了6个核验点。如上图中黄色框所示。后续章节会详细介绍上述步骤和核验点，具体内容安排如下：</p>
<ul>
<li>第3章：介绍13个复现步骤的理论知识、实战以及核验流程。</li>
<li>第4章：针对复现流程过程中每个步骤可能出现的问题，本章会进行详细介绍。</li>
</ul>
<h3 id="2-2-reprod-log-whl包"><a href="#2-2-reprod-log-whl包" class="headerlink" title="2.2 reprod_log whl包"></a>2.2 reprod_log whl包</h3><h4 id="2-2-1-reprod-log工具简介"><a href="#2-2-1-reprod-log工具简介" class="headerlink" title="2.2.1 reprod_log工具简介"></a>2.2.1 reprod_log工具简介</h4><p><code>reprod_log</code>是用于论文复现赛中辅助自查和核验工具。该工具源代码地址在：<a target="_blank" rel="noopener" href="https://github.com/WenmuZhou/reprod_log%E3%80%82%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD%E5%A6%82%E4%B8%8B%EF%BC%9A">https://github.com/WenmuZhou/reprod_log。主要功能如下：</a></p>
<ul>
<li>存取指定节点的输入输出tensor</li>
<li>基于文件的tensor读写</li>
<li>2个字典的对比验证</li>
<li>对比结果的输出与记录</li>
</ul>
<p>更多API与使用方法可以参考：<a target="_blank" rel="noopener" href="https://github.com/WenmuZhou/reprod_log/blob/master/README.md">reprod_log API使用说明</a>。</p>
<h4 id="2-2-2-reprod-log使用demo"><a href="#2-2-2-reprod-log使用demo" class="headerlink" title="2.2.2 reprod_log使用demo"></a>2.2.2 reprod_log使用demo</h4><p>下面基于代码：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/reprod_log_demo%EF%BC%8C%E7%BB%99%E5%87%BA%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E8%AF%A5%E5%B7%A5%E5%85%B7%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/reprod_log_demo，给出如何使用该工具。</a></p>
<p>文件夹中包含<code>write_log.py</code>和<code>check_log_diff.py</code>文件，其中<code>write_log.py</code>中给出了<code>ReprodLogger</code>类的使用方法，<code>check_log_diff.py</code>给出了<code>ReprodDiffHelper</code>类的使用方法，依次运行两个python文件，使用下面的方式运行代码。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">进入文件夹</span><br>cd pipeline/reprod_log_demo<br><span class="hljs-meta prompt_"># </span><span class="language-bash">随机生成矩阵，写入文件中</span><br>python3.7 write_log.py<br><span class="hljs-meta prompt_"># </span><span class="language-bash">进行文件对比，输出日志</span><br>python3.7 check_log_diff.py<br></code></pre></td></tr></table></figure>



<p>最终会输出以下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">2021-09-28 01:07:44,832 - reprod_log.utils - INFO - demo_test_1:<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO -     mean diff: check passed: True, value: 0.0<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO - demo_test_2:<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO -     mean diff: check passed: False, value: 0.3336232304573059<br>2021-09-28 01:07:44,832 - reprod_log.utils - INFO - diff check failed<br></code></pre></td></tr></table></figure>



<p>可以看出：对于key为<code>demo_test_1</code>的矩阵，由于diff为0，小于设置的阈值<code>1e-6</code>，核验成功；对于key为<code>demo_test_2</code>的矩阵，由于diff为0.33，大于设置的阈值<code>1e-6</code>，核验失败。</p>
<h4 id="2-2-3-reprod-log在论文复现中应用"><a href="#2-2-3-reprod-log在论文复现中应用" class="headerlink" title="2.2.3 reprod_log在论文复现中应用"></a>2.2.3 reprod_log在论文复现中应用</h4><p>在论文复现中，基于reprod_log的结果记录模块，产出下面若干文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plain">log_reprod<br>├── forward_paddle.npy<br>├── forward_torch.npy    # 与forward_paddle.npy作为一并核查的文件对<br>├── metric_paddle.npy<br>├── metric_torch.npy     # 与metric_paddle.npy作为一并核查的文件对<br>├── loss_paddle.npy<br>├── loss_torch.npy       # 与loss_paddle.npy作为一并核查的文件对<br>├── bp_align_paddle.npy<br>├── bp_align_torch.npy   # 与bp_align_paddle.npy作为一并核查的文件对<br>├── train_align_paddle.npy<br>├── train_align_benchmark.npy # PaddlePaddle提供的参考评估指标<br></code></pre></td></tr></table></figure>



<p>基于reprod_log的<code>ReprodDiffHelper</code>模块，产出下面5个日志文件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plain">├── forward_diff.log     # forward_paddle.npy与forward_torch.npy生成的diff结果文件<br>├── metric_diff.log      # metric_paddle.npy与metric_torch.npy生成的diff结果文件<br>├── loss_diff.log          # loss_paddle.npy与loss_torch.npy生成的diff结果文件<br>├── bp_align_diff.log    # bp_align_paddle.npy与bp_align_torch.npy生成的diff结果文件<br>├── train_align_diff.log # train_align_paddle.npy与train_align_benchmark.npy生成的diff结果文件<br></code></pre></td></tr></table></figure>



<p>上述文件的生成代码都需要开发者进行开发，核验时需要提供上面罗列的所有文件（不需要提供产生这些文件的可运行程序）以及完整的模型训练评估程序和日志。</p>
<p>AlexNet-Prod项目提供了基于reprod_log的前5个核验点对齐核验示例，参考代码地址为：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/%EF%BC%8C%E6%AF%8F%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E7%9A%84README.md%E6%96%87%E6%A1%A3%E6%8F%90%E4%BE%9B%E4%BA%86%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/，每个文件夹中的README.md文档提供了使用说明。</a></p>
<h2 id="3-论文复现理论知识及实战"><a href="#3-论文复现理论知识及实战" class="headerlink" title="3. 论文复现理论知识及实战"></a>3. 论文复现理论知识及实战</h2><h3 id="3-1-模型结构对齐"><a href="#3-1-模型结构对齐" class="headerlink" title="3.1 模型结构对齐"></a>3.1 模型结构对齐</h3><p>对齐模型结构时，一般有3个主要步骤：</p>
<ul>
<li>网络结构代码转换</li>
<li>权重转换</li>
<li>模型组网正确性验证</li>
</ul>
<p>下面详细介绍这3个部分。</p>
<h4 id="3-1-1-网络结构代码转换"><a href="#3-1-1-网络结构代码转换" class="headerlink" title="3.1.1 网络结构代码转换"></a>3.1.1 网络结构代码转换</h4><p><strong>【基本流程】</strong></p>
<p>由于PyTorch的API和PaddlePaddle的API非常相似，可以参考<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">PyTorch-PaddlePaddle API映射表</a><br>，组网部分代码直接进行手动转换即可。</p>
<p><strong>【注意事项】</strong></p>
<p>如果遇到PaddlePaddle没有的API，可以尝试用多种API来组合，也可以给PaddlePaddle团队提<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/issues">ISSUE</a>，获得支持。</p>
<p><strong>【实战】</strong></p>
<p>AlexNet网络结构的PyTorch实现: <a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step1/AlexNet_torch/torchvision/models/alexnet.py">alexnet-pytorch</a></p>
<p>对应转换后的PaddlePaddle实现: <a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step1/AlexNet_paddle/paddlevision/models/alexnet.py">alexnet-paddle</a></p>
<h4 id="3-1-2-权重转换"><a href="#3-1-2-权重转换" class="headerlink" title="3.1.2 权重转换"></a>3.1.2 权重转换</h4><p><strong>【基本流程】</strong></p>
<p>组网代码转换完成之后，需要对模型权重进行转换，如果PyTorch repo中已经提供权重，那么可以直接下载并进行后续的转换；如果没有提供，则可以基于PyTorch代码，随机生成一个初始化权重(定义完model以后，使用<code>torch.save()</code> API保存模型权重)，然后进行权重转换。</p>
<p><strong>【注意事项】</strong></p>
<p>在权重转换的时候，需要注意<code>paddle.nn.Linear</code>以及<code>paddle.nn.BatchNorm2D</code>等API的权重保存格式和名称等与PyTorch稍有diff，具体内容可以参考<code>4.1章节</code>。</p>
<p><strong>【实战】</strong></p>
<p>AlexNet的代码转换脚本可以在这里查看：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py%EF%BC%8C">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py，</a></p>
<p>注意：运行该代码需要首先下载PyTorch的AlexNet预训练模型到该目录下，下载地址为：<a target="_blank" rel="noopener" href="https://download.pytorch.org/models/alexnet-owt-7be5be79.pth">https://download.pytorch.org/models/alexnet-owt-7be5be79.pth</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/weights/torch2paddle.py</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> paddle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">transfer</span>():<br>    input_fp = <span class="hljs-string">&quot;alexnet-owt-7be5be79.pth&quot;</span><br>    output_fp = <span class="hljs-string">&quot;alexnet_paddle.pdparams&quot;</span><br>    torch_dict = torch.load(input_fp)<br>    paddle_dict = &#123;&#125;<br>    fc_names = [<br>        <span class="hljs-string">&quot;classifier.1.weight&quot;</span>, <span class="hljs-string">&quot;classifier.4.weight&quot;</span>, <span class="hljs-string">&quot;classifier.6.weight&quot;</span><br>    ]<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> torch_dict:<br>        weight = torch_dict[key].cpu().detach().numpy()<br>        flag = [i <span class="hljs-keyword">in</span> key <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> fc_names]<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(flag):<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;weight &#123;&#125; need to be trans&quot;</span>.<span class="hljs-built_in">format</span>(key))<br>            weight = weight.transpose()<br>        paddle_dict[key] = weight<br>    paddle.save(paddle_dict, output_fp)<br><br>transfer()<br></code></pre></td></tr></table></figure>



<p>运行完成之后，会在当前目录生成<code>alexnet_paddle.pdparams</code>文件，即为转换后的PaddlePaddle预训练模型。</p>
<h4 id="3-1-3-模型组网正确性验证"><a href="#3-1-3-模型组网正确性验证" class="headerlink" title="3.1.3 模型组网正确性验证"></a>3.1.3 模型组网正确性验证</h4><p><strong>【基本流程】</strong></p>
<ol>
<li>定义PyTorch模型，加载权重，固定seed，基于numpy生成随机数，转换为PyTorch可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li>
<li>定义PaddlePaddle模型，加载权重，固定seed，基于numpy生成随机数，转换为PaddlePaddle可以处理的tensor，送入网络，获取输出，使用reprod_log保存结果。</li>
<li>使用reprod_log排查diff，小于阈值，即可完成自测。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li>模型在前向对齐验证时，需要调用<code>model.eval()</code>方法，保证组网中的随机量被关闭，比如BatchNorm、Dropout等。</li>
<li>给定相同的输入数据，为保证可复现性，如果有随机数生成，固定相关的随机种子。</li>
<li>输出diff可以使用<code>np.mean(np.abs(o1 - o2))</code>进行计算，一般小于1e-6的话，可以认为前向没有问题。如果最终输出结果diff较大，可以使用二分的方法进行排查，比如说ResNet50，包含1个stem、4个res-stage、global avg-pooling以及最后的fc层，那么完成模型组网和权重转换之后，如果模型输出没有对齐，可以尝试输出中间某一个res-stage的tensor进行对比，如果相同，则向后进行排查；如果不同，则继续向前进行排查，以此类推，直到找到导致没有对齐的操作。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>AlexNet模型组网正确性验证可以参考如下示例代码：<br><a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/Step1">https://github.com/littletomatodonkey/AlexNet-Prod/tree/master/pipeline/Step1</a></p>
<p><strong>【核验】</strong></p>
<p>对于待复现的项目，前向对齐核验流程如下。</p>
<ol>
<li>准备输入：fake data</li>
</ol>
<ul>
<li><ul>
<li>使用参考代码的dataloader，生成一个batch的数据，保存下来，在前向对齐时，直接从文件中读入。</li>
<li>固定随机数种子，生成numpy随机矩阵，转化tensor</li>
</ul>
</li>
</ul>
<ol>
<li>保存输出：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为tensor的值。最后将dict保存到文件中。建议命名为<code>forward_paddle.npy</code>和<code>forward_pytorch.npy</code>。</li>
</ul>
</li>
</ul>
<ol>
<li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>forward_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li>
<li>提交内容：新建文件夹，将<code>forward_paddle.npy</code>、<code>forward_pytorch.npy</code>与<code>forward_diff_log.txt</code>文件放在文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li>
<li>注意：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle与PyTorch保存的dict的key需要保持相同，否则report过程可能会提示key无法对应，从而导致report失败，之后的<code>【核验】</code>环节也是如此。</li>
<li>如果是固定随机数种子，建议将fake data保存到dict中，方便check参考代码和PaddlePaddle的输入是否一致。</li>
</ul>
</li>
</ul>
<h3 id="3-2-准备小数据集，验证集数据读取对齐"><a href="#3-2-准备小数据集，验证集数据读取对齐" class="headerlink" title="3.2 准备小数据集，验证集数据读取对齐"></a>3.2 准备小数据集，验证集数据读取对齐</h3><p><strong>【基本流程】</strong></p>
<p>PaddlePaddle中数据集相关的API为<code>paddle.io.Dataset</code>，使用该接口可以完成数据集的单个样本读取。</p>
<p>复现完Dataset之后，可以使用<code>paddle.io.DataLoader</code>，构建Dataloader，对数据进行组batch、批处理，送进网络进行计算。</p>
<p>为后续的快速验证(训练&#x2F;评估&#x2F;预测)，建议准备一个小数据集（训练集和验证集各8~16张图像即可，压缩后数据大小建议在<code>20M</code>以内），放在<code>lite_data</code>文件夹下。</p>
<p><strong>【注意事项】</strong></p>
<p>对于一个数据集，一般有以下一些信息需要重点关注</p>
<ul>
<li>数据集名称、下载地址</li>
<li>训练集&#x2F;验证集&#x2F;测试集图像数量、类别数量、分辨率等</li>
<li>数据集标注格式、标注信息</li>
<li>数据集通用的预处理方法</li>
</ul>
<p>论文中一般会提供数据集的名称以及基本信息。复现过程中，我们在下载完数据之后，建议先检查下是否和论文中描述一致，否则可能存在的问题有：</p>
<ul>
<li>数据集年份不同，比如论文中使用了MS-COCO2014数据集，但是我们下载的是MS-COCO2017数据集，如果不对其进行检查，可能会导致我们最终训练的数据量等与论文中有diff</li>
<li>数据集使用方式不同，有些论文中，可能只是抽取了该数据集的子集进行方法验证，此时需要注意抽取方法，需要保证抽取出的子集完全相同。</li>
<li>在评估指标对齐时，我们可以固定batch size，关闭Dataloader的shuffle操作。</li>
</ul>
<p>构建数据集时，也会涉及到一些预处理方法，以CV领域为例，PaddlePaddle提供了一些现成的视觉类操作api，具体可以参考：<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html">paddle.vision类API</a>。对应地，PyTorch中的数据处理api可以参考：<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">torchvision.transforms类API</a>。对于其中之一，可以找到另一个平台的实现。</p>
<p>此外，</p>
<ul>
<li>有些自定义的数据处理方法，如果不涉及到深度学习框架的部分，可以直接复用。</li>
<li>对于特定任务中的数据预处理方法，比如说图像分类、检测、分割等，如果没有现成的API可以调用，可以参考官方模型套件中的一些实现方法，比如PaddleClas、PaddleDetection、PaddleSeg等。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>AlexNet复现过程中，准备<code>ImageNet小数据集</code>的脚本可以参考<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/tipc/pipeline/Step2/prepare.py">prepare.py</a>。</p>
<p>AlexNet模型复现过程中，数据预处理和Dataset、Dataloader的检查可以参考该文件：<br><a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/test_data.py%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/test_data.py。</a></p>
<p>使用方法可以参考<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/README.md">数据检查文档</a>。</p>
<h3 id="3-3-评估指标对齐"><a href="#3-3-评估指标对齐" class="headerlink" title="3.3 评估指标对齐"></a>3.3 评估指标对齐</h3><p><strong>【基本流程】</strong></p>
<p>PaddlePaddle提供了一系列Metric计算类，比如说<code>Accuracy</code>, <code>Auc</code>, <code>Precision</code>, <code>Recall</code>等，而PyTorch中，目前可以通过组合的方式实现metric计算，或者调用<a target="_blank" rel="noopener" href="https://torchmetrics.readthedocs.io/en/latest/">torchmetrics</a>，在论文复现的过程中，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。具体流程如下。</p>
<ol>
<li>定义PyTorch模型，加载训练好的权重（需要是官网repo提供好的），获取评估结果，使用reprod_log保存结果。</li>
<li>定义PaddlePaddle模型，加载训练好的权重（需要是从PyTorch转换得到），获取评估结果，使用reprod_log保存结果。</li>
<li>使用reprod_log排查diff，小于阈值，即可完成自测。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<p>在评估指标对齐之前，需要注意保证对于该模块，给定相同的输入，二者输出完全一致。</p>
<p><strong>【实战】</strong></p>
<p>评估指标对齐检查方法可以参考文档：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step2/README.md#%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">评估指标对齐检查方法文档</a></p>
<p><strong>【核验】</strong></p>
<p>对于待复现的项目，评估指标对齐核验流程如下。</p>
<ol>
<li>输入：dataloader, model</li>
<li>输出：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>metric_paddle.npy</code>和<code>metric_pytorch.npy</code>。</li>
<li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>metric_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li>
</ul>
</li>
</ul>
<ol>
<li>提交内容：将<code>metric_paddle.npy</code>、<code>metric_pytorch.npy</code>与<code>metric_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li>
<li>注意：</li>
</ol>
<ul>
<li><ul>
<li>数据需要是真实数据</li>
<li>需要检查论文是否只是抽取了验证集&#x2F;测试集中的部分文件，如果是的话，则需要保证PaddlePaddle和参考代码中dataset使用的数据集一致。</li>
</ul>
</li>
</ul>
<h3 id="3-4-损失函数对齐"><a href="#3-4-损失函数对齐" class="headerlink" title="3.4 损失函数对齐"></a>3.4 损失函数对齐</h3><p><strong>【基本流程】</strong></p>
<p>PaddlePaddle与PyTorch均提供了很多loss function，用于模型训练，具体的API映射表可以参考：<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html#lossapi">Loss类API映射列表</a>。以CrossEntropyLoss为例，主要区别为：</p>
<ul>
<li>PaddlePaddle提供了对软标签、指定softmax计算纬度的支持。</li>
</ul>
<p>如果论文中使用的loss function没有指定的API，则可以尝试通过组合API的方式，实现自定义的loss function。</p>
<p>具体流程如下。</p>
<ol>
<li>定义PyTorch模型，加载权重，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PyTorch可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li>
<li>定义PaddlePaddle模型，加载fake data 和 fake label（或者固定seed，基于numpy生成随机数），转换为PaddlePaddle可以处理的tensor，送入网络，获取loss结果，使用reprod_log保存结果。</li>
<li>使用reprod_log排查diff，小于阈值，即可完成自测。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li>计算loss的时候，建议设置<code>model.eval()</code>，避免模型中随机量的问题。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>本部分可以参考文档：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step3/README.md%E3%80%82">https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step3/README.md。</a></p>
<p><strong>【核验】</strong></p>
<p>对于待复现的项目，损失函数对齐核验流程如下。</p>
<ol>
<li>输入：fake data &amp; label</li>
<li>输出：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>loss_paddle.npy</code>和<code>loss_pytorch.npy</code>。</li>
</ul>
</li>
</ul>
<ol>
<li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>loss_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li>
<li>提交内容：将<code>loss_paddle.npy</code>、<code>loss_pytorch.npy</code>与<code>loss_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li>
</ol>
<h3 id="3-5-优化器对齐"><a href="#3-5-优化器对齐" class="headerlink" title="3.5 优化器对齐"></a>3.5 优化器对齐</h3><p><strong>【基本流程】</strong></p>
<p>PaddlePaddle中的optimizer有<code>paddle.optimizer</code>等一系列实现，PyTorch中则有<code>torch.Optim</code>等一系列实现。</p>
<p><strong>【注意事项】</strong></p>
<p>以SGD等优化器为例，PaddlePaddle与Pytorch的优化器区别主要如下。</p>
<ul>
<li>PaddlePaddle在优化器中增加了对梯度裁剪的支持，在训练GAN或者一些NLP、多模态任务中，这个用到的比较多。</li>
<li>PaddlePaddle的SGD不支持动量更新、动量衰减和Nesterov动量，这里需要使用<code>paddle.optimizer.Momentum</code> API实现这些功能。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>本部分对齐建议对照<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/Overview_cn.html">PaddlePaddle优化器API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p>
<h3 id="3-6-学习率对齐"><a href="#3-6-学习率对齐" class="headerlink" title="3.6 学习率对齐"></a>3.6 学习率对齐</h3><p><strong>【基本流程】</strong></p>
<ul>
<li>学习率策略主要用于指定训练过程中的学习率变化曲线，这里可以将定义好的学习率策略，不断step，即可得到对应的学习率值，可以将学习率值保存在列表或者矩阵中，使用<code>reprod_log</code>工具判断二者是否对齐。</li>
</ul>
<p><strong>【注意事项】</strong></p>
<p>PaddlePaddle中，需要首先构建学习率策略，再传入优化器对象中；对于PyTorch，如果希望使用更丰富的学习率策略，需要先构建优化器，再传入学习率策略类API。</p>
<p><strong>【实战】</strong></p>
<p>学习率复现对齐，可以参考代码：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step4/README.md#%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%B9%E9%BD%90%E9%AA%8C%E8%AF%81">学习率对齐验证文档</a>。</p>
<h3 id="3-7-正则化策略对齐"><a href="#3-7-正则化策略对齐" class="headerlink" title="3.7 正则化策略对齐"></a>3.7 正则化策略对齐</h3><p><strong>【基本流程】</strong></p>
<p>L2正则化策略用于模型训练，可以防止模型对训练数据过拟合，L1正则化可以用于得到稀疏化的权重矩阵，PaddlePaddle中有<code>paddle.regularizer.L1Decay</code>与<code>paddle.regularizer.L2Decay</code> API。PyTorch中，torch.optim集成的优化器只有L2正则化方法，直接在构建optimizer的时候，传入<code>weight_decay</code>参数即可。</p>
<p><strong>【注意事项】</strong></p>
<ul>
<li>PaddlePaddle的optimizer中支持L1Decay&#x2F;L2Decay。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>本部分对齐建议对照<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/regularizer/L2Decay_cn.html">PaddlePaddle正则化API文档</a>与参考代码的优化器实现进行对齐，用之后的反向对齐统一验证该模块的正确性。</p>
<h3 id="3-8-反向对齐"><a href="#3-8-反向对齐" class="headerlink" title="3.8 反向对齐"></a>3.8 反向对齐</h3><p><strong>【基本流程】</strong></p>
<p>此处可以通过numpy生成假的数据和label（推荐），也可以准备固定的真实数据。具体流程如下。</p>
<ol>
<li>检查两个代码的训练超参数全部一致，如优化器及其超参数、学习率、BatchNorm&#x2F;LayerNorm中的eps等。</li>
<li>将PaddlePaddle与PyTorch网络中涉及的所有随机操作全部关闭，如dropout、drop_path等，推荐将模型设置为eval模式（<code>model.eval()</code>）</li>
<li>加载相同的weight dict（可以通过PyTorch来存储随机的权重），将准备好的数据分别传入网络并迭代，观察二者loss是否一致（此处batch-size要一致，如果使用多个真实数据，要保证传入网络的顺序一致）</li>
<li>如果经过2轮以上，loss均可以对齐，则基本可以认为反向对齐。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li>如果第一轮loss就没有对齐，则需要仔细排查一下模型前向部分。</li>
<li>如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证并反馈。</li>
</ul>
<p>梯度的打印方法示例代码如下所示，注释掉的内容即为打印网络中所有参数的梯度shape。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 代码地址：https://github.com/littletomatodonkey/AlexNet-Prod/blob/63184b258eda650e7a8b7f2610b55f4337246630/pipeline/Step4/AlexNet_paddle/train.py#L93</span><br>loss_list = []<br><span class="hljs-keyword">for</span> idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(max_iter):<br>    image = paddle.to_tensor(fake_data)<br>    target = paddle.to_tensor(fake_label)<br><br>    output = model(image)<br>    loss = criterion(output, target)<br>    loss.backward()<br>    <span class="hljs-comment"># for name, tensor in model.named_parameters():</span><br>    <span class="hljs-comment">#     grad = tensor.grad</span><br>    <span class="hljs-comment">#     print(name, tensor.grad.shape)</span><br>    <span class="hljs-comment">#     break</span><br>    optimizer.step()<br>    optimizer.clear_grad()<br>    loss_list.append(loss)<br></code></pre></td></tr></table></figure>



<p><strong>【实战】</strong></p>
<p>本部分可以参考文档：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step4/README.md#%E5%8F%8D%E5%90%91%E5%AF%B9%E9%BD%90%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95">反向对齐操作文档</a>。</p>
<p><strong>【核验】</strong></p>
<p>对于待复现的项目，反向对齐核验流程如下。</p>
<ol>
<li>输入：fake data &amp; label</li>
<li>输出：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle&#x2F;PyTorch：dict，key为tensor的name（自定义），value为具体loss的值。最后将dict使用reprod_log保存到各自的文件中，建议命名为<code>bp_align_paddle.npy</code>和<code>bp_align_pytorch.npy</code>。</li>
</ul>
</li>
</ul>
<ol>
<li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>bp_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li>
<li>提交内容：将<code>bp_align_paddle.npy</code>、<code>bp_align_pytorch.npy</code>与<code>bp_align_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，后续的输出结果和自查日志也放在该文件夹中，一并打包上传即可。</li>
<li>注意：</li>
</ol>
<ul>
<li><ul>
<li>loss需要保存至少2轮以上。</li>
<li>在迭代的过程中，需要保证模型的batch size等超参数完全相同</li>
<li>在迭代的过程中，需要设置<code>model.eval()</code>，使用固定的假数据，同时加载相同权重的预训练模型。</li>
</ul>
</li>
</ul>
<h3 id="3-9-训练集数据读取对齐"><a href="#3-9-训练集数据读取对齐" class="headerlink" title="3.9 训练集数据读取对齐"></a>3.9 训练集数据读取对齐</h3><p><strong>【基本流程】</strong></p>
<p>该部分内容与3.2节内容基本一致，参考PyTorch的代码，实现训练集数据读取与预处理模块即可。</p>
<p><strong>【注意事项】</strong></p>
<p>该部分内容，可以参考3.8节的自测方法，将输入的<code>fake data &amp; label</code>替换为训练的dataloader，但是需要注意的是：</p>
<ul>
<li>在使用train dataloader的时候，建议设置random seed，对于PyTorch来说</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#initialize random seed</span><br>torch.manual_seed(config.SEED)<br>torch.cuda.manual_seed_all(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure>



<p>对于PaddlePaddle来说</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">paddle.seed(config.SEED)<br>np.random.seed(config.SEED)<br>random.seed(config.SEED)<br></code></pre></td></tr></table></figure>



<p><strong>【实战】</strong></p>
<p>本部分对齐建议对照<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/vision/Overview_cn.html">PaddlePaddle vision高层API文档</a>与参考代码的数据预处理实现进行对齐，用之后的训练对齐统一验证该模块的正确性。</p>
<h3 id="3-10-网络初始化对齐"><a href="#3-10-网络初始化对齐" class="headerlink" title="3.10 网络初始化对齐"></a>3.10 网络初始化对齐</h3><p><strong>【基本流程】</strong></p>
<ul>
<li>下面给出了部分初始化API的映射表。</li>
</ul>
<table>
<thead>
<tr>
<th>PaddlePaddle API</th>
<th>PyTorch API</th>
</tr>
</thead>
<tbody><tr>
<td>paddle.nn.initializer.KaimingNormal</td>
<td>torch.nn.init.kaiming_normal_</td>
</tr>
<tr>
<td>paddle.nn.initializer.KaimingUniform</td>
<td>torch.nn.init.kaiming_uniform_</td>
</tr>
<tr>
<td>paddle.nn.initializer.XavierNormal</td>
<td>torch.nn.init.xavier_normal_</td>
</tr>
<tr>
<td>paddle.nn.initializer.XavierUniform</td>
<td>torch.nn.init.xavier_uniform_</td>
</tr>
</tbody></table>
<p><strong>【注意事项】</strong></p>
<ul>
<li>更多初始化API可以参考<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.init.html">PyTorch初始化API文档</a>以及<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle初始化API文档</a>。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>本部分对齐建议对照<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/Overview_cn.html#chushihuaxiangguan">PaddlePaddle 初始化API文档</a>与参考代码的初始化实现对齐。</p>
<h3 id="3-11-模型训练对齐"><a href="#3-11-模型训练对齐" class="headerlink" title="3.11 模型训练对齐"></a>3.11 模型训练对齐</h3><p><strong>【基本流程】</strong></p>
<p>完成前面的步骤之后，就可以开始全量数据的训练对齐任务了。按照下面的步骤进行训练对齐。</p>
<ol>
<li>准备train&#x2F;eval data, loader, model</li>
<li>对model按照论文所述进行初始化(如果论文中提到加载pretrain，则按需加载pretrained model)</li>
<li>加载配置，开始训练，迭代得到最终模型与评估指标，将评估指标使用reprod_log保存到文件中。</li>
<li>将PaddlePaddle提供的参考指标使用reprod_log提交到另一个文件中。</li>
<li>使用reprod_log排查diff，小于阈值，即可完成自测。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li><p>【强烈】建议先做完反向对齐之后再进行模型训练对齐，二者之间的不确定量包括：数据集、PaddlePaddle与参考代码在模型training mode下的区别，初始化参数。</p>
</li>
<li><p>在训练对齐过程中，受到较多随机量的影响，精度有少量diff是正常的，以ImageNet1k数据集的分类为例，diff在0.15%以内可以认为是正常的，这里可以根据不同的任务，适当调整对齐检查的阈值(<code>ReprodDiffHelper.report</code>函数中的<code>diff_threshold</code>参数)。</p>
</li>
<li><p>训练过程中的波动是正常的，如果最终收敛结果不一致，可以 </p>
</li>
<li><ul>
<li>仔细排查Dropout、BatchNorm以及其他组网模块及超参是否无误。</li>
<li>基于参考代码随机生成一份预训练模型，转化为PaddlePaddle的模型，并使用PaddlePaddle加载训练，对比二者的收敛曲线与最终结果，排查初始化影响。</li>
<li>使用参考代码的Dataloader生成的数据，进行模型训练，排查train dataloader的影响。</li>
</ul>
</li>
</ul>
<p><strong>【实战】</strong></p>
<p>本部分可以参考文档：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step5/README.md">训练对齐操作文档</a>。</p>
<p><strong>【核验】</strong></p>
<p>对于待复现的项目，训练对齐核验流程如下。</p>
<ol>
<li>输入：train&#x2F;eval dataloader, model</li>
<li>输出：</li>
</ol>
<ul>
<li><ul>
<li>PaddlePaddle：dict，key为保存值的name（自定义），value为具体评估指标的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_paddle.npy</code>。</li>
<li>benchmark：dict，key为保存值的name（自定义），value为论文复现赛的评估指标要求的值。最后将dict使用reprod_log保存到文件中，建议命名为<code>train_align_benchmark.npy</code>。</li>
</ul>
</li>
</ul>
<ol>
<li>自测：使用reprod_log加载2个文件，使用report功能，记录结果到日志文件中，建议命名为<code>train_align_diff_log.txt</code>，观察diff，二者diff小于特定的阈值即可。</li>
<li>提交内容：将<code>train_align_paddle.npy</code>、<code>train_align_benchmark.npy</code>与<code>train_align_diff_log.txt</code>文件备份到<code>3.1节核验环节</code>新建的文件夹中，最终一并打包上传即可。</li>
</ol>
<h3 id="3-12-规范训练日志"><a href="#3-12-规范训练日志" class="headerlink" title="3.12 规范训练日志"></a>3.12 规范训练日志</h3><p><strong>【背景】</strong></p>
<p>训练过程中，损失函数(<code>loss</code>)可以直接反映目前网络的收敛情况，数据耗时(<code>reader_cost</code>)对于分析GPU利用率非常重要，一个batch训练耗时(<code>batch_cost</code>)对于我们判断模型的整体训练时间非常重要，因此希望在训练中添加这些统计信息，便于分析模型的收敛和资源利用情况。</p>
<p><strong>【基本流程】</strong></p>
<ol>
<li>在训练代码中添加日志统计信息，对训练中的信息进行统计。</li>
</ol>
<ul>
<li>必选项：损失值<code>loss</code>, 训练耗时<code>batch_cost</code>, 数据读取耗时<code>reader_cost</code>。</li>
<li>建议项：当前<code>epoch</code>, 当前迭代次数<code>iter</code>，学习率(<code>lr</code>), 准确率(<code>acc</code>)等。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain">[2021/12/04 05:16:13] root INFO: [epoch 0, iter 0][TRAIN]avg_samples: 32.0 , avg_reader_cost: 0.0010543 sec, avg_batch_cost: 0.0111100 sec, loss: 0.3450000 , avg_ips: 2880.2952878 images/sec<br>[2021/12/04 05:16:13] root INFO: [epoch 0, iter 0][TRAIN]avg_samples: 32.0 , avg_reader_cost: 0.0010542 sec, avg_batch_cost: 0.0111101 sec, loss: 0.2450000 , avg_ips: 2880.2582019 images/sec<br></code></pre></td></tr></table></figure>



<ol>
<li>如果训练中同时包含评估过程，则也需要在日志里添加模型的<code>评估结果</code>信息。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li>日志打印也比较耗时，这里不建议统计其耗时，防止对统计结果造成影响。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>参考代码：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/d0eab851603a8d9097b1b8d6089f26d96c6707b0/pipeline/Step5/AlexNet_paddle/train.py#L204">train.py</a>。</p>
<p>具体地，规范化的训练日志可以按照如下所示的方式实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_one_epoch</span>(<span class="hljs-params">model,</span><br><span class="hljs-params">                    criterion,</span><br><span class="hljs-params">                    optimizer,</span><br><span class="hljs-params">                    data_loader,</span><br><span class="hljs-params">                    epoch,</span><br><span class="hljs-params">                    print_freq</span>):<br>    model.train()<br>    <span class="hljs-comment"># training log</span><br>    train_reader_cost = <span class="hljs-number">0.0</span><br>    train_run_cost = <span class="hljs-number">0.0</span><br>    total_samples = <span class="hljs-number">0</span><br>    acc = <span class="hljs-number">0.0</span><br>    reader_start = time.time()<br>    batch_past = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> batch_idx, (image, target) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(data_loader):<br>        train_reader_cost += time.time() - reader_start<br>        train_start = time.time()<br>        output = model(image)<br>        loss = criterion(output, target)<br>        loss.backward()<br>        optimizer.step()<br>        optimizer.clear_grad()<br>        train_run_cost += time.time() - train_start<br>        acc = utils.accuracy(output, target).item()<br>        total_samples += image.shape[<span class="hljs-number">0</span>]<br>        batch_past += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> batch_idx &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> batch_idx % print_freq == <span class="hljs-number">0</span>:<br>            msg = <span class="hljs-string">&quot;[Epoch &#123;&#125;, iter: &#123;&#125;] acc: &#123;:.5f&#125;, lr: &#123;:.5f&#125;, loss: &#123;:.5f&#125;, avg_reader_cost: &#123;:.5f&#125; sec, avg_batch_cost: &#123;:.5f&#125; sec, avg_samples: &#123;&#125;, avg_ips: &#123;:.5f&#125; images/sec.&quot;</span>.<span class="hljs-built_in">format</span>(<br>                epoch, batch_idx, acc / batch_past,<br>                optimizer.get_lr(),<br>                loss.item(), train_reader_cost / batch_past,<br>                (train_reader_cost + train_run_cost) / batch_past,<br>                total_samples / batch_past,<br>                total_samples / (train_reader_cost + train_run_cost))<br>            <span class="hljs-comment"># just log on 1st device</span><br>            <span class="hljs-keyword">if</span> paddle.distributed.get_rank() &lt;= <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(msg)<br>            sys.stdout.flush()<br>            train_reader_cost = <span class="hljs-number">0.0</span><br>            train_run_cost = <span class="hljs-number">0.0</span><br>            total_samples = <span class="hljs-number">0</span><br>            acc = <span class="hljs-number">0.0</span><br>            batch_past = <span class="hljs-number">0</span><br><br>        reader_start = time.time()<br></code></pre></td></tr></table></figure>



<h3 id="3-13-预测程序开发"><a href="#3-13-预测程序开发" class="headerlink" title="3.13 预测程序开发"></a>3.13 预测程序开发</h3><p><strong>【基本流程】</strong></p>
<p>模型训练完成之后，对图像使用该模型基于训练引擎进行预测，主要包含</p>
<ol>
<li>定义模型结构，加载模型权重；</li>
<li>加载图像，对其进行数据预处理；</li>
<li>模型预测；</li>
<li>对模型输出进行后处理，获取最终输出结果。</li>
</ol>
<p><strong>【注意事项】</strong></p>
<ul>
<li>在模型评估过程中，为了保证数据可以组batch，我们一般会使用resize&#x2F;crop&#x2F;padding等方法去保持尺度的一致性，在预测推理过程中，需要注意crop是否合适，比如OCR识别任务中，crop的操作会导致识别结果不全。</li>
</ul>
<p><strong>【实战】</strong></p>
<p>AlexNet的预测程序：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/tipc/pipeline/Step5/AlexNet_paddle/tools/predict.py">predict.py</a>。</p>
<p><strong>【核验】</strong></p>
<p>预测程序按照文档中的命令操作可以正常跑通，文档中给出预测结果可视化结果或者终端输出结果。</p>
<h3 id="3-14-单机多卡训练"><a href="#3-14-单机多卡训练" class="headerlink" title="3.14 单机多卡训练"></a>3.14 单机多卡训练</h3><p>如果希望使用单机多卡提升训练效率，可以从以下几个过程对代码进行修改。</p>
<h4 id="3-14-1-数据读取"><a href="#3-14-1-数据读取" class="headerlink" title="3.14.1 数据读取"></a>3.14.1 数据读取</h4><p>对于PaddlePaddle来说，多卡数据读取这块主要的变化在sampler</p>
<p>对于单机单卡，sampler实现方式如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train_sampler = paddle.io.RandomSampler(dataset)<br>train_batch_sampler = paddle.io.BatchSampler(<br>    sampler=train_sampler, batch_size=args.batch_size)<br></code></pre></td></tr></table></figure>



<p>对于单机多卡任务，sampler实现方式如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">train_batch_sampler = paddle.io.DistributedBatchSampler(<br>        dataset=dataset,<br>        batch_size=args.batch_size,<br>        shuffle=<span class="hljs-literal">True</span>,<br>        drop_last=<span class="hljs-literal">False</span><br>    )<br></code></pre></td></tr></table></figure>



<p>注意：在这种情况下，单机多卡的代码仍然能够以单机单卡的方式运行，因此建议以这种sampler方式进行论文复现。</p>
<h4 id="3-14-2-多卡模型初始化"><a href="#3-14-2-多卡模型初始化" class="headerlink" title="3.14.2 多卡模型初始化"></a>3.14.2 多卡模型初始化</h4><p>如果以多卡的方式运行，需要初始化并行训练环境，代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>        paddle.distributed.init_parallel_env()<br></code></pre></td></tr></table></figure>



<p>在模型组网并初始化参数之后，需要使用<code>paddle.DataParallel()</code>对模型进行封装，使得模型可以通过数据并行的模式被执行。代码如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> paddle.distributed.get_world_size() &gt; <span class="hljs-number">1</span>:<br>    model = paddle.DataParallel(model)<br></code></pre></td></tr></table></figure>



<h4 id="3-14-3-模型保存、日志保存等其他模块"><a href="#3-14-3-模型保存、日志保存等其他模块" class="headerlink" title="3.14.3 模型保存、日志保存等其他模块"></a>3.14.3 模型保存、日志保存等其他模块</h4><p>以模型保存为例，我们只需要在0号卡上保存即可，否则多个trainer同时保存的话，可能会造成写冲突，导致最终保存的模型不可用。</p>
<h4 id="3-14-4-程序启动方式"><a href="#3-14-4-程序启动方式" class="headerlink" title="3.14.4 程序启动方式"></a>3.14.4 程序启动方式</h4><p>对于单机单卡，启动脚本如下所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CUDA_VISIBLE_DEVICES=0<br>python3.7 train.py \<br>    --data-path /paddle/data/ILSVRC2012_torch \<br>    --lr 0.00125 \<br>    --batch-size 32 \<br>    --output-dir &quot;./output/&quot;<br></code></pre></td></tr></table></figure>



<p>对于单机多卡（示例中为8卡训练），启动脚本如下所示。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7<br><br>python3.7 -m paddle.distributed.launch \<br>    --gpus=&quot;0,1,2,3,4,5,6,7&quot; \<br>    train.py \<br>    --data-path /paddle/data/ILSVRC2012_torch \<br>    --lr 0.01 \<br>    --batch-size 32 \<br>    --output-dir &quot;./output/&quot;<br></code></pre></td></tr></table></figure>



<p>注意：这里8卡训练时，虽然单卡的batch size没有变化(32)，但是总卡的batch size相当于是单卡的8倍，因此学习率也设置为了单卡时的8倍。</p>
<p><strong>【实战】</strong></p>
<p>本部分可以参考文档：<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/master/pipeline/Step5/AlexNet_paddle/shell/train_dist.sh">单机多卡训练脚本</a>。</p>
<h2 id="4-论文复现注意事项与FAQ"><a href="#4-论文复现注意事项与FAQ" class="headerlink" title="4. 论文复现注意事项与FAQ"></a>4. 论文复现注意事项与FAQ</h2><h3 id="4-1-通用注意事项"><a href="#4-1-通用注意事项" class="headerlink" title="4.1 通用注意事项"></a>4.1 通用注意事项</h3><ul>
<li>需要仔细对照PaddlePaddle与参考代码的优化器参数实现，确保优化器参数严格对齐。</li>
<li>如果遇到一些Paddle不支持的API操作，可以尝试使用替代实现进行复现。如下面的PyTorch代码，PaddlePaddle中可以通过slice + concat API的组合形式进行功能实现。同时，对于这个问题，建议优先给Paddle提<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，开发人员会根据优先级进行开发。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.stack([<br>    per_locations[:, <span class="hljs-number">0</span>] - per_box_regression[:, <span class="hljs-number">0</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] - per_box_regression[:, <span class="hljs-number">1</span>],<br>    per_locations[:, <span class="hljs-number">0</span>] + per_box_regression[:, <span class="hljs-number">2</span>],<br>    per_locations[:, <span class="hljs-number">1</span>] + per_box_regression[:, <span class="hljs-number">3</span>],<br>], dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<ul>
<li><p>如果遇到Paddle不包含的OP或者API，比如(1) 如果是某些算法实现存在调用了外部OP，而且Paddle也不包含该OP实现；(2) 其他框架存在的API或者OP，但是Paddle中没有这些OP。此时： </p>
</li>
<li><ul>
<li>对于Paddle资深用户来说，可以尝试使用Paddle的自定义算子功能，存在一定的代码开发量。</li>
<li>对于初学者来说，可以给Paddle提<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，列出Paddle不支持的实现，Paddle开发人员会根据优先级进行实现。</li>
</ul>
</li>
<li><p>PaddlePaddle与PyTorch对于不同名称的API，实现的功能可能是相同的，复现的时候注意，比如<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/optimizer/lr/StepDecay_cn.html#stepdecay">paddle.optimizer.lr.StepDecay</a>与<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR">torch.optim.lr_scheduler.StepLR</a> ，关于PaddlePaddle与PyTorch更多API的映射关系可以参考：<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/08_api_mapping/pytorch_api_mapping_cn.html">API映射表</a>。 </p>
</li>
<li><p>对于PaddlePaddle来说，通过<code>paddle.set_device</code>函数（全局）来确定模型结构是运行在什么设备上，对于torch来说，是通过<code>model.to(&quot;device&quot;)</code> （局部）来确定模型结构的运行设备，这块在复现的时候需要注意。 </p>
</li>
<li><p>安装paddle的develop版本：在 Paddle 修复了框架的问题或者新增了API和功能之后，如果需要马上使用，可以采用以下方式安装最新的 develop 版本： </p>
</li>
<li><ul>
<li>进入 <a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/develop/install/pip/linux-pip.html">Paddle 官网</a>，选择develop版本，并根据自己的情况选择其他字段，根据生成的安装信息安装，当选择 Linux-pip-CUDA10.2字段后，就可以按照下面的信息安装。</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">python -m pip install paddlepaddle-gpu==0.0.0.post102 -f https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html<br></code></pre></td></tr></table></figure>

<ul>
<li><ul>
<li>如果不确定自己安装的是否是最新版本，可以进入<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/whl/linux/gpu/develop.html">网站</a>下载对应的包并查看时间戳。</li>
</ul>
</li>
<li><p>如果遇到复现时间较长的论文，我们建议： </p>
</li>
<li><ul>
<li>根据自己的时间、资源、战略部署评估是否复现这个论文复现；</li>
<li>在决定复现的情况下，参照本复现指南中的对齐操作对模型、数据、优化方式等对齐，以最快的时间排除问题。</li>
</ul>
</li>
</ul>
<h3 id="4-2-模型结构对齐"><a href="#4-2-模型结构对齐" class="headerlink" title="4.2 模型结构对齐"></a>4.2 模型结构对齐</h3><h4 id="4-2-1-API"><a href="#4-2-1-API" class="headerlink" title="4.2.1 API"></a>4.2.1 API</h4><ul>
<li><p>对于 <code>paddle.nn.Linear</code> 层的weight参数，PaddlePaddle与PyTorch的保存方式不同，在转换时需要进行转置，示例代码可以参考<a target="_blank" rel="noopener" href="https://github.com/littletomatodonkey/AlexNet-Prod/blob/e3855e0b1992332c2765ccf627d0c5f5f68232fe/pipeline/weights/torch2paddle.py#L19">AlexNet权重转换脚本</a>。</p>
</li>
<li><p><code>paddle.nn.BatchNorm2D</code> 包含4个参数<code>weight</code>, <code>bias</code>, <code>_mean</code>, <code>_variance</code>，torch.nn.BatchNorm2d包含4个参数<code>weight</code>,  <code>bias</code>, <code>running_mean</code>, <code>running_var</code>, <code>num_batches_tracked</code>。 其中，<code>num_batches_tracked</code>在PaddlePaddle中没有用到，剩下4个的对应关系为 </p>
</li>
<li><ul>
<li><code>weight</code> -&gt; <code>weight</code></li>
<li><code>bias</code> -&gt; <code>bias</code></li>
<li><code>_variance</code> -&gt; <code>running_var</code></li>
<li><code>_mean</code> -&gt; <code>running_mean</code></li>
</ul>
</li>
<li><p><code>paddle.nn.AvgPool2D</code>需要将 <code>exclusive</code> 参数设为 <code>False</code> ，结果才能 PyTorch 的默认行为一致。</p>
</li>
<li><p><code>torch.masked_fill</code>函数的功能目前可以使用<code>paddle.where</code>进行实现，可以参考：<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/faq/train_cn.html#paddletorch-masked-fillapi">链接</a>。</p>
</li>
<li><p><code>pack_padded_sequence</code>和<code>pad_packed_sequence</code>这两个API目前PaddlePaddle中没有实现，可以直接在RNN或者LSTM的输入中传入<code>sequence_length</code>来实现等价的功能。</p>
</li>
</ul>
<h4 id="4-2-2-权重转换"><a href="#4-2-2-权重转换" class="headerlink" title="4.2.2 权重转换"></a>4.2.2 权重转换</h4><ul>
<li>在权重转换的时候，不能只关注参数的名称，比如说有些<code>paddle.nn.Linear</code>层，但是定义的变量名称为<code>conv</code>，这种也是需要进行权重转置的。</li>
<li>权重转换时，建议同时打印 Paddle 和 PyTorch 对应权重的shape，以防止名称相似但是shape不同的参数权重转换报错。</li>
</ul>
<h4 id="4-2-3-模型组网正确性验证"><a href="#4-2-3-模型组网正确性验证" class="headerlink" title="4.2.3 模型组网正确性验证"></a>4.2.3 模型组网正确性验证</h4><ul>
<li>在论文复现的过程中，可能会遇到一些经典的模型结构，比如ResNet等，Paddle官方也提供了ResNet的实现，但是这里建议自己根据PyTorch代码重新实现一遍，一方面是对整体的模型结构更加熟悉，另一方面也保证模型结构和权重完全对齐。</li>
<li>在复杂的网络结构中，如果前向结果对不齐，可以按照模块排查问题，比如依次获取backbone、neck、head输出等，看下问题具体出现在哪个子模块，再进到子模块详细排查。</li>
<li>网络结构对齐后，尽量使用训练好的预训练模型和真实的图片进行前向diff计算，这样更准确。</li>
</ul>
<h3 id="4-3-验证-测试集数据读取对齐"><a href="#4-3-验证-测试集数据读取对齐" class="headerlink" title="4.3 验证&#x2F;测试集数据读取对齐"></a>4.3 验证&#x2F;测试集数据读取对齐</h3><ul>
<li>如果使用 PaddlePaddle 提供的数据集API，比如 <code>paddle.vision.datasets.Cifar10</code>等，可能无法完全与参考代码在数据顺序上保持一致，但是这些数据集的实现都是经过广泛验证的，可以使用。此时对数据预处理和后处理进行排查就好。<code>数据集+数据处理</code>的部分可以通过评估指标对齐完成自查。</li>
<li>需要仔细排查数据预处理，不仅包含的预处理方法相同，也需要保证预处理的流程相同，比如先padding再做归一化与先做归一化再padding，得到的结果是不同的。</li>
</ul>
<h3 id="4-4-评估指标对齐"><a href="#4-4-评估指标对齐" class="headerlink" title="4.4 评估指标对齐"></a>4.4 评估指标对齐</h3><ul>
<li>真实数据评估时，需要注意评估时 <code>paddle.io.DataLoader</code> 的 <code>drop_last</code> 参数是否打开(文档<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/io/DataLoader_cn.html#dataloader">链接</a>)，复现代码需要与参考代码保持一致，否则最后不够batch-size的数据的评估会有diff。</li>
<li>在识别或者检索过程中，为了加速评估过程，往往会将评估函数由CPU实现改为GPU实现，由此会带来评估函数输出的不一致。这是由于sort函数对于相同值的排序结果不同带来的。在复现的过程中，如果可以接受轻微的指标不稳定，可以使用PaddlePaddle的sort函数，如果对于指标非常敏感，同时对速度性能要求很高，可以给PaddlePaddle提<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/issues/new/choose">ISSUE</a>，由研发人员高优开发。</li>
<li>在检测任务中，评估流程往往和训练流程有一定差异，例如RPN阶段NMS的参数等，这里需要仔细检查评估时的超参数，不要将训练超参和评估超参弄混淆。</li>
<li>在OCR等任务中，需要注意评估过程也会对gt信息进行修正，比如大小写等，也会过滤掉一些样本，这里需要注意过滤规则，确保有效评估数据集一致。</li>
</ul>
<h3 id="4-5-损失函数对齐"><a href="#4-5-损失函数对齐" class="headerlink" title="4.5 损失函数对齐"></a>4.5 损失函数对齐</h3><ul>
<li>部分算法的损失函数中会用到 bool 索引，这时候可以使用<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/where_cn.html#where">paddle.where</a> 代替。</li>
<li><code>paddle.nn.CrossEntropyLoss</code> 默认是在最后一维(axis&#x3D;-1)计算损失函数，而 <code>torch.nn.CrossEntropyLoss</code> 是在axis&#x3D;1的地方计算损失函数，因此如果输入的维度大于2，这里需要保证计算的维(axis)相同，否则可能会出错。</li>
<li>在生成模型中会遇到梯度损失，需要对模型中的算子求二次梯度，目前<code>MaxPooling</code>暂时不支持二次梯度，如果复现的过程中遇到了需要对<code>MaxPooling</code>求二次梯度的情况，可以和Paddle官方开发同学反馈，进一步确认解决方案。</li>
<li>在保存损失函数值的时候，注意要使用<code>paddle.no_grad</code>，或者仅仅保存转换成 numpy 的数组，避免损失没有析构导致内存泄漏问题。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 错误示范</span><br>loss = celoss(pred, label)<br>avg_loss += loss<br><span class="hljs-comment"># 正确示范1</span><br>loss = celoss(pred, label)<br>avg_loss += loss.numpy()<br><span class="hljs-comment"># 正确示范2</span><br>loss = celoss(pred, label)<br><span class="hljs-keyword">with</span> paddle.no_grad()<br>    avg_loss += loss<br></code></pre></td></tr></table></figure>

<ul>
<li>目前PaddlePaddle中没有HingeEmbeddingLoss API，可以使用组合的方式进行实现，参考实现：<a target="_blank" rel="noopener" href="https://github.com/ImportPaddle/DiscoGAN-Paddle/blob/main/discogan/loss_fn.py">链接</a>。</li>
</ul>
<h3 id="4-6-优化器对齐"><a href="#4-6-优化器对齐" class="headerlink" title="4.6 优化器对齐"></a>4.6 优化器对齐</h3><ul>
<li>Paddle目前支持在 <code>optimizer</code> 中通过设置 <code>params_groups</code> 的方式设置不同参数的更新方式，可以参考<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/optimizer/optimizer.py#L107">代码示例</a> 。</li>
<li>有些模型训练时，会使用梯度累加策略，即累加到一定step数量之后才进行参数更新，这时在实现上需要注意对齐。</li>
<li>在某些任务中，比如说深度学习可视化、可解释性等任务中，一般只要求模型前向过程，不需要训练，此时优化器、学习率等用于模型训练的模块对于该类论文复现是不需要的。</li>
<li>在图像分类领域，大多数Vision Transformer模型都采用了AdamW优化器，并且会设置weigh decay，同时部分参数设置为no weight decay，例如位置编码的参数通常设置为no weight decay，no weight decay参数设置不正确，最终会有明显的精度损失，需要特别注意。一般可以通过分析模型权重来发现该问题，分别计算官方模型和复现模型每层参数权重的平均值、方差，对每一层依次对比，有显著差异的层可能存在问题，因为在weight decay的作用下，参数权重数值会相对较小，而未正确设置no weight decay，则会造成该层参数权重数值异常偏小。</li>
<li>在OCR识别等任务中，<code>Adadelta</code>优化器常常被使用，该优化器与PyTorch实现目前稍有不同，但是不影响模型训练精度对齐，在做前反向对齐时，需要注意可以将该优化器替换为Adam等优化器（PaddlePaddle与参考代码均需要替换）；对齐完成之后，再使用<code>Adadelta</code>优化器进行训练对齐。</li>
</ul>
<h3 id="4-7-学习率对齐"><a href="#4-7-学习率对齐" class="headerlink" title="4.7 学习率对齐"></a>4.7 学习率对齐</h3><ul>
<li>PaddlePaddle 中参数的学习率受到优化器学习率和<code>ParamAttr</code>中设置的学习率影响，因此跟踪学习率需要将二者结合进行跟踪。</li>
<li>对于复现代码和参考代码，学习率在整个训练过程中在相同的轮数相同的iter下应该保持一致，可以通过<code>reprod_log</code>工具、打印学习率值或者可视化二者学习率的log来查看diff。</li>
<li>有些网络的学习率策略比较细致，比如带warmup的学习率策略，这里需要保证起始学习率等参数都完全一致。</li>
<li><code>torch.optim.lr_scheduler.MultiplicativeLR</code> API目前PaddlePaddle中没有实现，可以使用<code>paddle.optimizer.lr.LambdaDecay</code>替换实现，参考代码：<a target="_blank" rel="noopener" href="https://github.com/Paddle-Team-7/PixelCNN-Paddle/blob/607ef1d1ca6a489cecdcd2182d3acc5b2df7c779/src/pixel_cnn.py#L161">链接</a>。</li>
</ul>
<h3 id="4-8-正则化策略对齐"><a href="#4-8-正则化策略对齐" class="headerlink" title="4.8 正则化策略对齐"></a>4.8 正则化策略对齐</h3><ul>
<li>在如Transformer或者少部分CNN模型中，存在一些参数不做正则化(正则化系数为0)的情况。这里需要找到这些参数并对齐取消实施正则化策略，可以参考<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleClas/blob/release%2F2.3/ppcls/arch/backbone/model_zoo/resnest.py#L72">这里</a>，对特定参数进行修改。</li>
</ul>
<h3 id="4-9-反向对齐"><a href="#4-9-反向对齐" class="headerlink" title="4.9 反向对齐"></a>4.9 反向对齐</h3><ul>
<li>Paddle打印反向和参数更新，可以参考<a target="_blank" rel="noopener" href="https://github.com/jerrywgz/PaddleDetection/blob/debug_gfl/ppdet/modeling/backbones/resnet.py#L581">代码实例</a>；PyTorch打印反向和参数更新，可以参考<a target="_blank" rel="noopener" href="https://github.com/jerrywgz/mmdetection/blob/debug_gfl/mmdet/models/backbones/resnet.py#L630">代码实例</a>。</li>
<li>反向对齐时，如果第二轮开始，loss开始无法对齐，则首先需要排查下超参数的差异，没问题的话，在<code>loss.backward()</code>方法之后，使用<code>tensor.grad</code>获取梯度值，二分的方法查找diff，定位出PaddlePaddle与PyTorch梯度无法对齐的API或者操作，然后进一步验证。第3章中给出了获取所有参数的梯度方法，如果只希望打印特定参数的梯度，可以用下面的方式。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> paddle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_hook_fn</span>(<span class="hljs-params">grad</span>):<br>    <span class="hljs-built_in">print</span>(grad)<br><br>x = paddle.to_tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>], stop_gradient=<span class="hljs-literal">False</span>)<br>h = x.register_hook(print_hook_fn)<br>w = x * <span class="hljs-number">4</span><br>w.backward()<br><span class="hljs-comment"># backward之后会输出下面的内容</span><br><span class="hljs-comment">#     Tensor(shape=[4], dtype=float32, place=CPUPlace, stop_gradient=False,</span><br><span class="hljs-comment">#            [4., 4., 4., 4.])</span><br></code></pre></td></tr></table></figure>

<h3 id="4-10-训练集数据读取对齐"><a href="#4-10-训练集数据读取对齐" class="headerlink" title="4.10 训练集数据读取对齐"></a>4.10 训练集数据读取对齐</h3><h4 id="4-10-1-API"><a href="#4-10-1-API" class="headerlink" title="4.10.1 API"></a>4.10.1 API</h4><ul>
<li>在前向过程中，如果数据预处理过程运行出错，请先将 <code>paddle.io.DataLoader</code> 的 <code>num_workers</code> 参数设为0，然后根据单个进程下的报错日志定位出具体的bug。</li>
<li>如果使用PaddlePaddle提供的数据集API，比如<code>paddle.vision.datasets.Cifar10</code>等，可能无法完全与参考代码在数据顺序上保持一致，如果是全量数据使用，对结果不会有影响，如果是按照比例选取子集进行训练，则建议重新根据参考代码实现数据读取部分，保证子集完全一致。</li>
</ul>
<h4 id="4-10-2-数据预处理"><a href="#4-10-2-数据预处理" class="headerlink" title="4.10.2 数据预处理"></a>4.10.2 数据预处理</h4><ul>
<li>数据读取需要注意图片读取方式是opencv还是PIL.Image，图片格式是RGB还是BGR，复现时，需要保证复现代码和参考代码完全一致。</li>
<li>如果数据处理过程中涉及到随机数生成，建议固定seed (<code>np.random.seed(0)</code>, <code>random.seed(0)</code>)，查看复现代码和参考代码处理后的数据是否有diff。</li>
<li>不同的图像预处理库，使用相同的插值方式可能会有diff，建议使用相同的库对图像进行resize。</li>
<li>视频解码时，不同库解码出来的图像数据会有diff，注意区分解码库是opencv、decord还是pyAV，需要保证复现代码和参考代码完全一致。</li>
</ul>
<h3 id="4-11-网络初始化对齐"><a href="#4-11-网络初始化对齐" class="headerlink" title="4.11 网络初始化对齐"></a>4.11 网络初始化对齐</h3><h4 id="4-11-1-网络初始化通用问题"><a href="#4-11-1-网络初始化通用问题" class="headerlink" title="4.11.1 网络初始化通用问题"></a>4.11.1 网络初始化通用问题</h4><ul>
<li>对于不同的深度学习框架，网络初始化在大多情况下，即使值的分布完全一致，也无法保证值完全一致，这里也是论文复现中不确定性比较大的地方。如果十分怀疑初始化导致的问题，建议将参考的初始化权重转成paddle模型，加载该初始化模型训练，看下收敛精度。 </li>
<li>Paddle中目前没有<code>torch.nn.init.constant_()</code>的方法，如果希望对参数赋值为常数，可以使用<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/initializer/Constant_cn.html#constant">paddle.nn.initializer.Constant</a>API；或者可以参考下面的实现。更加具体的解释可以参考：<a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle/issues/37578">链接</a>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> paddle<br><span class="hljs-keyword">import</span> paddle.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Define the linear layer.</span><br>m = paddle.nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br><span class="hljs-built_in">print</span>(m.bias)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Layer):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;set m.bias&quot;</span>)<br>    m.bias.set_value(np.ones(shape=m.bias.shape, dtype=<span class="hljs-string">&quot;float32&quot;</span>))<br>    <span class="hljs-built_in">print</span>(m.bias)<br></code></pre></td></tr></table></figure>



<h4 id="4-11-2-细分场景特定问题"><a href="#4-11-2-细分场景特定问题" class="headerlink" title="4.11.2 细分场景特定问题"></a>4.11.2 细分场景特定问题</h4><ul>
<li>CNN对于模型初始化相对来说没有那么敏感，在迭代轮数与数据集足够的情况下，最终精度指标基本接近；而transformer系列模型对于初始化比较敏感，在transformer系列模型训练对齐过程中，建议对这一块进行重点检查。</li>
<li>生成模型尤其是超分模型，对初始化比较敏感，建议对初始化重点检查。</li>
<li>领域自适应算法由于需要基于初始模型生成伪标签，因此对初始网络敏感，建议加载预训练的模型进行训练。</li>
</ul>
<h3 id="4-12-模型训练对齐"><a href="#4-12-模型训练对齐" class="headerlink" title="4.12 模型训练对齐"></a>4.12 模型训练对齐</h3><h4 id="4-12-1-训练对齐通用问题"><a href="#4-12-1-训练对齐通用问题" class="headerlink" title="4.12.1 训练对齐通用问题"></a>4.12.1 训练对齐通用问题</h4><ul>
<li><p>有条件的话，复现工作之前最好先基于官方代码完成训练，保证与官方指标能够对齐，并且将训练策略和训练过程中的关键指标记录保存下来，比如每个epoch的学习率、Train Loss、Eval Loss、Eval Acc等，在复现网络的训练过程中，将关键指标保存下来，这样可以将两次训练中关键指标的变化曲线绘制出来，能够很方便的进行对比。</p>
</li>
<li><p>训练过程中可以对loss或者acc进行可视化，和竞品loss或者acc进行直观的对比；如果训练较大的数据集，1次完整训练的成本比较高，此时可以隔一段时间查看一下，如果精度差异比较大，建议先停掉实验，排查原因。</p>
</li>
<li><p>如果训练的过程中出nan，一般是因为除0或者log0的情况， 可以着重看下几个部分： </p>
</li>
<li><ul>
<li>如果有预训练模型的话，可以确认下是否加载正确</li>
<li>确认下reader的预处理中是否会出现box（或mask）为空的情况</li>
<li>模型结构中计算loss的部分是否有考虑到正样本为0的情况</li>
<li>也可能是某个API的数值越界导致的，可以测试较小的输入是否还会出现nan。</li>
</ul>
</li>
<li><p>如果训练过程中出现不收敛的情况，可以 </p>
</li>
<li><ul>
<li>简化网络和数据，实验是否收敛；</li>
<li>如果是基于原有实现进行改动，可以尝试控制变量法，每次做一个改动，逐个排查；</li>
<li>检查学习率是否过大、优化器设置是否合理，排查下weight decay是否设置正确；</li>
<li>保存不同step之间的模型参数，观察模型参数是否更新。</li>
</ul>
</li>
</ul>
<h4 id="4-12-2-细分场景特定问题"><a href="#4-12-2-细分场景特定问题" class="headerlink" title="4.12.2 细分场景特定问题"></a>4.12.2 细分场景特定问题</h4><ul>
<li>小数据上指标波动可能比较大，时间允许的话，可以跑多次实验，取平均值。</li>
<li>transformer 系列模型对于数据增广与模型初始化非常敏感，因此在保证前反向对齐后，如果训练仍无法对齐，可以考虑使用官方的PyTorch模型训练代码，结合复现的Paddle组网代码进行训练，这样可以验证是否是数据预处理&#x2F;数据增强策略存在问题。</li>
<li>检测、分割等任务中，训练通常需要加载backbone的权重作为预训练模型，注意在完成模型对齐后，将转换的权重修改为backbone权重。</li>
<li>生成任务中，训练时经常需要固定一部分网络参数。对于一个参数<code>param</code>，可以通过<code>param.trainable = False</code>来固定。</li>
<li>在训练GAN时，通常通过GAN的loss较难判断出训练是否收敛，建议每训练几次迭代保存一下训练生成的图像，通过可视化判断训练是否收敛。</li>
<li>在训练GAN时，如果PaddlePaddle实现的代码已经可以与参考代码完全一致，参考代码和PaddlePaddle代码均难以收敛，则可以在训练的时候，可以判断一下loss，如果loss大于一个阈值或者直接为NAN，说明训崩了，就终止训练，使用最新存的参数重新继续训练。可以参考该链接的实现：<a target="_blank" rel="noopener" href="https://github.com/JennyVanessa/Paddle-GI">链接</a>。</li>
</ul>
<h3 id="4-13-规范训练日志"><a href="#4-13-规范训练日志" class="headerlink" title="4.13 规范训练日志"></a>4.13 规范训练日志</h3><ul>
<li><code>autolog</code>支持训练和预测的日志规范化，更多关于<code>autolog</code>的使用可以参考：<a target="_blank" rel="noopener" href="https://github.com/LDOUBLEV/AutoLog%E3%80%82">https://github.com/LDOUBLEV/AutoLog。</a></li>
</ul>
<h3 id="4-14-预测程序开发"><a href="#4-14-预测程序开发" class="headerlink" title="4.14 预测程序开发"></a>4.14 预测程序开发</h3><h3 id="4-15-常见bug汇总"><a href="#4-15-常见bug汇总" class="headerlink" title="4.15 常见bug汇总"></a>4.15 常见bug汇总</h3><p>在论文复现中，可能因为各种原因出现报错，下面我们列举了常见的问题和解决方法，从而提供debug的方向：</p>
<h4 id="4-15-1-显存泄露"><a href="#4-15-1-显存泄露" class="headerlink" title="4.15.1 显存泄露"></a>4.15.1 显存泄露</h4><p>显存泄露会在 <code>nvidia-smi</code> 等命令下，明显地观察到显存的增加，最后会因为 <code>out of memory</code> 的错误而程序终止。</p>
<ul>
<li>可能原因：</li>
</ul>
<ol>
<li>Tensor 切片的时候增加变量引用，导致显存增加。解决方法如下：<br>   使用 where, gather 函数替代原有的 slice 方式：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a = paddle.<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>)<br>c = paddle.ones([<span class="hljs-number">3</span>])<br>b = a&gt;<span class="hljs-number">1</span><br><span class="hljs-comment"># 会增加引用的一种写法</span><br>c[b] = <span class="hljs-number">0</span><br><span class="hljs-comment"># 修改后</span><br>paddle.where(b, paddle.zeros(c.shape), c)<br></code></pre></td></tr></table></figure>

<h4 id="4-15-2-内存泄露"><a href="#4-15-2-内存泄露" class="headerlink" title="4.15.2 内存泄露"></a>4.15.2 内存泄露</h4><p>内存泄露和显存泄露相似，并不能立即察觉，而是在使用 <code>top</code> 命令时，观察到内存显著增加，最后会因为 <code>can&#39;t allocate memory</code> 的错误而程序终止，如图所示是 <code>top</code> 命令下观察内存变化需要检查的字段。</p>
<p><img src="https://gitee.com/xieleileileilei/picture/raw/master/image/image-20240110100108616.png" alt="image-20240110100108616"></p>
<p>可能原因：</p>
<ol>
<li>对在计算图中的 tensor 进行了不需要的累加、保存等操作，导致反向传播中计算图没有析构，解决方法如下：<br>   <strong>预测阶段</strong>：在predict函数上增加装饰器@paddle.no_grad()；在预测部分的代码前加上 with paddle.no_grad()<br>   <strong>训练阶段</strong>：对于不需要进行加入计算图的计算，将tensor detach出来；对于不需要使用tensor的情形，将 tensor 转换为numpy进行操作，例如下面的代码：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">cross_entropy_loss = paddle.nn.CrossEntropyLoss()<br>loss = cross_entropy_loss(pred, gt)<br><span class="hljs-comment"># 会导致内存泄露的操作</span><br>loss_total += loss<br><span class="hljs-comment"># 修改后</span><br>loss_total += loss.numpy() <span class="hljs-comment"># 如果可以转化为numpy</span><br>loss_total += loss.detach().clone() <span class="hljs-comment"># 如果需要持续使用tensor</span><br></code></pre></td></tr></table></figure>

<p>排查方法：</p>
<ol>
<li>在没有使用 paddle.no_grad 的代码中，寻找对模型参数和中间计算结果的操作；</li>
<li>考虑这些操作是否应当加入计算图中（即对最后损失产生影响）；</li>
<li>如果不需要，则需要对操作中的参数或中间计算结果进行<code>.detach().clone()</code>或者<code>.numpy</code> 后操作。</li>
</ol>
<h4 id="4-15-3-dataloader-加载数据时间长"><a href="#4-15-3-dataloader-加载数据时间长" class="headerlink" title="4.15.3 dataloader 加载数据时间长"></a>4.15.3 dataloader 加载数据时间长</h4><ul>
<li><strong>解决方式</strong>：增大 num_worker 的值，提升io速度，一般建议设置 4 或者 8。</li>
</ul>
<h4 id="4-15-4-单机多卡报错信息不明确"><a href="#4-15-4-单机多卡报错信息不明确" class="headerlink" title="4.15.4 单机多卡报错信息不明确"></a>4.15.4 单机多卡报错信息不明确</h4><ul>
<li><strong>解决方式</strong>：前往 log 下寻找 worklog.x 进行查看，其中 worklog.x 代表第 x 卡的报错信息。</li>
</ul>
<h2 id="来源："><a href="#来源：" class="headerlink" title="来源："></a>来源：</h2><p><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/">https://github.com/PaddlePaddle/</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">xie lei</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/">http://example.com/2024/01/10/CV%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Xielei's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">论文复现</a><a class="post-meta__tags" href="/tags/paddle/">paddle</a></div><div class="post_share"><div class="social-share" data-image="/img/logo.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/01/10/NLP%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0-paddle%E6%8C%87%E5%8D%97/" title="NLP论文复现-paddle指南"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">NLP论文复现-paddle指南</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/09/python%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" title="python内存管理"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">python内存管理</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/01/10/NLP%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0-paddle%E6%8C%87%E5%8D%97/" title="NLP论文复现-paddle指南"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-10</div><div class="title">NLP论文复现-paddle指南</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/logo.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">xie lei</div><div class="author-info__description">朝闻道兮</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xieleixielei"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%8C%87%E5%8D%97-CV%E6%96%B9%E5%90%91"><span class="toc-number">1.</span> <span class="toc-text">论文复现指南-CV方向</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%80%BB%E8%A7%88"><span class="toc-number">1.1.</span> <span class="toc-text">1. 总览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E8%83%8C%E6%99%AF"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 背景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%89%8D%E5%BA%8F%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 前序工作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B4%E4%BD%93%E6%A1%86%E5%9B%BE"><span class="toc-number">1.2.</span> <span class="toc-text">2. 整体框图</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%B5%81%E7%A8%8B%E6%A6%82%E8%A7%88"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 流程概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-reprod-log-whl%E5%8C%85"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 reprod_log whl包</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-reprod-log%E5%B7%A5%E5%85%B7%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.2.1 reprod_log工具简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-reprod-log%E4%BD%BF%E7%94%A8demo"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2.2.2 reprod_log使用demo</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-reprod-log%E5%9C%A8%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E4%B8%AD%E5%BA%94%E7%94%A8"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">2.2.3 reprod_log在论文复现中应用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86%E5%8F%8A%E5%AE%9E%E6%88%98"><span class="toc-number">1.3.</span> <span class="toc-text">3. 论文复现理论知识及实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 模型结构对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E4%BB%A3%E7%A0%81%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">3.1.1 网络结构代码转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E6%9D%83%E9%87%8D%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">3.1.2 权重转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E6%A8%A1%E5%9E%8B%E7%BB%84%E7%BD%91%E6%AD%A3%E7%A1%AE%E6%80%A7%E9%AA%8C%E8%AF%81"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">3.1.3 模型组网正确性验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%87%86%E5%A4%87%E5%B0%8F%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E9%AA%8C%E8%AF%81%E9%9B%86%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 准备小数据集，验证集数据读取对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 评估指标对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 损失函数对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E4%BC%98%E5%8C%96%E5%99%A8%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.5 优化器对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.6.</span> <span class="toc-text">3.6 学习率对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-7-%E6%AD%A3%E5%88%99%E5%8C%96%E7%AD%96%E7%95%A5%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.7.</span> <span class="toc-text">3.7 正则化策略对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-8-%E5%8F%8D%E5%90%91%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.8.</span> <span class="toc-text">3.8 反向对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-9-%E8%AE%AD%E7%BB%83%E9%9B%86%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.9.</span> <span class="toc-text">3.9 训练集数据读取对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-10-%E7%BD%91%E7%BB%9C%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.10.</span> <span class="toc-text">3.10 网络初始化对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-11-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AF%B9%E9%BD%90"><span class="toc-number">1.3.11.</span> <span class="toc-text">3.11 模型训练对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-12-%E8%A7%84%E8%8C%83%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97"><span class="toc-number">1.3.12.</span> <span class="toc-text">3.12 规范训练日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-13-%E9%A2%84%E6%B5%8B%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91"><span class="toc-number">1.3.13.</span> <span class="toc-text">3.13 预测程序开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-14-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E8%AE%AD%E7%BB%83"><span class="toc-number">1.3.14.</span> <span class="toc-text">3.14 单机多卡训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-14-1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96"><span class="toc-number">1.3.14.1.</span> <span class="toc-text">3.14.1 数据读取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-14-2-%E5%A4%9A%E5%8D%A1%E6%A8%A1%E5%9E%8B%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.3.14.2.</span> <span class="toc-text">3.14.2 多卡模型初始化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-14-3-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E3%80%81%E6%97%A5%E5%BF%97%E4%BF%9D%E5%AD%98%E7%AD%89%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9D%97"><span class="toc-number">1.3.14.3.</span> <span class="toc-text">3.14.3 模型保存、日志保存等其他模块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-14-4-%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F"><span class="toc-number">1.3.14.4.</span> <span class="toc-text">3.14.4 程序启动方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E4%B8%8EFAQ"><span class="toc-number">1.4.</span> <span class="toc-text">4. 论文复现注意事项与FAQ</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E9%80%9A%E7%94%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 通用注意事项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 模型结构对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-API"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">4.2.1 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E6%9D%83%E9%87%8D%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">4.2.2 权重转换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-%E6%A8%A1%E5%9E%8B%E7%BB%84%E7%BD%91%E6%AD%A3%E7%A1%AE%E6%80%A7%E9%AA%8C%E8%AF%81"><span class="toc-number">1.4.2.3.</span> <span class="toc-text">4.2.3 模型组网正确性验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E9%AA%8C%E8%AF%81-%E6%B5%8B%E8%AF%95%E9%9B%86%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 验证&#x2F;测试集数据读取对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 评估指标对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 损失函数对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E4%BC%98%E5%8C%96%E5%99%A8%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.6 优化器对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.7.</span> <span class="toc-text">4.7 学习率对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-8-%E6%AD%A3%E5%88%99%E5%8C%96%E7%AD%96%E7%95%A5%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.8.</span> <span class="toc-text">4.8 正则化策略对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-9-%E5%8F%8D%E5%90%91%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.9.</span> <span class="toc-text">4.9 反向对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-10-%E8%AE%AD%E7%BB%83%E9%9B%86%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.10.</span> <span class="toc-text">4.10 训练集数据读取对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-10-1-API"><span class="toc-number">1.4.10.1.</span> <span class="toc-text">4.10.1 API</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-10-2-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.4.10.2.</span> <span class="toc-text">4.10.2 数据预处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-11-%E7%BD%91%E7%BB%9C%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.11.</span> <span class="toc-text">4.11 网络初始化对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-11-1-%E7%BD%91%E7%BB%9C%E5%88%9D%E5%A7%8B%E5%8C%96%E9%80%9A%E7%94%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.11.1.</span> <span class="toc-text">4.11.1 网络初始化通用问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-11-2-%E7%BB%86%E5%88%86%E5%9C%BA%E6%99%AF%E7%89%B9%E5%AE%9A%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.11.2.</span> <span class="toc-text">4.11.2 细分场景特定问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-12-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AF%B9%E9%BD%90"><span class="toc-number">1.4.12.</span> <span class="toc-text">4.12 模型训练对齐</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-12-1-%E8%AE%AD%E7%BB%83%E5%AF%B9%E9%BD%90%E9%80%9A%E7%94%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.12.1.</span> <span class="toc-text">4.12.1 训练对齐通用问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-12-2-%E7%BB%86%E5%88%86%E5%9C%BA%E6%99%AF%E7%89%B9%E5%AE%9A%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.12.2.</span> <span class="toc-text">4.12.2 细分场景特定问题</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-13-%E8%A7%84%E8%8C%83%E8%AE%AD%E7%BB%83%E6%97%A5%E5%BF%97"><span class="toc-number">1.4.13.</span> <span class="toc-text">4.13 规范训练日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-14-%E9%A2%84%E6%B5%8B%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91"><span class="toc-number">1.4.14.</span> <span class="toc-text">4.14 预测程序开发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-15-%E5%B8%B8%E8%A7%81bug%E6%B1%87%E6%80%BB"><span class="toc-number">1.4.15.</span> <span class="toc-text">4.15 常见bug汇总</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-15-1-%E6%98%BE%E5%AD%98%E6%B3%84%E9%9C%B2"><span class="toc-number">1.4.15.1.</span> <span class="toc-text">4.15.1 显存泄露</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-15-2-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2"><span class="toc-number">1.4.15.2.</span> <span class="toc-text">4.15.2 内存泄露</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-15-3-dataloader-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E6%97%B6%E9%97%B4%E9%95%BF"><span class="toc-number">1.4.15.3.</span> <span class="toc-text">4.15.3 dataloader 加载数据时间长</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-15-4-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%8D%A1%E6%8A%A5%E9%94%99%E4%BF%A1%E6%81%AF%E4%B8%8D%E6%98%8E%E7%A1%AE"><span class="toc-number">1.4.15.4.</span> <span class="toc-text">4.15.4 单机多卡报错信息不明确</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A5%E6%BA%90%EF%BC%9A"><span class="toc-number">1.5.</span> <span class="toc-text">来源：</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/16/2956-%E6%89%BE%E5%88%B0%E4%B8%A4%E4%B8%AA%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E5%85%AC%E5%85%B1%E5%85%83%E7%B4%A0/" title="2956:找到两个数组中的公共元素">2956:找到两个数组中的公共元素</a><time datetime="2024-07-16T07:28:48.000Z" title="发表于 2024-07-16 15:28:48">2024-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/16/%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" title="206.反转链表">206.反转链表</a><time datetime="2024-07-16T06:56:29.000Z" title="发表于 2024-07-16 14:56:29">2024-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/16/%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0/" title="2.两数相加">2.两数相加</a><time datetime="2024-07-16T02:56:20.000Z" title="发表于 2024-07-16 10:56:20">2024-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/16/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/" title="1.两数之和">1.两数之和</a><time datetime="2024-07-16T02:55:20.000Z" title="发表于 2024-07-16 10:55:20">2024-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/15/%E6%95%B0%E6%8D%AE%E6%8A%95%E6%AF%92%E6%94%BB%E5%87%BB/" title="数据投毒攻击">数据投毒攻击</a><time datetime="2024-07-15T14:27:04.000Z" title="发表于 2024-07-15 22:27:04">2024-07-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By xie lei</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>